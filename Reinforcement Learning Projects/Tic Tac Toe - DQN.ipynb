{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright Try number 2! This time we use tensorflow as well, along with the following tricks:\n",
    "* Experience Replay \n",
    "* Fixed Q-targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# For DQN\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import math\n",
    "\n",
    "# For Experience Replay\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "#For Display (illustrator())\n",
    "from matplotlib import pyplot as plt\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "#For Testing\n",
    "from time import time\n",
    "\n",
    "signature = 'DQN '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class board:\n",
    "    \n",
    "    def __init__(self):    \n",
    "        #Game specific Variables\n",
    "        self.turn = 1\n",
    "        self.moves_left = 9\n",
    "        self.state = np.array([[0 for _ in range(9)]])\n",
    "        self.mask = np.array([[1 for _ in range(9)]])\n",
    "        \n",
    "    def update(self, action):\n",
    "        \n",
    "        if self.state[0][action] != 0:\n",
    "            raise ValueError('invalid move!', self.state, self.turn, self.moves_left, action)\n",
    "            return 'invalid move'\n",
    "            \n",
    "        self.state[0][action] = self.turn\n",
    "        self.mask[0][action] = 0\n",
    "        self.turn = (self.turn == 1)*(-1)+(self.turn == -1)*(1)\n",
    "        self.moves_left -= 1\n",
    "        \n",
    "        if self.moves_left < 5:\n",
    "            win_cond = -3*self.turn\n",
    "                        \n",
    "            # row check\n",
    "            temp = action//3 * 3\n",
    "            if self.state[0][temp] + self.state[0][temp+1] + self.state[0][temp+2] == win_cond:\n",
    "                return f\"{-1*self.turn} won\"\n",
    "            \n",
    "            # col check\n",
    "            if self.state[0][action] + self.state[0][(action+3)%9] + self.state[0][(action+6)%9] == win_cond:\n",
    "                return f\"{-1*self.turn} won\"\n",
    "            \n",
    "            #diag check\n",
    "            if action%2 == 0:\n",
    "                if self.state[0][0] + self.state[0][4] + self.state[0][8] == win_cond \\\n",
    "                or self.state[0][2] + self.state[0][4] + self.state[0][6] == win_cond:\n",
    "                    return f\"{-1*self.turn} won\"\n",
    "                            \n",
    "            if self.moves_left == 0:\n",
    "                return 'tie'\n",
    "        \n",
    "        return 'valid move'\n",
    "\n",
    "    def reset(self):\n",
    "        self.turn = 1\n",
    "        self.moves_left = 9\n",
    "        self.state = np.array([[0 for _ in range(9)]])\n",
    "        self.mask = np.array([[1 for _ in range(9)]])\n",
    "\n",
    "class game:\n",
    "    \n",
    "    def __init__(self):\n",
    "        #RL Variables\n",
    "        self.terminal = False\n",
    "        self.reward = 0\n",
    "        \n",
    "        #Tic Tac Toe Board\n",
    "        self.gameboard = board()\n",
    "        \n",
    "    def update(self, action):                    \n",
    "        result = self.gameboard.update(action)\n",
    "        \n",
    "        if result == 'invalid move':\n",
    "            self.reward = -1\n",
    "            self.terminal = True\n",
    "            \n",
    "        elif result == 'valid move':\n",
    "            self.reward = 0\n",
    "            self.terminal = False\n",
    "            \n",
    "        elif result == '1 won':\n",
    "            self.reward = 1 * -1 * self.gameboard.turn\n",
    "            self.terminal = True\n",
    "            \n",
    "        elif result == '-1 won':\n",
    "            self.reward = -1 * -1 * self.gameboard.turn\n",
    "            self.terminal = True\n",
    "        \n",
    "        elif result == 'tie':\n",
    "            self.reward = 0\n",
    "            self.terminal = True\n",
    "                \n",
    "    def reset(self):\n",
    "        self.gameboard.reset()\n",
    "        \n",
    "        self.terminal = False\n",
    "        self.reward = 0\n",
    "    \n",
    "    def return_state_features(self):\n",
    "        return self.gameboard.state.reshape(1,9)*self.gameboard.turn\n",
    "    \n",
    "    def get_mask(self):\n",
    "        return self.gameboard.mask\n",
    "    \n",
    "    def get_reward(self):\n",
    "        return self.reward\n",
    "    \n",
    "class illustrator:\n",
    "    \n",
    "    def __init__(self, host_game):\n",
    "        self.host = host_game\n",
    "    \n",
    "    def draw(self, state=None):\n",
    "        if state is not None:\n",
    "            st = state\n",
    "        else:\n",
    "            st = self.host.gameboard.state*self.host.gameboard.turn\n",
    "        \n",
    "        def convert(n):\n",
    "            return \"X\"*(n==1) + \" \"*(n==0) + \"O\"*(n==-1)\n",
    "        temp = [[convert(int(st[0][3*j+i])) for i in range(3)] for j in range(3)]\n",
    "        \n",
    "        print(f\"{temp[0][0]}|{temp[0][1]}|{temp[0][2]}\")\n",
    "        print(\"-----\")\n",
    "        print(f\"{temp[1][0]}|{temp[1][1]}|{temp[1][2]}\")\n",
    "        print(\"-----\")\n",
    "        print(f\"{temp[2][0]}|{temp[2][1]}|{temp[2][2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class player:\n",
    "    def __init__(self):\n",
    "        self.epsilon = 0\n",
    "        \n",
    "    def q_values(self, s):\n",
    "        return \"IS A PLAYER\"\n",
    "    \n",
    "    def choose_action(self, s, m):\n",
    "        return int(input(\"Where would you like to move? \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:\n",
    "* replay memory \n",
    "* freeze net \n",
    "* UCB \n",
    "* advantage stream? \n",
    "* mcts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class memory_replay:\n",
    "    \n",
    "    def __init__(self, max_size):\n",
    "        \n",
    "        self.max = max_size \n",
    "        self.mem = deque()\n",
    "    \n",
    "    def add(self, info_list):\n",
    "        \n",
    "        if len(self.mem) < self.max:\n",
    "            self.mem.append(info_list)\n",
    "            \n",
    "        else:\n",
    "            self.mem.popleft()\n",
    "            self.mem.append(info_list)\n",
    "            \n",
    "    def sample(self, mb_size):\n",
    "        \n",
    "        sample_size = min(mb_size, len(self.mem))\n",
    "        training_set = random.sample(self.mem, sample_size)\n",
    "        return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dqn:\n",
    "    def __init__(self, inp_features, num_actions, epsilon, gamma, decay=0.99999, unfreeze_freq=5000, mem_size=5000, \\\n",
    "                optimizer = keras.optimizers.SGD(learning_rate=0.0009, momentum=0.00007, name=\"SGD\"), loss = keras.losses.MSE):\n",
    "        \n",
    "        #Make the trainable variables\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.decay = decay\n",
    "        self.min_epsilon = 0.1\n",
    "        \n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer #alpha should be included in the optimizer\n",
    "        \n",
    "        self.num_actions = num_actions\n",
    "        self.u_freq = unfreeze_freq\n",
    "        self.counter = unfreeze_freq\n",
    "        self.memory = memory_replay(mem_size)\n",
    "        self.gradient_update = []\n",
    "        \n",
    "        # Make the network\n",
    "        inputs = keras.Input(shape=(inp_features,), name=\"inp\")\n",
    "        x = layers.Dense((inp_features*5//4), activation=\"relu\", name=\"layer_1\")(inputs)\n",
    "        x = layers.Dense((inp_features*10//9), activation=\"relu\", name=\"layer_2\")(x)\n",
    "        outputs = layers.Dense(num_actions, activation=\"tanh\", name=\"q_values\")(x)\n",
    "        self.q_net = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        self.freeze_net = tf.keras.models.clone_model(self.q_net)\n",
    "        self.freeze_net.set_weights(self.q_net.get_weights())\n",
    "    \n",
    "        def update(q_true, s, mask):\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = self.q_values(s)*mask\n",
    "                loss = self.loss(q_true, pred)\n",
    "                loss += sum(self.q_net.losses)\n",
    "\n",
    "            gradient = tape.gradient(loss, self.q_net.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(gradient, self.q_net.trainable_weights))\n",
    "            return gradient\n",
    "            \n",
    "        inps = (tf.TensorSpec(shape=[None, self.num_actions],dtype=tf.float32), \\\n",
    "                tf.TensorSpec(shape=[None, inp_features],dtype=tf.float32), \\\n",
    "                tf.TensorSpec(shape=[None, self.num_actions], dtype=tf.float32))\n",
    "        self.update = tf.function(func= update, input_signature= inps)\n",
    "        \n",
    "\n",
    "        def q_values(state_features):\n",
    "            return self.q_net(state_features)\n",
    "\n",
    "        self.q_values = tf.function(func= q_values, input_signature=(tf.TensorSpec(shape=[None, inp_features],dtype=tf.float32),))\n",
    "\n",
    "        def q_freeze(state_features):\n",
    "            return self.freeze_net(state_features)\n",
    "        \n",
    "        self.q_freeze = tf.function(func= q_freeze, input_signature=(tf.TensorSpec(shape=[None, inp_features],dtype=tf.float32),))\n",
    "        \n",
    "    def choose_action(self, state_features, mask = None):\n",
    "        \n",
    "        if self.epsilon > self.min_epsilon:\n",
    "            self.epsilon*=self.decay\n",
    "        \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            p = np.random.uniform(size=(1,self.num_actions))\n",
    "            if mask is not None: p*= mask\n",
    "            return int(p.argmax())\n",
    "        \n",
    "        q_values = self.q_values(state_features)\n",
    "        q_values = (q_values + 1)\n",
    "        if mask is not None: q_values*=mask\n",
    "        return int(tf.argmax(q_values[0]))\n",
    "        \n",
    "    def update_normal(self, s, a, r, s2, a2=None, mb_size = 64):\n",
    "        \n",
    "        self.memory.add([False, s,a,r,s2,a2])\n",
    "        self.train_step(mb_size)\n",
    "        \n",
    "    def update_final(self, s, a, r, mb_size = 64):\n",
    "                \n",
    "        self.memory.add([True, s,a,r])\n",
    "        self.train_step(mb_size)\n",
    "        \n",
    "    def train_step(self, mb_size): \n",
    "\n",
    "        if self.counter >=1:\n",
    "            self.counter -=1\n",
    "        else:\n",
    "            self.counter = self.u_freq\n",
    "            self.freeze_net.set_weights(self.q_net.get_weights())\n",
    "        \n",
    "        data = self.memory.sample(mb_size)\n",
    "        \n",
    "        states = []\n",
    "        rewards, mask = [np.zeros((len(data), self.num_actions)) for i in range(2)]\n",
    "        \n",
    "        for i, step in enumerate(data):\n",
    "            if step[0]:\n",
    "                s,a,r = step[1:]\n",
    "            else:\n",
    "                s,a,r,s2,a2 = step[1:]\n",
    "                r+= self.gamma*tf.reduce_max(self.q_freeze(s2)).numpy()\n",
    "                \n",
    "            rewards[i, a] = r\n",
    "            mask[i, a] = 1\n",
    "            states.append(s.reshape(-1))\n",
    "            \n",
    "        q_true = tf.constant(rewards, dtype=tf.float32)\n",
    "        s = tf.constant(states, dtype=tf.float32)\n",
    "        mask = tf.constant(mask, dtype=tf.float32)\n",
    "        grad = self.update(q_true, s, mask)\n",
    "        \n",
    "        total_update = 0\n",
    "        for g in grad:\n",
    "            total_update += tf.reduce_sum(tf.abs(g))\n",
    "        self.gradient_update.append(total_update)\n",
    "        \n",
    "    def reset_gradient_update(self):\n",
    "        size = sum(self.gradient_update)\n",
    "        self.gradient_update = []\n",
    "        return size\n",
    "        \n",
    "    def save(self, filename='sample', adjust = True):\n",
    "        if adjust: filename = signature + filename\n",
    "        self.q_net.save(filename)\n",
    "    \n",
    "    def load(self, filename='sample', adjust = True):\n",
    "        if adjust: filename = signature + filename\n",
    "        self.q_net = keras.models.load_model(filename)\n",
    "        self.freeze_net = keras.models.load_model(filename)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLEMEM = agent.memory.mem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24148de7b80>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = dqn(9, 9, 1, 0.8, decay=decay, optimizer=keras.optimizers.SGD(learning_rate=0.00012, momentum=0.00003, name=\"SGD\"))\n",
    "agent.memory.mem = SAMPLEMEM\n",
    "n = []\n",
    "for i in range(100):\n",
    "    agent.train_step(100)\n",
    "    n.append(agent.reset_gradient_update())\n",
    "    \n",
    "x = np.arange(0,len(n))\n",
    "y = np.array(n)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 eps are done! Agent epsilon: 0.16306221347847136. Took 7 steps with update of 0.7342290282249451    \n",
      "\n",
      "INFO:tensorflow:Assets written to: DQN agent_50000 simple DQN\\assets\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7256.7591190338135"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "training_eps, expec_steps = 50000, 9\n",
    "#steps_list = []\n",
    "grads_list = []\n",
    "decay = (0.1)**(1/(training_eps*expec_steps)) #min_epsilon = 0.1\n",
    "\n",
    "b = game()\n",
    "agent = dqn(9, 9, 1, 0.8, decay=decay, optimizer=keras.optimizers.SGD(learning_rate=0.00082, momentum=0.0001, name=\"SGD\"))\n",
    "mb_size = 32\n",
    "\n",
    "for ep in range(1, training_eps+1):\n",
    "            \n",
    "    s1, m1 = b.return_state_features(), b.get_mask()\n",
    "    a1 = agent.choose_action(s1, m1) \n",
    "    b.update(a1)\n",
    "    r1 = b.get_reward()\n",
    "    \n",
    "    s2, m2 = b.return_state_features(), b.get_mask()\n",
    "    a2 = agent.choose_action(s2, m2) \n",
    "    b.update(a2)\n",
    "    r2 = b.get_reward()\n",
    "     \n",
    "    remember = [(s2, a2, r2), (s1, a1, r1)]\n",
    "    steps = 1\n",
    "\n",
    "    while not b.terminal:\n",
    "\n",
    "        s, m = b.return_state_features(), b.get_mask()\n",
    "        a = agent.choose_action(s,m)\n",
    "        b.update(a)\n",
    "        r = b.get_reward()\n",
    "\n",
    "        sb, ab, rb = remember.pop()\n",
    "        remember.insert(0, (s,a,r))\n",
    "        agent.update_normal(sb, ab, rb, s, a, mb_size = mb_size)\n",
    "        \n",
    "        steps+=1\n",
    "\n",
    "    sb, ab, rb = remember.pop()\n",
    "    sg, ag, rg = remember.pop()\n",
    "    agent.update_final(sg, ag, rg, mb_size = mb_size)\n",
    "    agent.update_final(sb, ab, rg*(-1), mb_size = mb_size)\n",
    "    \n",
    "    b.reset()\n",
    "    #steps_list.append(steps)\n",
    "    grads_list.append(agent.reset_gradient_update()/(mb_size*steps))\n",
    "    \n",
    "    print(f\"{ep} eps are done! Agent epsilon: {agent.epsilon}. Took {steps} steps with update of {grads_list[-1]}   \", end='\\r')\n",
    "\n",
    "print(\"\\n\")\n",
    "agent.save('agent_{} simple DQN'.format(training_eps))\n",
    "print(\"\\nDone!\")\n",
    "\n",
    "time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2414fbe3130>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0,len(grads_list))\n",
    "y = np.array(grads_list)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before p:  [[0.35165957 0.03228974 0.09829543 0.22855671 0.37016127 0.72718488\n",
      "  0.70028248 0.1628494  0.82952456]]\n",
      "Mask m: [[1 0 0 1 1 0 1 1 1]]\n",
      "(1, 9)\n",
      "(1, 9)\n",
      "After p:  [[0.35165957 0.         0.         0.22855671 0.37016127 0.\n",
      "  0.70028248 0.1628494  0.82952456]]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([[1, 0,0,1,1,0,1,1,1]])\n",
    "p = np.random.uniform(size=(1,9))\n",
    "print(\"Before p: \", p)\n",
    "print(\"Mask m:\", m)\n",
    "print(p.shape)\n",
    "print(m.shape)\n",
    "if m is not None: p= p*m\n",
    "print(\"After p: \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player1 thinks values are [[0.46258163 0.43423808 0.62625605 0.34981054 0.41913798 0.5427545\n",
      "  0.42885187 0.4315722  0.63846767]]\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "action was 8 and the reward was 0\n",
      "\n",
      "player2 thinks values are [[ 0.07513438 -0.12841648  0.12475929 -0.28915334 -0.20171447 -0.25552863\n",
      "  -0.09003791 -0.13722306  0.07410436]]\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | |O\n",
      "action was 2 and the reward was 0\n",
      "\n",
      "player1 thinks values are [[0.53842163 0.5373466  0.7355229  0.26582757 0.5877971  0.6789705\n",
      "  0.7619905  0.54149413 0.80001795]]\n",
      " | |O\n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | |X\n",
      "action was 6 and the reward was 0\n",
      "\n",
      "player2 thinks values are [[-0.45817205 -0.70889145 -0.58439106 -0.7680274  -0.307859   -0.9031472\n",
      "  -0.48623288  0.313179   -0.00679248]]\n",
      " | |X\n",
      "-----\n",
      " | | \n",
      "-----\n",
      "O| |O\n",
      "action was 7 and the reward was 0\n",
      "\n",
      "player1 thinks values are [[0.49281827 0.5498089  0.68957835 0.35950446 0.5691828  0.44700146\n",
      "  0.6965835  0.42797977 0.63471144]]\n",
      " | |O\n",
      "-----\n",
      " | | \n",
      "-----\n",
      "X|O|X\n",
      "action was 4 and the reward was 0\n",
      "\n",
      "player2 thinks values are [[ 0.13043042 -0.10963984  0.31033772 -0.56018126 -0.24935253 -0.6665368\n",
      "   0.03866772 -0.2563605  -0.30348518]]\n",
      " | |X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "O|X|O\n",
      "action was 0 and the reward was 0\n",
      "\n",
      "player1 thinks values are [[ 0.58994365  0.5223139   0.668948   -0.12235944  0.63847864 -0.5187143\n",
      "   0.635243   -0.28173578 -0.02200614]]\n",
      "O| |O\n",
      "-----\n",
      " |X| \n",
      "-----\n",
      "X|O|X\n",
      "action was 1 and the reward was 0\n",
      "\n",
      "player2 thinks values are [[ 0.20552844  0.04379359  0.59720296 -0.2712835  -0.23002389  0.08631963\n",
      "   0.31687263 -0.29576874 -0.1188942 ]]\n",
      "X|O|X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "O|X|O\n",
      "action was 5 and the reward was 0\n",
      "\n",
      "player1 thinks values are [[ 0.59398425  0.4726377   0.70018697 -0.00450671  0.81409657 -0.09819506\n",
      "   0.8568068   0.31565902  0.65263385]]\n",
      "O|X|O\n",
      "-----\n",
      " |X|O\n",
      "-----\n",
      "X|O|X\n",
      "action was 3 and the reward was 0\n",
      "\n",
      "X|O|X\n",
      "-----\n",
      "O|O|X\n",
      "-----\n",
      "O|X|O\n"
     ]
    }
   ],
   "source": [
    "b = game()\n",
    "i = illustrator(b)\n",
    "player1 = agent#player()\n",
    "player2 = agent#agent#player()\n",
    "\n",
    "init_e1, init_e2 = player1.epsilon, player2.epsilon\n",
    "player1.epsilon, player2.epsilon = 0, 0\n",
    "\n",
    "while not b.terminal:\n",
    "    s, m = b.return_state_features(), b.get_mask()\n",
    "    print(f\"player1 thinks values are {player1.q_values(s)}\")\n",
    "    i.draw()\n",
    "    a = player1.choose_action(s, m)\n",
    "    b.update(a)\n",
    "    r = b.get_reward()\n",
    "    print(f\"action was {a} and the reward was {r}\\n\")\n",
    "    \n",
    "\n",
    "    if not b.terminal:\n",
    "        s, m = b.return_state_features(), b.get_mask()\n",
    "        print(f\"player2 thinks values are {player2.q_values(s)}\")\n",
    "        i.draw()\n",
    "        a = player2.choose_action(s, m)\n",
    "        b.update(a)\n",
    "        r = b.get_reward()\n",
    "        print(f\"action was {a} and the reward was {r}\\n\")\n",
    "            \n",
    "player1.epsilon, player2.epsilon = init_e1, init_e2\n",
    "i.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player1 thinks values are [[0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "mask is [[1 1 1 1 1 1 1 1 1]]\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "action was 1 and the reward was 0\n",
      "\n",
      "player1 thinks values are [[-0.40544295  0.51106715 -0.21474798 -0.17592032  0.04194491 -0.10426518\n",
      "   0.07508005  0.1880093   0.04645349]]\n",
      "mask is [[1 0 1 1 1 1 1 1 1]]\n",
      " |O| \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "action was 6 and the reward was 0\n",
      "\n",
      "player1 thinks values are [[-0.2801775   0.04971854  0.30935258 -0.08465388  0.17671342  0.20639361\n",
      "   0.2816697  -0.31822774 -0.25919774]]\n",
      "mask is [[1 0 1 1 1 1 0 1 1]]\n",
      " |X| \n",
      "-----\n",
      " | | \n",
      "-----\n",
      "O| | \n",
      "action was 4 and the reward was 0\n",
      "\n",
      "yay\n",
      "player1 thinks values are [[-0.60675293  0.6063926  -0.33959913 -0.31059304 -0.31372195 -0.04563268\n",
      "   0.00279822  0.13560483 -0.08742871]]\n",
      "mask is [[1 0 1 1 0 1 0 1 1]]\n",
      " |O| \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "X| | \n",
      "action was 7 and the reward was 0\n",
      "\n",
      "yay\n",
      "player1 thinks values are [[-0.08063656  0.4866256  -0.24605937 -0.00481645  0.10860009  0.17790893\n",
      "   0.3923865  -0.48966163 -0.13683066]]\n",
      "mask is [[1 0 1 1 0 1 0 0 1]]\n",
      " |X| \n",
      "-----\n",
      " |X| \n",
      "-----\n",
      "O|O| \n",
      "action was 0 and the reward was 0\n",
      "\n",
      "yay\n",
      "player1 thinks values are [[-0.2507263   0.2794626  -0.20165002 -0.07635912 -0.14134714  0.04096065\n",
      "   0.01949454  0.07576695 -0.08318947]]\n",
      "mask is [[0 0 1 1 0 1 0 0 1]]\n",
      "O|O| \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      "X|X| \n",
      "action was 3 and the reward was 0\n",
      "\n",
      "yay\n",
      "player1 thinks values are [[-0.3691543   0.47276342  0.11411069 -0.12940392  0.20757158  0.3381479\n",
      "   0.5516845  -0.68763936 -0.3860438 ]]\n",
      "mask is [[0 0 1 0 0 1 0 0 1]]\n",
      "X|X| \n",
      "-----\n",
      "O|X| \n",
      "-----\n",
      "O|O| \n",
      "action was 5 and the reward was 0\n",
      "\n",
      "yay\n",
      "player1 thinks values are [[-0.28924206  0.21177176 -0.16570005 -0.14139165 -0.1916798   0.15360649\n",
      "   0.00430193 -0.00441662 -0.21771148]]\n",
      "mask is [[0 0 1 0 0 0 0 0 1]]\n",
      "O|O| \n",
      "-----\n",
      "X|O|O\n",
      "-----\n",
      "X|X| \n",
      "action was 8 and the reward was 1\n",
      "\n",
      "yay\n",
      "X|X| \n",
      "-----\n",
      "O|X|X\n",
      "-----\n",
      "O|O|O\n"
     ]
    }
   ],
   "source": [
    "b = game()\n",
    "i = illustrator(b)\n",
    "agent = dqn(9, 9, 1, 0.8, decay=0.99, optimizer=keras.optimizers.SGD(learning_rate=0.0009, momentum=0.00007, name=\"SGD\"))\n",
    "\n",
    "\n",
    "s1, m1 = b.return_state_features(), b.get_mask()\n",
    "print(f\"player1 thinks values are {agent.q_values(s1)}\")\n",
    "print(f\"mask is {m1}\")\n",
    "i.draw()\n",
    "a1 = agent.choose_action(s1, m1) \n",
    "b.update(a1)\n",
    "r1 = b.get_reward()\n",
    "print(f\"action was {a1} and the reward was {r1}\\n\")\n",
    "\n",
    "s2, m2 = b.return_state_features(), b.get_mask()\n",
    "print(f\"player1 thinks values are {agent.q_values(s2)}\")\n",
    "print(f\"mask is {m2}\")\n",
    "i.draw()\n",
    "a2 = agent.choose_action(s2, m2) \n",
    "b.update(a2)\n",
    "r2 = b.get_reward()\n",
    "print(f\"action was {a2} and the reward was {r2}\\n\")\n",
    "\n",
    "remember = [(s2, a2, r2), (s1, a1, r1)]\n",
    "steps = 1\n",
    "\n",
    "while not b.terminal:\n",
    "\n",
    "    s, m = b.return_state_features(), b.get_mask()\n",
    "    print(f\"player1 thinks values are {agent.q_values(s)}\")\n",
    "    print(f\"mask is {m}\")\n",
    "    i.draw()\n",
    "    a = agent.choose_action(s, m)\n",
    "    b.update(a)\n",
    "    r = b.get_reward()\n",
    "    print(f\"action was {a} and the reward was {r}\\n\")\n",
    "\n",
    "    sb, ab, rb = remember.pop()\n",
    "    remember.insert(0, (s,a,r))\n",
    "    agent.update_normal(sb, ab, rb, s, a, mb_size = 20)\n",
    "\n",
    "    steps+=1\n",
    "    print('yay')\n",
    "\n",
    "sb, ab, rb = remember.pop()\n",
    "sg, ag, rg = remember.pop()\n",
    "agent.update_final(sg, ag, rg, mb_size = 20)\n",
    "agent.update_final(sb, ab, rg*(-1), mb_size = 20)\n",
    "\n",
    "i.draw()\n",
    "b.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sarsa_simple:\n",
    "    def __init__(self, num_states, num_actions, alpha, epsilon, gamma, decay=0.99999):\n",
    "        self.q_table = np.zeros((num_states, num_actions))\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = 0.1\n",
    "        self.decay = decay\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def pre_process(state_features):\n",
    "        st = 0\n",
    "        for i in range(9):\n",
    "            st+= 3**i * (state_features[0][i]+1)\n",
    "        return st\n",
    "    \n",
    "    def q_values(self, state_features):\n",
    "        return self.q_table[sarsa_simple.pre_process(state_features)]\n",
    "        \n",
    "    def choose_action(self, state_features, mask):\n",
    "        \n",
    "        if self.epsilon > self.min_epsilon:\n",
    "            self.epsilon*=self.decay\n",
    "        \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            p = np.random.uniform(size=(1,9)) * mask\n",
    "            return int(p.argmax())\n",
    "        \n",
    "        q_values = self.q_values(state_features)\n",
    "        q_values = (q_values + 1) * mask\n",
    "        \n",
    "        return int(q_values.argmax())\n",
    "        \n",
    "    def update_normal(self, s, a, r, s2, a2):\n",
    "        s = sarsa_simple.pre_process(s)\n",
    "        s2 = sarsa_simple.pre_process(s2)\n",
    "        self.q_table[s][a] += self.alpha*(r+self.gamma*self.q_table[s2][a2]-self.q_table[s][a])\n",
    "    \n",
    "    def update_final(self, s, a, r):\n",
    "        s = sarsa_simple.pre_process(s)\n",
    "        self.q_table[s][a] += self.alpha*(r-self.q_table[s][a])\n",
    "\n",
    "import json \n",
    "\n",
    "def save_simple(agent, filename = 'simple_agent'):\n",
    "    \n",
    "    data = {\"q_table\": agent.q_table.tolist(),\n",
    "            \"gamma\": agent.gamma,\n",
    "            \"alpha\": agent.alpha,\n",
    "            \"epsilon\": agent.epsilon,\n",
    "            \"decay\": agent.decay}\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def load_simple(filename = 'simple_agent'):\n",
    "    \n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    agent = sarsa_simple(1,1,0,0,0)\n",
    "    \n",
    "    agent.q_table = np.array(data[\"q_table\"])\n",
    "    agent.alpha = data['alpha']\n",
    "    agent.gamma = data['gamma']\n",
    "    agent.epsilon = data['epsilon']\n",
    "    agent.decay = data['decay']\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player 1 sarsa_simple won 4621 times and player 2 dqn won 61 times. They drew 318 times. They played 5000 games.            \r"
     ]
    }
   ],
   "source": [
    "b = game()\n",
    "i = illustrator(b)\n",
    "\n",
    "player2 = agent\n",
    "player1 = load_simple('agent_300000')\n",
    "\n",
    "init_e1, init_e2 = player1.epsilon, player2.epsilon\n",
    "expl_rate = 0.1\n",
    "player1.epsilon, player2.epsilon = expl_rate, expl_rate \n",
    "\n",
    "num_matches = 5000\n",
    "p1_wins = 0\n",
    "p2_wins = 0\n",
    "for i in range(1, num_matches+1):\n",
    "    \n",
    "    while not b.terminal:\n",
    "        s, m = b.return_state_features(), b.get_mask()\n",
    "        a = player1.choose_action(s, m)\n",
    "        b.update(a)\n",
    "        r = b.get_reward()\n",
    "        if r == 1:\n",
    "            p1_wins +=1\n",
    "\n",
    "\n",
    "        if not b.terminal:\n",
    "            s, m = b.return_state_features(), b.get_mask()\n",
    "            a = player2.choose_action(s, m)\n",
    "            b.update(a)\n",
    "            r = b.get_reward()\n",
    "            if r == 1:\n",
    "                p2_wins+=1\n",
    "                    \n",
    "    b.reset()\n",
    "    \n",
    "    if i%100==0:\n",
    "        msg1 = f'player 1 {str(player1.__class__)[17:-2]} won {p1_wins} times'\n",
    "        msg2 = f' and player 2 {str(player2.__class__)[17:-2]} won {p2_wins} times.' \n",
    "        msg3 = f' They drew {i-p1_wins-p2_wins} times.'\n",
    "        msg4 = f' They played {i} games.    '\n",
    "        print(msg1 + msg2 + msg3 + msg4 + '        ', end = '\\r')\n",
    "    #print(f\"hi {i}\", end='\\r') \n",
    "player1.epsilon, player2.epsilon = init_e1, init_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player1 thinks values are [ 0.04448604  0.00903321  0.04734044  0.05046598  0.14577523 -0.00539944\n",
      "  0.03828195  0.06640134  0.04881157]\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "action was 4 and the reward was 0\n",
      "\n",
      "player2 thinks values are [[-0.06754432  0.02131769  0.12639712  0.08479375 -0.43347448  0.110697\n",
      "  -0.15785258  0.0199419   0.06101904]]\n",
      " | | \n",
      "-----\n",
      " |O| \n",
      "-----\n",
      " | | \n",
      "action was 2 and the reward was 0\n",
      "\n",
      "player1 thinks values are [ 0.05933756  0.21819092  0.         -0.01220219  0.          0.03981587\n",
      "  0.06206419 -0.01840248  0.03726664]\n",
      " | |O\n",
      "-----\n",
      " |X| \n",
      "-----\n",
      " | | \n",
      "action was 1 and the reward was 0\n",
      "\n",
      "player2 thinks values are [[-0.05973139  0.13117014  0.18427747  0.26295444 -0.37683424  0.21481459\n",
      "  -0.10802469  0.19284865  0.13578682]]\n",
      " |O|X\n",
      "-----\n",
      " |O| \n",
      "-----\n",
      " | | \n",
      "action was 3 and the reward was 0\n",
      "\n",
      "player1 thinks values are [0.6219639  0.         0.         0.         0.         0.24250834\n",
      " 0.21694198 1.         0.64099798]\n",
      " |X|O\n",
      "-----\n",
      "O|X| \n",
      "-----\n",
      " | | \n",
      "action was 7 and the reward was 1\n",
      "\n",
      " |O|X\n",
      "-----\n",
      "X|O| \n",
      "-----\n",
      " |O| \n"
     ]
    }
   ],
   "source": [
    "b = game()\n",
    "i = illustrator(b)\n",
    "player1 = agent#player()\n",
    "player2 = load_simple('agent_300000')\n",
    "\n",
    "init_e1, init_e2 = player1.epsilon, player2.epsilon\n",
    "player1.epsilon, player2.epsilon = 0, 0\n",
    "\n",
    "while not b.terminal:\n",
    "    s, m = b.return_state_features(), b.get_mask()\n",
    "    print(f\"player1 thinks values are {player1.q_values(s)}\")\n",
    "    i.draw()\n",
    "    a = player1.choose_action(s, m)\n",
    "    b.update(a)\n",
    "    r = b.get_reward()\n",
    "    print(f\"action was {a} and the reward was {r}\\n\")\n",
    "    \n",
    "\n",
    "    if not b.terminal:\n",
    "        s, m = b.return_state_features(), b.get_mask()\n",
    "        print(f\"player2 thinks values are {player2.q_values(s)}\")\n",
    "        i.draw()\n",
    "        a = player2.choose_action(s, m)\n",
    "        b.update(a)\n",
    "        r = b.get_reward()\n",
    "        print(f\"action was {a} and the reward was {r}\\n\")\n",
    "            \n",
    "player1.epsilon, player2.epsilon = init_e1, init_e2\n",
    "i.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
