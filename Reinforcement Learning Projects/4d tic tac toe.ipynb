{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can generate test cases by having random bots play and screenshoting position 1 or 2 moves before game is won. \n",
    "Alternatively use Illustrator().get_winning_moves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the future considerations\n",
    "\n",
    "- Reduce coupling in game class (certain variables must be updated simultaneously which is bad)\n",
    "- Make sure illustrator doesn't use boardgame directly\n",
    "- Make sure nothing uses boardgame directly - need to practice good OOP principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of choices made: \n",
    "\n",
    "- Reward lies between 0 and 1 \n",
    "- Player is -1 or 1 \n",
    "- Game state includes color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from __future__ import annotations\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "\n",
    "from itertools import product\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"winning_positions\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "        \n",
    "    diags = {int(k): v for k, v in data['diags'].items()}\n",
    "    space_diags = {int(k): v for k, v in data['space_diags'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BG: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "               \n",
    "    # Will update self.reward, self.done\n",
    "    def check_done(self, a):\n",
    "        \n",
    "        def convert(p):\n",
    "            return p // 16, (p % 16) // 4, p % 4\n",
    "        \n",
    "        def unconvert(i, j, k):\n",
    "            return 16 * i + 4 * j + k\n",
    "        \n",
    "        if self.moves_left == 0:\n",
    "            self.reward = 0.5\n",
    "            self.done = True\n",
    "        \n",
    "        i, j, k = convert(a)\n",
    "        \n",
    "        # Straight Line checks\n",
    "        if sum([self.state[unconvert(i, j, t)] for t in range(4)]) == 4 * self.player or \\\n",
    "            sum([self.state[unconvert(i, t, k)] for t in range(4)]) == 4 * self.player or \\\n",
    "            sum([self.state[unconvert(t, j, k)] for t in range(4)]) == 4 * self.player: \n",
    "                self.reward = (self.player + 1) // 2\n",
    "                self.done = True\n",
    "                return None\n",
    "        \n",
    "        # Diag checks \n",
    "        for pos in diags[i] + diags[4+j] + diags[8+k]:\n",
    "            if sum([self.state[x] for x in pos]) == 4 * self.player:\n",
    "                self.reward = (self.player + 1) // 2\n",
    "                self.done = True\n",
    "                return None\n",
    "        \n",
    "        # Space diag checks \n",
    "        if a in space_diags and sum([self.state[x] for x in space_diags[a]]) == 4 * self.player:\n",
    "            self.reward = (self.player + 1) // 2\n",
    "            self.done = True\n",
    "            return None\n",
    "        \n",
    "    def step(self, a: int) -> List[np.array, int, bool, np.array]:\n",
    "        \n",
    "        if self.state[a] != 0: \n",
    "            raise ValueError('invalid move!', a, self.get_internal())\n",
    "            \n",
    "        self.state[a] = self.player\n",
    "        self.game_state[0][a + (64 if self.player == -1 else 0)] = 1\n",
    "        #self.game_state[0][[128, 129]] = 1 - self.game_state[0][[128, 129]]\n",
    "        self.mask[a] = 0\n",
    "        self.moves_left -= 1\n",
    "        self.actions_taken.append(a) \n",
    "        \n",
    "        self.check_done(a)\n",
    "        self.player *= -1 \n",
    "        \n",
    "        return self.game_state, self.reward, self.done, self.mask\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.game_state\n",
    "    \n",
    "    def undo(self): \n",
    "        if len(self.actions_taken) == 0:\n",
    "            raise ValueError('no actions taken yet', self.get_internal())\n",
    "        \n",
    "        recent_action = self.actions_taken.pop()\n",
    "        self.game_state[0][[recent_action, recent_action + 64]] = 0\n",
    "        #self.game_state[0][[128, 129]] = 1 - self.game_state[0][[128, 129]]\n",
    "        self.state[recent_action] = 0\n",
    "        self.mask[recent_action] = 1\n",
    "        self.moves_left += 1\n",
    "        self.done = False\n",
    "        self.player *= -1\n",
    "        self.reward = 0.5\n",
    "     \n",
    "    def set_internal(self, internal_dict: Dict):\n",
    "        self.game_state = internal_dict.get('game_state', np.zeros((1, 128), dtype = np.float32))\n",
    "        #self.game_state = internal_dict.get('game_state', np.zeros((1, 130), dtype = np.float32))\n",
    "        self.state = internal_dict.get('state', np.zeros(64, dtype = np.int32))\n",
    "        self.mask = internal_dict.get('mask', np.ones(64, dtype = np.float32))\n",
    "        \n",
    "        self.reward = internal_dict.get('reward', 0.5)\n",
    "        self.done = internal_dict.get('done', False)\n",
    "        \n",
    "        self.actions_taken = internal_dict.get('actions_taken', [])\n",
    "        self.moves_left = internal_dict.get('moves_left', 64)\n",
    "        self.player = internal_dict.get('player', 1.0)\n",
    "        \n",
    "    def get_internal(self) -> Dict:\n",
    "        return {'game_state': self.game_state.copy(),\n",
    "                'state': self.state.copy(), \n",
    "                'mask': self.mask.copy(), \n",
    "                'reward': self.reward, \n",
    "                'done': self.done, \n",
    "                'moves_left': self.moves_left,\n",
    "                'actions_taken': self.actions_taken.copy(),\n",
    "                'player': self.player}\n",
    "        \n",
    "    def reset(self) -> List[np.array, int, bool, np.array]:\n",
    "        self.set_internal({})\n",
    "        #self.game_state[0][128] = 1\n",
    "        return self.game_state, self.reward, self.done, self.mask\n",
    "    \n",
    "    def render(self): \n",
    "        conv = {-1: 'O', 0: ' ', 1: 'X'}\n",
    "        #for row in self.state.reshape(4, 4, 4): \n",
    "         #   temp = row.astype(np.int)\n",
    "\n",
    "         #   lines = ['|'.join(conv[v] for v in row) for row in temp]\n",
    "         #   board = '\\n-------\\n'.join(lines)\n",
    "         #   print(board, end=\"\\n\\n\")\n",
    "    \n",
    "        boards = ['\\n-------\\n'.join(['|'.join(conv[v] for v in row) for row in temp]) for temp in self.state.reshape(4, 4, 4).astype(int)]\n",
    "        grid = \"\\n\\n=======\\n\\n\".join(boards)\n",
    "        print(grid, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[0, 5, 10, 15], [3, 6, 9, 12]],\n",
       " 1: [[16, 21, 26, 31], [19, 22, 25, 28]],\n",
       " 2: [[32, 37, 42, 47], [35, 38, 41, 44]],\n",
       " 3: [[48, 53, 58, 63], [51, 54, 57, 60]],\n",
       " 4: [[0, 17, 34, 51], [3, 18, 33, 48]],\n",
       " 5: [[4, 21, 38, 55], [7, 22, 37, 52]],\n",
       " 6: [[8, 25, 42, 59], [11, 26, 41, 56]],\n",
       " 7: [[12, 29, 46, 63], [15, 30, 45, 60]],\n",
       " 8: [[0, 20, 40, 60], [12, 24, 36, 48]],\n",
       " 9: [[1, 21, 41, 61], [13, 25, 37, 49]],\n",
       " 10: [[2, 22, 42, 62], [14, 26, 38, 50]],\n",
       " 11: [[3, 23, 43, 63], [15, 27, 39, 51]]}"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants that we will use later on \n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "\n",
    "ORANGE = (255, 187, 0)\n",
    "TEAL = (0, 225, 255)\n",
    "\n",
    "class UnplayablePlayedError(ValueError):\n",
    "    pass\n",
    "\n",
    "class Illustrator:\n",
    "    \n",
    "    def __init__(self, boardgame: BG, topleft: np.array, spacing: int, normal_display: bool = False):\n",
    "        self.bg = boardgame\n",
    "        \n",
    "        self.topleft = topleft\n",
    "        \n",
    "        self.spacing = spacing\n",
    "        self.x_shift = np.array([spacing, 0])\n",
    "        self.y_shift = np.array([0, spacing])\n",
    "        self.b_shift = np.array([spacing, spacing])\n",
    "        \n",
    "        if normal_display: self.type = 1\n",
    "        else: self.type = 3 # Top row is xy slices, middle row is yz slices, bottom row is xz slices\n",
    "        \n",
    "        self.consider = 64\n",
    "        \n",
    "    def get_centerrad(self, i, j, k):\n",
    "        center = self.topleft + self.x_shift * (i + 5 * k) + self.y_shift * j + self.b_shift * 0.5\n",
    "        rad = 2 * self.spacing // 5\n",
    "        \n",
    "        return center, rad    \n",
    "        \n",
    "    def get_winning_moves(self, prev_flag = True): \n",
    "            \n",
    "        winning_moves = []\n",
    "        if prev_flag:\n",
    "            self.bg.player *= -1\n",
    "           \n",
    "        for a in range(64):\n",
    "            \n",
    "            if self.bg.mask[a] == 0:\n",
    "                continue\n",
    "                    \n",
    "            self.bg.state[a] = self.bg.player\n",
    "            \n",
    "            self.bg.check_done(a)\n",
    "            if self.bg.done:\n",
    "                winning_moves.append(a)\n",
    "                \n",
    "            self.bg.state[a] = 0\n",
    "            \n",
    "            self.bg.done = False\n",
    "        \n",
    "        if prev_flag: \n",
    "            self.bg.player *= -1\n",
    "        self.reward = 0.5\n",
    "            \n",
    "        return winning_moves        \n",
    "        \n",
    "    def get_action(self, pos: np.array): \n",
    "        \n",
    "        def unswap(i, j, k, b): \n",
    "            if b == 0: return i, j, k\n",
    "            elif b == 1: return i, k, j\n",
    "            return k, i, j\n",
    "        \n",
    "        x, y = pos - self.topleft\n",
    "        a, inpos = divmod(x, 5 * self.spacing)\n",
    "        b, downpos = divmod(y, 5 * self.spacing)\n",
    "        \n",
    "        s = self.spacing  \n",
    "        \n",
    "        # Check out of bounds \n",
    "        if  y < 0 or x < 0 or y >= 15 * s or downpos >= 4 * s or x >= 20 * s or inpos >= 4 * s: \n",
    "            raise UnplayablePlayedError(f\"Failed at mousecoor {pos}\")\n",
    "        \n",
    "        k = a\n",
    "        j = downpos // self.spacing\n",
    "        i = inpos // self.spacing \n",
    "                \n",
    "        i, j, k = unswap(i, j, k, b)\n",
    "        \n",
    "        action = i + 4 * j + 16 * k\n",
    "        \n",
    "        if self.bg.mask[action] == 0:\n",
    "            raise UnplayablePlayedError(f\"Already played action {action}\")\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    def considering(self, pos: np.array): \n",
    "        try: \n",
    "            self.consider = self.get_action(pos)\n",
    "        except UnplayablePlayedError: \n",
    "            self.consider = 64\n",
    "    \n",
    "    def draw(self, gameDisplay: pygame.Surface):\n",
    "        \n",
    "        def unconvert(a): \n",
    "            return a // 16, (a % 16) // 4, a % 4\n",
    "        \n",
    "        def swap(i, j, k, b):            \n",
    "            if b == 0: return i, j, k\n",
    "            elif b == 1: return i, k, j\n",
    "            return j, k, i\n",
    "        \n",
    "        board = self.bg.state.reshape(4, 4, 4).astype(int)\n",
    "        \n",
    "        for b in range(self.type):\n",
    "            tl_adj = self.y_shift * b * 5\n",
    "                    \n",
    "            #Draw lines\n",
    "            for x in range(4):\n",
    "                tl = self.topleft + self.x_shift * x * 5 + tl_adj\n",
    "                for i in range(1,4):\n",
    "                    pygame.draw.line(gameDisplay, WHITE, tl + i*self.x_shift, tl + i*self.x_shift + self.y_shift*4)\n",
    "                    pygame.draw.line(gameDisplay, WHITE, tl + i*self.y_shift, tl + i*self.y_shift + self.x_shift*4)\n",
    "                \n",
    "            # Draw tiles  \n",
    "            for k, j, i in product(range(4), range(4), range(4)):\n",
    "        \n",
    "                if not board[k][j][i]:\n",
    "                    continue\n",
    "                    \n",
    "                color = BLUE if board[k][j][i] == 1 else RED\n",
    "\n",
    "                i, j, k = swap(i, j, k, b)\n",
    "                    \n",
    "                center, rad = self.get_centerrad(i, j, k)\n",
    "                center += tl_adj\n",
    "\n",
    "                pygame.draw.circle(gameDisplay, color, center, rad)\n",
    "            \n",
    "        if self.bg.done: \n",
    "            return\n",
    "               \n",
    "        for b in range(self.type):\n",
    "            tl_adj = self.y_shift * b * 5\n",
    "            \n",
    "            # Draw winning squares for opponent \n",
    "            color = ORANGE if self.bg.player == 1 else TEAL\n",
    "            for move in self.get_winning_moves():\n",
    "                k, j, i = unconvert(move) \n",
    "                i, j, k = swap(i, j, k, b)\n",
    "\n",
    "                center, rad = self.get_centerrad(i, j, k)\n",
    "                center += tl_adj\n",
    "                pygame.draw.circle(gameDisplay, color, center, rad)    \n",
    "\n",
    "            # Draw square being considered\n",
    "            if self.consider != 64: \n",
    "\n",
    "                k, j, i = unconvert(self.consider)\n",
    "                i, j, k = swap(i, j, k, b)\n",
    "\n",
    "                color = BLUE if self.bg.player == 1 else RED\n",
    "                center, rad = self.get_centerrad(i, j, k)\n",
    "                center += tl_adj\n",
    "                rad /= 2\n",
    "                pygame.draw.circle(gameDisplay, color, center, rad)  \n",
    "\n",
    "            # Draw winning squares for opponent \n",
    "            color = ORANGE if self.bg.player == -1 else TEAL\n",
    "            for move in self.get_winning_moves(prev_flag = False):\n",
    "                k, j, i = unconvert(move)\n",
    "                i, j, k = swap(i, j, k, b)\n",
    "\n",
    "                center, rad = self.get_centerrad(i, j, k)\n",
    "                center += tl_adj\n",
    "                pygame.draw.circle(gameDisplay, color, center, rad)    \n",
    "                \n",
    "class GUI: \n",
    "    \n",
    "    # Create some pygame related environment variables and set the positions of the display\n",
    "    def __init__(self, topleft: np.array = np.array([60, 60]), spacing: int = 35, normal_display: bool = True):\n",
    "        \n",
    "        pygame.init()\n",
    "        pygame.display.set_caption(\"4d Tic Tac Toe\")\n",
    "        \n",
    "        if normal_display: size = (800, 300)\n",
    "        else: size = (800, 600)\n",
    "        self.gameDisplay = pygame.display.set_mode(size) \n",
    "        \n",
    "        self.game = BG()\n",
    "        self.illustrator = Illustrator(self.game, topleft, spacing, normal_display)\n",
    "        \n",
    "        self.bots = {}\n",
    "        self.compete = False\n",
    "\n",
    "        \n",
    "    def playable(self, a):\n",
    "        return self.game.mask[a] == 1\n",
    "        \n",
    "    def update(self, action: int) -> bool: \n",
    "        \n",
    "        self.illustrator.consider = 64\n",
    "        self.game.step(action)\n",
    "        \n",
    "        return self.game.done\n",
    "        \n",
    "    # Keep collecting user input and running the game until the user exits the window\n",
    "    def main_loop(self):\n",
    "        run = True\n",
    "        play = True\n",
    "        bot_move = False\n",
    "        while run: \n",
    "            self.draw_all()\n",
    "            \n",
    "            if bot_move and self.game.player in self.bots and play:\n",
    "                bot = self.bots[self.game.player]\n",
    "                action = bot.choose_action(self.game, test = True)\n",
    "\n",
    "                play = not self.update(action)\n",
    "                bot_move = False\n",
    "            \n",
    "            for event in pygame.event.get():    \n",
    "                if event.type == QUIT:\n",
    "                    run = False\n",
    "                    pygame.quit()\n",
    "                    \n",
    "                elif event.type == MOUSEMOTION and play: \n",
    "                    self.illustrator.considering(np.array(event.pos))\n",
    "        \n",
    "                elif event.type == MOUSEBUTTONDOWN and play:\n",
    "                    \n",
    "                    try: \n",
    "                        action = self.illustrator.get_action(np.array(event.pos))\n",
    "                        play = not self.update(action)\n",
    "                    \n",
    "                    except UnplayablePlayedError as e: \n",
    "                        pass\n",
    "                    \n",
    "                    if self.compete: bot_move = True\n",
    "        \n",
    "                elif event.type == KEYDOWN: \n",
    "                    if event.key == pygame.K_SPACE:\n",
    "                        run = False\n",
    "                        \n",
    "                    if event.key == pygame.K_u:\n",
    "                        try: \n",
    "                            self.game.undo()\n",
    "                            play = True\n",
    "                        except ValueError: \n",
    "                            pass\n",
    "                        \n",
    "                    if event.key == pygame.K_n:\n",
    "                        bot_move = True\n",
    "                        \n",
    "        pygame.quit()\n",
    "        \n",
    "    def connect_bots(self, bots_list):\n",
    "        self.bots = {k: v for k,v in zip([1, -1], bots_list)}\n",
    "        self.turn = self.game.player\n",
    "        \n",
    "    def enable_competition(self):\n",
    "        self.compete = True\n",
    "        \n",
    "    # Draws all the components and updates the pygame display\n",
    "    def draw_all(self):\n",
    "        self.gameDisplay.fill(BLACK)\n",
    "        self.illustrator.draw(self.gameDisplay)\n",
    "        pygame.display.update()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    \n",
    "    def __init__(self): \n",
    "        pass\n",
    "    \n",
    "    def choose_action(self, env, test = True):\n",
    "        return int(input(\"Take an action please: \"))\n",
    "    \n",
    "class RandomBot: \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def evaluate(self, env):\n",
    "        return \"IS A RANDOM BOT\"\n",
    "    \n",
    "    def choose_action(self, env, test = True):\n",
    "        return (np.random.uniform(low = 0.5, high = 1, size=[64]) * env.mask).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SPACE = 128 + 2\n",
    "ACTION_SPACE = 64\n",
    "\n",
    "inputs = keras.Input(shape=(STATE_SPACE,), name=\"inp\")\n",
    "x = layers.Dense(256, activation=\"relu\", name=\"layer_1\")(inputs)\n",
    "x = layers.Dense(128, activation=\"relu\", name=\"layer_2\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\", name=\"layer_3\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\", name=\"value\")(x)\n",
    "value_network = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Minimax:\n",
    "    \n",
    "    player_to_exp = {1: max, -1: min}\n",
    "\n",
    "        \n",
    "    def __init__(self, max_depth = 3, max_search = 500, \n",
    "                 debug = False, training = True, explore = True, \n",
    "                 epsilon = 0.9, decay = 0.9999, min_epsilon = 0.15):\n",
    "        \n",
    "        self.value = 0\n",
    "        self.e = BG()\n",
    "        self.max_depth = max_depth\n",
    "        self.max_search = max_search\n",
    "        \n",
    "        self.states = []\n",
    "        self.rewards = []\n",
    "        \n",
    "        self.loss_fn = keras.losses.MSE\n",
    "        self.optimizer = keras.optimizers.SGD(learning_rate=0.0012, momentum=0.0003, name=\"SGD\")\n",
    "        self.loss_h = []\n",
    "        self.episode_loss = []\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        self.decay = decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.explore = explore\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.training = training\n",
    "        \n",
    "        \n",
    "    def choose_action(self, env, test = False):\n",
    "        \n",
    "        self.e.set_internal(env.get_internal())    \n",
    "        \n",
    "        self.checked = 0\n",
    "        self.evals = []\n",
    "            \n",
    "        a = self.expand(self.max_depth)[0]\n",
    "        \n",
    "        if self.training: \n",
    "            r = tf.expand_dims(tf.stack(self.rewards), axis = 1)\n",
    "            \n",
    "            l = self.update(tf.stack(self.states), r)\n",
    "            self.states, self.rewards = [], []\n",
    "            self.episode_loss.append(tf.math.reduce_mean(l))\n",
    "            \n",
    "        if self.explore and not test:      \n",
    "            if self.epsilon > self.min_epsilon:\n",
    "                self.epsilon*=self.decay\n",
    "\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                p = np.random.uniform(size=(ACTION_SPACE))\n",
    "                p*= env.mask\n",
    "                a = int(p.argmax())\n",
    "        \n",
    "        return a\n",
    "        \n",
    "    def evaluate(self, s):     \n",
    "        #return tf.squeeze(value_network(s))\n",
    "    \n",
    "        start = time.time()\n",
    "        v = tf.squeeze(value_network(s))\n",
    "        self.evals.append(time.time() - start)\n",
    "        return v\n",
    "    \n",
    "    @staticmethod\n",
    "    def pick_random(options):\n",
    "        ind = np.random.choice(np.arange(len(options)))\n",
    "        return options[ind]\n",
    "            \n",
    "    def expand(self, depth):\n",
    "        \n",
    "        if depth == 0 or self.checked > self.max_search: \n",
    "        \n",
    "            self.checked += 1\n",
    "            return -1, self.evaluate(self.e.get_state())\n",
    "        \n",
    "        info = []\n",
    "        \n",
    "        for a in self.e.mask.nonzero()[0]:\n",
    "            s, r, d, m = self.e.step(a)\n",
    "            \n",
    "            if d: info.append((a, r))  \n",
    "            else: info.append((a, self.expand(depth-1)[1])) \n",
    "                \n",
    "            self.e.undo()\n",
    "            \n",
    "        _, reward = Minimax.player_to_exp[self.e.player](info, key = lambda x : x[1])\n",
    "        possibilities = [(x, y) for x,y in info if y == reward]\n",
    "        self.add_update(self.e.get_state(), reward)\n",
    "        \n",
    "        if self.debug and depth == self.max_depth:\n",
    "            stuff = [(x, round(float(y), 3)) for x, y in info]\n",
    "            stuff.sort(key = lambda t : t[1] * self.e.player)\n",
    "            print(stuff[:3], stuff[-3:], \"\\n\")\n",
    "\n",
    "        return Minimax.pick_random(possibilities)[0], reward\n",
    "    \n",
    "    @tf.function(input_signature=(tf.TensorSpec(shape=[None, STATE_SPACE],dtype=tf.float32), \n",
    "                                  tf.TensorSpec(shape=[None, 1],dtype=tf.float32)))\n",
    "    def update(self, s, r):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            r_pred = value_network(s)\n",
    "            loss = tf.norm(self.loss_fn(r, r_pred))\n",
    "            \n",
    "        gradient = tape.gradient(loss, value_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradient, value_network.trainable_weights))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def reset_metric(self):\n",
    "        if len(self.episode_loss) > 0:\n",
    "            self.loss_h.append(np.mean(self.episode_loss))\n",
    "            self.episode_loss = []\n",
    "            \n",
    "    def add_update(self, s, r):        \n",
    "        self.states.append(tf.squeeze(s))\n",
    "        self.rewards.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 1 completed in 34.72173023223877 seconds with total loss 0.027400816977024078\n",
      "1 strategies were explored with an exploration rate of 0.8983813762658757\n",
      "Game number 2 completed in 81.88843727111816 seconds with total loss 0.2318860962986946\n",
      "2 strategies were explored with an exploration rate of 0.8964070111162198\n",
      "Game number 3 completed in 111.58340954780579 seconds with total loss 0.2644715905189514\n",
      "3 strategies were explored with an exploration rate of 0.8952423809429291\n",
      "Game number 4 completed in 139.80132484436035 seconds with total loss 0.29132389426231386\n",
      "4 strategies were explored with an exploration rate of 0.8940792638807852\n",
      "Game number 5 completed in 181.31613516807556 seconds with total loss 0.4431479573249817\n",
      "5 strategies were explored with an exploration rate of 0.8923820412889367\n",
      "Game number 6 completed in 218.04813528060913 seconds with total loss 0.5649575471878052\n",
      "6 strategies were explored with an exploration rate of 0.8908662048517141\n",
      "Game number 7 completed in 251.8790364265442 seconds with total loss 0.6722265601158142\n",
      "7 strategies were explored with an exploration rate of 0.8895308405487291\n",
      "Game number 8 completed in 275.72021746635437 seconds with total loss 0.7423324957489967\n",
      "8 strategies were explored with an exploration rate of 0.8886417098903336\n",
      "Game number 9 completed in 317.69994711875916 seconds with total loss 0.9604097381234169\n",
      "9 strategies were explored with an exploration rate of 0.8869548093581164\n",
      "Game number 10 completed in 349.11784315109253 seconds with total loss 1.0217502474784852\n",
      "10 strategies were explored with an exploration rate of 0.8857138794311288\n",
      "Game number 11 completed in 377.0791013240814 seconds with total loss 1.1540962323546409\n",
      "11 strategies were explored with an exploration rate of 0.8846516071521587\n",
      "Game number 12 completed in 394.00822710990906 seconds with total loss 0.9953798368573189\n",
      "12 strategies were explored with an exploration rate of 0.88403253677303\n",
      "Game number 13 completed in 434.68411803245544 seconds with total loss 1.0896179258823395\n",
      "13 strategies were explored with an exploration rate of 0.8824426300555198\n",
      "Game number 14 completed in 488.1425268650055 seconds with total loss 1.2109292924404145\n",
      "14 strategies were explored with an exploration rate of 0.880327201499919\n",
      "Game number 15 completed in 532.5680930614471 seconds with total loss 1.2666581571102142\n",
      "15 strategies were explored with an exploration rate of 0.878656084323888\n",
      "Game number 16 completed in 558.5736455917358 seconds with total loss 1.1957093812525272\n",
      "16 strategies were explored with an exploration rate of 0.877690045747029\n",
      "Game number 17 completed in 585.8764808177948 seconds with total loss 1.278550783544779\n",
      "17 strategies were explored with an exploration rate of 0.8767250692814424\n",
      "Game number 18 completed in 630.4845068454742 seconds with total loss 1.5041250251233578\n",
      "18 strategies were explored with an exploration rate of 0.8750607900004698\n",
      "Game number 19 completed in 652.7101631164551 seconds with total loss 1.3162602454423904\n",
      "19 strategies were explored with an exploration rate of 0.8742735502378599\n",
      "Game number 20 completed in 703.4377717971802 seconds with total loss 1.475354789197445\n",
      "20 strategies were explored with an exploration rate of 0.8723521666534958\n",
      "Game number 21 completed in 903.3567929267883 seconds with total loss 1.3453048069030047\n",
      "21 strategies were explored with an exploration rate of 0.8713930589199594\n",
      "Game number 22 completed in 927.8701956272125 seconds with total loss 1.397065543010831\n",
      "22 strategies were explored with an exploration rate of 0.870347962177011\n",
      "Game number 23 completed in 955.1937506198883 seconds with total loss 1.3828752357512712\n",
      "23 strategies were explored with an exploration rate of 0.8692171884487343\n",
      "Game number 24 completed in 990.9693584442139 seconds with total loss 1.4047678608447314\n",
      "24 strategies were explored with an exploration rate of 0.8677407007728871\n",
      "Game number 25 completed in 1015.4719285964966 seconds with total loss 1.2184359807521106\n",
      "25 strategies were explored with an exploration rate of 0.8666999844499622\n",
      "Game number 26 completed in 1044.4387834072113 seconds with total loss 1.2666834753006697\n",
      "26 strategies were explored with an exploration rate of 0.8654873928533262\n",
      "Game number 27 completed in 1060.7283084392548 seconds with total loss 1.1910014774650335\n",
      "27 strategies were explored with an exploration rate of 0.8647952452270523\n",
      "Game number 28 completed in 1078.2788081169128 seconds with total loss 0.9580494236201048\n",
      "28 strategies were explored with an exploration rate of 0.8641036511251169\n",
      "Game number 29 completed in 1096.735149860382 seconds with total loss 1.0244989220052958\n",
      "29 strategies were explored with an exploration rate of 0.8633262688438449\n",
      "Game number 30 completed in 1126.7383556365967 seconds with total loss 0.9691803995519876\n",
      "30 strategies were explored with an exploration rate of 0.8621183973802038\n",
      "Game number 31 completed in 1158.7799427509308 seconds with total loss 1.1013174206018448\n",
      "31 strategies were explored with an exploration rate of 0.8608261246163046\n",
      "Game number 32 completed in 1186.6132514476776 seconds with total loss 1.0328353051096202\n",
      "32 strategies were explored with an exploration rate of 0.8598796891915872\n",
      "Game number 33 completed in 1208.0878765583038 seconds with total loss 0.9582293529063464\n",
      "33 strategies were explored with an exploration rate of 0.8590201963450884\n",
      "Game number 34 completed in 1227.0819466114044 seconds with total loss 0.8332068469375372\n",
      "34 strategies were explored with an exploration rate of 0.8582473873435016\n",
      "Game number 35 completed in 1244.9823496341705 seconds with total loss 0.8744427498430014\n",
      "35 strategies were explored with an exploration rate of 0.8575610296948395\n",
      "Game number 36 completed in 1291.1568474769592 seconds with total loss 0.9885754283517599\n",
      "36 strategies were explored with an exploration rate of 0.8555908074379651\n",
      "Game number 37 completed in 1319.697506427765 seconds with total loss 0.908826919272542\n",
      "37 strategies were explored with an exploration rate of 0.8544792065044877\n",
      "Game number 38 completed in 1332.913209438324 seconds with total loss 0.8912464011460542\n",
      "38 strategies were explored with an exploration rate of 0.8540520523406118\n",
      "Game number 39 completed in 1373.6726684570312 seconds with total loss 0.9461917508393526\n",
      "39 strategies were explored with an exploration rate of 0.8528571563439131\n",
      "Game number 40 completed in 1404.8827621936798 seconds with total loss 0.831616860255599\n",
      "40 strategies were explored with an exploration rate of 0.8516639321146894\n",
      "Game number 41 completed in 1420.2611355781555 seconds with total loss 0.6820962652564049\n",
      "41 strategies were explored with an exploration rate of 0.8510679461818297\n",
      "Game number 42 completed in 1442.7147619724274 seconds with total loss 0.667316815070808\n",
      "42 strategies were explored with an exploration rate of 0.8502172611141133\n",
      "Game number 43 completed in 1460.3814980983734 seconds with total loss 0.6895750133320689\n",
      "43 strategies were explored with an exploration rate of 0.849537325318449\n",
      "Game number 44 completed in 1490.0117630958557 seconds with total loss 0.6522370554506779\n",
      "44 strategies were explored with an exploration rate of 0.848433589191742\n",
      "Game number 45 completed in 1511.5768325328827 seconds with total loss 0.6294613994657994\n",
      "45 strategies were explored with an exploration rate of 0.8476703043263039\n",
      "Game number 46 completed in 1538.5738551616669 seconds with total loss 0.540241626650095\n",
      "46 strategies were explored with an exploration rate of 0.8467383330703748\n",
      "Game number 47 completed in 1564.059788942337 seconds with total loss 0.5209833893924951\n",
      "47 strategies were explored with an exploration rate of 0.8458073864703969\n",
      "Game number 48 completed in 1596.6621701717377 seconds with total loss 0.5093916688114405\n",
      "48 strategies were explored with an exploration rate of 0.844624025506271\n",
      "Game number 49 completed in 1630.066893339157 seconds with total loss 0.5384305987507105\n",
      "49 strategies were explored with an exploration rate of 0.8435266728383509\n",
      "Game number 50 completed in 1651.0390350818634 seconds with total loss 0.5068148463964463\n",
      "50 strategies were explored with an exploration rate of 0.8427678024315532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 51 completed in 1695.1818075180054 seconds with total loss 0.7162800412625074\n",
      "51 strategies were explored with an exploration rate of 0.8411679839235603\n",
      "Game number 52 completed in 1721.6364328861237 seconds with total loss 0.820936449803412\n",
      "52 strategies were explored with an exploration rate of 0.8402431616448706\n",
      "Game number 53 completed in 1755.2069051265717 seconds with total loss 0.7717380322515964\n",
      "53 strategies were explored with an exploration rate of 0.8390675855340806\n",
      "Game number 54 completed in 1783.4009699821472 seconds with total loss 0.7945739036425948\n",
      "54 strategies were explored with an exploration rate of 0.8380612580314928\n",
      "Game number 55 completed in 1809.5194523334503 seconds with total loss 0.7975278845056891\n",
      "55 strategies were explored with an exploration rate of 0.8371398514430975\n",
      "Game number 56 completed in 1855.835443496704 seconds with total loss 0.8604960968717933\n",
      "56 strategies were explored with an exploration rate of 0.8354671613519952\n",
      "Game number 57 completed in 1876.7184908390045 seconds with total loss 0.8734151111915708\n",
      "57 strategies were explored with an exploration rate of 0.8347155416047878\n",
      "Game number 58 completed in 1902.3828523159027 seconds with total loss 0.9640991242602468\n",
      "58 strategies were explored with an exploration rate of 0.8337978134648699\n",
      "Game number 59 completed in 1934.4309210777283 seconds with total loss 0.8468238862231374\n",
      "59 strategies were explored with an exploration rate of 0.8327145264312535\n",
      "Game number 60 completed in 1952.9938588142395 seconds with total loss 0.8609458988532424\n",
      "60 strategies were explored with an exploration rate of 0.8320485879235499\n",
      "Game number 61 completed in 1999.658489704132 seconds with total loss 0.8195562785491347\n",
      "61 strategies were explored with an exploration rate of 0.8303860706918876\n",
      "Game number 62 completed in 2039.4109523296356 seconds with total loss 0.7761038875207305\n",
      "62 strategies were explored with an exploration rate of 0.8289755431323029\n",
      "Game number 63 completed in 2069.851846933365 seconds with total loss 0.7788498967885971\n",
      "63 strategies were explored with an exploration rate of 0.8278985212901268\n",
      "Game number 64 completed in 2095.6689455509186 seconds with total loss 0.8183409661054611\n",
      "64 strategies were explored with an exploration rate of 0.8269882881243183\n",
      "Game number 65 completed in 2129.5762848854065 seconds with total loss 0.8115896217525005\n",
      "65 strategies were explored with an exploration rate of 0.8258312567793458\n",
      "Game number 66 completed in 2157.883782148361 seconds with total loss 0.6537830922752619\n",
      "66 strategies were explored with an exploration rate of 0.8248408041381982\n",
      "Game number 67 completed in 2194.7074735164642 seconds with total loss 0.7260412219911814\n",
      "67 strategies were explored with an exploration rate of 0.8236044086396455\n",
      "Game number 68 completed in 2239.262889146805 seconds with total loss 0.7843419495970011\n",
      "68 strategies were explored with an exploration rate of 0.8221231801470302\n",
      "Game number 69 completed in 2267.5068686008453 seconds with total loss 0.7333626914769411\n",
      "69 strategies were explored with an exploration rate of 0.8211371747513264\n",
      "Game number 70 completed in 2301.579444885254 seconds with total loss 0.7995120864361525\n",
      "70 strategies were explored with an exploration rate of 0.8199883296426919\n",
      "Game number 71 completed in 2317.892936229706 seconds with total loss 0.7056650098413229\n",
      "71 strategies were explored with an exploration rate of 0.8194145099807946\n",
      "Game number 72 completed in 2348.81089758873 seconds with total loss 0.6597581245005131\n",
      "72 strategies were explored with an exploration rate of 0.8183499100268435\n",
      "Game number 73 completed in 2395.6625084877014 seconds with total loss 0.866623617708683\n",
      "73 strategies were explored with an exploration rate of 0.8167964437834749\n",
      "Game number 74 completed in 2430.572993040085 seconds with total loss 0.9484938234090805\n",
      "74 strategies were explored with an exploration rate of 0.8156536717497098\n",
      "Game number 75 completed in 2459.339907884598 seconds with total loss 1.003313910216093\n",
      "75 strategies were explored with an exploration rate of 0.8147569011857488\n",
      "Game number 76 completed in 2482.7234823703766 seconds with total loss 1.152769596502185\n",
      "76 strategies were explored with an exploration rate of 0.8139425108274152\n",
      "Game number 77 completed in 2515.8509097099304 seconds with total loss 1.1742015641182662\n",
      "77 strategies were explored with an exploration rate of 0.8128037317037481\n",
      "Game number 78 completed in 2536.5570435523987 seconds with total loss 1.025471020117402\n",
      "78 strategies were explored with an exploration rate of 0.8121537162579187\n",
      "Game number 79 completed in 2555.3577864170074 seconds with total loss 1.0366806335747243\n",
      "79 strategies were explored with an exploration rate of 0.811504220642478\n",
      "Game number 80 completed in 2574.0399696826935 seconds with total loss 0.9710512757301331\n",
      "80 strategies were explored with an exploration rate of 0.8108552444417072\n",
      "Game number 81 completed in 2615.2501471042633 seconds with total loss 1.0178788229823112\n",
      "81 strategies were explored with an exploration rate of 0.8094778927381001\n",
      "Game number 82 completed in 2647.380345106125 seconds with total loss 1.0527416799217462\n",
      "82 strategies were explored with an exploration rate of 0.8084262026388442\n",
      "Game number 83 completed in 2673.3992924690247 seconds with total loss 0.9304043803364038\n",
      "83 strategies were explored with an exploration rate of 0.8075373783169895\n",
      "Game number 84 completed in 2701.778414964676 seconds with total loss 0.7982332967221737\n",
      "84 strategies were explored with an exploration rate of 0.8065688662600607\n",
      "Game number 85 completed in 2720.4612691402435 seconds with total loss 0.7208646073937416\n",
      "85 strategies were explored with an exploration rate of 0.8059238369611732\n",
      "Game number 86 completed in 2747.894630908966 seconds with total loss 0.6604063257575035\n",
      "86 strategies were explored with an exploration rate of 0.8050377638656754\n",
      "Game number 87 completed in 2785.1494114398956 seconds with total loss 0.7207416877150535\n",
      "87 strategies were explored with an exploration rate of 0.8038310521433466\n",
      "Game number 88 completed in 2816.4021351337433 seconds with total loss 0.7137170728296042\n",
      "88 strategies were explored with an exploration rate of 0.8030275827187339\n",
      "Game number 89 completed in 2844.2478597164154 seconds with total loss 0.7735914789140225\n",
      "89 strategies were explored with an exploration rate of 0.802224916402081\n",
      "Game number 90 completed in 2867.907717227936 seconds with total loss 0.7676629148423672\n",
      "90 strategies were explored with an exploration rate of 0.8014230523906415\n",
      "Game number 91 completed in 2905.3472554683685 seconds with total loss 0.7249512247741222\n",
      "91 strategies were explored with an exploration rate of 0.8001417367658284\n",
      "Game number 92 completed in 2931.284093618393 seconds with total loss 0.7365567199885845\n",
      "92 strategies were explored with an exploration rate of 0.7992620208013445\n",
      "Game number 93 completed in 2950.98463511467 seconds with total loss 0.7156389556825161\n",
      "93 strategies were explored with an exploration rate of 0.7986228349333162\n",
      "Game number 94 completed in 2982.7961859703064 seconds with total loss 0.7665732849389315\n",
      "94 strategies were explored with an exploration rate of 0.7975852479453653\n",
      "Game number 95 completed in 2997.7230756282806 seconds with total loss 0.8134497668594122\n",
      "95 strategies were explored with an exploration rate of 0.7971068164184347\n",
      "Game number 96 completed in 3025.899669647217 seconds with total loss 0.7354827564209699\n",
      "96 strategies were explored with an exploration rate of 0.7961508141539075\n",
      "Game number 97 completed in 3065.711266040802 seconds with total loss 0.67349105887115\n",
      "97 strategies were explored with an exploration rate of 0.79479843999376\n",
      "Game number 98 completed in 3101.1110026836395 seconds with total loss 0.6816357403993607\n",
      "98 strategies were explored with an exploration rate of 0.7936070765106066\n",
      "Game number 99 completed in 3127.558747291565 seconds with total loss 0.6155291959643364\n",
      "99 strategies were explored with an exploration rate of 0.7927345450794181\n",
      "Game number 100 completed in 3142.4268519878387 seconds with total loss 0.6527076222002506\n",
      "100 strategies were explored with an exploration rate of 0.7922590232466986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 101 completed in 3169.4997959136963 seconds with total loss 0.6021224103868008\n",
      "101 strategies were explored with an exploration rate of 0.7913879739328935\n",
      "Game number 102 completed in 3197.6717517375946 seconds with total loss 0.6354925505816936\n",
      "102 strategies were explored with an exploration rate of 0.7904388305061707\n",
      "Game number 103 completed in 3227.0514204502106 seconds with total loss 0.7258662424981595\n",
      "103 strategies were explored with an exploration rate of 0.7894908254253342\n",
      "Game number 104 completed in 3250.548172712326 seconds with total loss 0.7252049423754215\n",
      "104 strategies were explored with an exploration rate of 0.7887016897760579\n",
      "Game number 105 completed in 3286.8525400161743 seconds with total loss 0.8339482434093952\n",
      "105 strategies were explored with an exploration rate of 0.7875194650194164\n",
      "Game number 106 completed in 3316.476986885071 seconds with total loss 0.8108820535242558\n",
      "106 strategies were explored with an exploration rate of 0.786574961251025\n",
      "Game number 107 completed in 3343.546124458313 seconds with total loss 0.7297542445361614\n",
      "107 strategies were explored with an exploration rate of 0.7857101612801187\n",
      "Game number 108 completed in 3365.8614678382874 seconds with total loss 0.7981043249368668\n",
      "108 strategies were explored with an exploration rate of 0.785003304924635\n",
      "Game number 109 completed in 3385.6883952617645 seconds with total loss 0.8182010494172574\n",
      "109 strategies were explored with an exploration rate of 0.784375522037666\n",
      "Game number 110 completed in 3425.214075088501 seconds with total loss 0.8208355240523815\n",
      "110 strategies were explored with an exploration rate of 0.783121462013925\n",
      "Game number 111 completed in 3458.0337529182434 seconds with total loss 0.8572929002344608\n",
      "111 strategies were explored with an exploration rate of 0.7820258043226582\n",
      "Game number 112 completed in 3493.2319810390472 seconds with total loss 0.815263856202364\n",
      "112 strategies were explored with an exploration rate of 0.7808535863875538\n",
      "Game number 113 completed in 3513.077743768692 seconds with total loss 0.6794742725789547\n",
      "113 strategies were explored with an exploration rate of 0.7802291221137256\n",
      "Game number 114 completed in 3542.5558354854584 seconds with total loss 0.7116346441209316\n",
      "114 strategies were explored with an exploration rate of 0.7792933619467983\n",
      "Game number 115 completed in 3563.424080133438 seconds with total loss 0.565945066139102\n",
      "115 strategies were explored with an exploration rate of 0.7785922784012058\n",
      "Game number 116 completed in 3600.0306556224823 seconds with total loss 0.6619868453592062\n",
      "116 strategies were explored with an exploration rate of 0.7774252071513432\n",
      "Game number 117 completed in 3626.9794640541077 seconds with total loss 0.6976779710501433\n",
      "117 strategies were explored with an exploration rate of 0.7765704668790913\n",
      "Game number 118 completed in 3652.6796929836273 seconds with total loss 0.6800961147993803\n",
      "118 strategies were explored with an exploration rate of 0.7757166663511728\n",
      "Game number 119 completed in 3677.2612822055817 seconds with total loss 0.7526467937976122\n",
      "119 strategies were explored with an exploration rate of 0.7749412986642518\n",
      "Game number 120 completed in 3716.05477643013 seconds with total loss 0.7854798618704081\n",
      "120 strategies were explored with an exploration rate of 0.7737023220821212\n",
      "Game number 121 completed in 3742.096535921097 seconds with total loss 0.7686798382550478\n",
      "121 strategies were explored with an exploration rate of 0.7728516749364729\n",
      "Game number 122 completed in 3759.6269183158875 seconds with total loss 0.7749393288046121\n",
      "122 strategies were explored with an exploration rate of 0.772310841035822\n",
      "Game number 123 completed in 3783.1507561206818 seconds with total loss 0.7923481736332179\n",
      "123 strategies were explored with an exploration rate of 0.7715388776420037\n",
      "Game number 124 completed in 3806.9852545261383 seconds with total loss 0.7060877408832311\n",
      "124 strategies were explored with an exploration rate of 0.7707676858642883\n",
      "Game number 125 completed in 3835.7066690921783 seconds with total loss 0.7239309072494506\n",
      "125 strategies were explored with an exploration rate of 0.7698432731783935\n",
      "Game number 126 completed in 3862.7274203300476 seconds with total loss 0.7170788139104843\n",
      "126 strategies were explored with an exploration rate of 0.768996868864699\n",
      "Game number 127 completed in 3896.859799861908 seconds with total loss 0.6833046421408653\n",
      "127 strategies were explored with an exploration rate of 0.7679209727556012\n",
      "Game number 128 completed in 3926.1392023563385 seconds with total loss 0.644017169624567\n",
      "128 strategies were explored with an exploration rate of 0.7669999742472321\n",
      "Game number 129 completed in 3966.2312870025635 seconds with total loss 0.6735515840351581\n",
      "129 strategies were explored with an exploration rate of 0.7656971168895992\n",
      "Game number 130 completed in 3986.0163943767548 seconds with total loss 0.6153368942439557\n",
      "130 strategies were explored with an exploration rate of 0.7650847735484069\n",
      "Game number 131 completed in 4009.598843574524 seconds with total loss 0.5848434384912252\n",
      "131 strategies were explored with an exploration rate of 0.7643200329712123\n",
      "Game number 132 completed in 4034.903843641281 seconds with total loss 0.5794695373624563\n",
      "132 strategies were explored with an exploration rate of 0.7635560567905537\n",
      "Game number 133 completed in 4054.830286502838 seconds with total loss 0.5940345179289579\n",
      "133 strategies were explored with an exploration rate of 0.7629454256980635\n",
      "Game number 134 completed in 4090.1591238975525 seconds with total loss 0.5984861340373755\n",
      "134 strategies were explored with an exploration rate of 0.7618018083051773\n",
      "Game number 135 completed in 4120.143807411194 seconds with total loss 0.6230322916060687\n",
      "135 strategies were explored with an exploration rate of 0.7608881487568457\n",
      "Game number 136 completed in 4141.193154335022 seconds with total loss 0.5806979943066836\n",
      "136 strategies were explored with an exploration rate of 0.7602036232787931\n",
      "Game number 137 completed in 4169.928240776062 seconds with total loss 0.5699530679732561\n",
      "137 strategies were explored with an exploration rate of 0.7592918804980429\n",
      "Game number 138 completed in 4188.608984470367 seconds with total loss 0.5482789646834135\n",
      "138 strategies were explored with an exploration rate of 0.758684659552856\n",
      "Game number 139 completed in 4204.725330114365 seconds with total loss 0.43382074423134326\n",
      "139 strategies were explored with an exploration rate of 0.7581537395883963\n",
      "Game number 140 completed in 4245.786388397217 seconds with total loss 0.4826479826122522\n",
      "140 strategies were explored with an exploration rate of 0.7568659088048177\n",
      "Game number 141 completed in 4286.100604057312 seconds with total loss 0.4922301635146141\n",
      "141 strategies were explored with an exploration rate of 0.755580265582997\n",
      "Game number 142 completed in 4308.3817923069 seconds with total loss 0.46098639219999316\n",
      "142 strategies were explored with an exploration rate of 0.7549005152894086\n",
      "Game number 143 completed in 4337.20032119751 seconds with total loss 0.5036249175667763\n",
      "143 strategies were explored with an exploration rate of 0.7539951327393607\n",
      "Game number 144 completed in 4352.13488984108 seconds with total loss 0.5940274246037006\n",
      "144 strategies were explored with an exploration rate of 0.7535428487439083\n",
      "Game number 145 completed in 4374.625460624695 seconds with total loss 0.5577272988855839\n",
      "145 strategies were explored with an exploration rate of 0.7528649313921763\n",
      "Game number 146 completed in 4411.062899112701 seconds with total loss 0.6958977676928043\n",
      "146 strategies were explored with an exploration rate of 0.7517364241608152\n",
      "Game number 147 completed in 4450.939708709717 seconds with total loss 0.7497114710509777\n",
      "147 strategies were explored with an exploration rate of 0.750459494090277\n",
      "Game number 148 completed in 4478.16736125946 seconds with total loss 0.8060419864952564\n",
      "148 strategies were explored with an exploration rate of 0.7496344012756986\n",
      "Game number 149 completed in 4496.895015954971 seconds with total loss 0.79744220264256\n",
      "149 strategies were explored with an exploration rate of 0.7490349036103361\n",
      "Game number 150 completed in 4510.643283367157 seconds with total loss 0.7590151775628329\n",
      "150 strategies were explored with an exploration rate of 0.7485855950084259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 151 completed in 4538.130165338516 seconds with total loss 0.8668863553553819\n",
      "151 strategies were explored with an exploration rate of 0.7477625624525019\n",
      "Game number 152 completed in 4563.173403739929 seconds with total loss 0.8468203537166119\n",
      "152 strategies were explored with an exploration rate of 0.7470151362934869\n",
      "Game number 153 completed in 4597.14680147171 seconds with total loss 0.7465881479904055\n",
      "153 strategies were explored with an exploration rate of 0.7461938303786563\n",
      "Game number 154 completed in 4657.377447605133 seconds with total loss 0.7827748341485858\n",
      "154 strategies were explored with an exploration rate of 0.7447773373696144\n",
      "Game number 155 completed in 4680.429226875305 seconds with total loss 0.8063348723575473\n",
      "155 strategies were explored with an exploration rate of 0.7442561496106319\n",
      "Game number 156 completed in 4734.2991144657135 seconds with total loss 0.68214141856879\n",
      "156 strategies were explored with an exploration rate of 0.7429919258387404\n",
      "Game number 157 completed in 4768.361789703369 seconds with total loss 0.7496447248384357\n",
      "157 strategies were explored with an exploration rate of 0.7421750432433081\n",
      "Game number 158 completed in 4804.0148396492 seconds with total loss 0.7241756794974208\n",
      "158 strategies were explored with an exploration rate of 0.74135905876958\n",
      "Game number 159 completed in 4828.63457942009 seconds with total loss 0.8049869725480676\n",
      "159 strategies were explored with an exploration rate of 0.7407661790615898\n",
      "Game number 160 completed in 4870.505018234253 seconds with total loss 0.9332577088847757\n",
      "160 strategies were explored with an exploration rate of 0.7398037606146233\n",
      "Game number 161 completed in 4911.033241987228 seconds with total loss 0.8807069459930063\n",
      "161 strategies were explored with an exploration rate of 0.7388425925612268\n",
      "Game number 162 completed in 4940.67277264595 seconds with total loss 0.9020988238975406\n",
      "162 strategies were explored with an exploration rate of 0.7381779001492015\n",
      "Game number 163 completed in 4971.7879848480225 seconds with total loss 0.9528572611510754\n",
      "163 strategies were explored with an exploration rate of 0.7374400543405416\n",
      "Game number 164 completed in 4994.8366277217865 seconds with total loss 0.8398561239242553\n",
      "164 strategies were explored with an exploration rate of 0.7369240011391069\n",
      "Game number 165 completed in 5022.53697514534 seconds with total loss 0.8478949382901192\n",
      "165 strategies were explored with an exploration rate of 0.7362610347688299\n",
      "Game number 166 completed in 5073.715167999268 seconds with total loss 0.8188510037958622\n",
      "166 strategies were explored with an exploration rate of 0.7350839002142695\n",
      "Game number 167 completed in 5120.263429403305 seconds with total loss 0.8184863485395908\n",
      "167 strategies were explored with an exploration rate of 0.7339820458676806\n",
      "Game number 168 completed in 5151.218970298767 seconds with total loss 0.8244806699454784\n",
      "168 strategies were explored with an exploration rate of 0.733248394025671\n",
      "Game number 169 completed in 5178.875532865524 seconds with total loss 0.7716918542981148\n",
      "169 strategies were explored with an exploration rate of 0.7325887343788862\n",
      "Game number 170 completed in 5212.872342586517 seconds with total loss 0.718633683025837\n",
      "170 strategies were explored with an exploration rate of 0.7317832895740203\n",
      "Game number 171 completed in 5245.49458026886 seconds with total loss 0.7735623434185982\n",
      "171 strategies were explored with an exploration rate of 0.731051835499128\n",
      "Game number 172 completed in 5279.71728014946 seconds with total loss 0.7901668973267079\n",
      "172 strategies were explored with an exploration rate of 0.7302480804379894\n",
      "Game number 173 completed in 5314.00830078125 seconds with total loss 0.8222726307809353\n",
      "173 strategies were explored with an exploration rate of 0.7294452090654852\n",
      "Game number 174 completed in 5360.3593916893005 seconds with total loss 0.9472594872117043\n",
      "174 strategies were explored with an exploration rate of 0.7283518068375586\n",
      "Game number 175 completed in 5403.74911403656 seconds with total loss 1.0851591274142265\n",
      "175 strategies were explored with an exploration rate of 0.7273327768430831\n",
      "Game number 176 completed in 5432.971650362015 seconds with total loss 1.0700812660157681\n",
      "176 strategies were explored with an exploration rate of 0.7266784391226372\n",
      "Game number 177 completed in 5468.5948576927185 seconds with total loss 1.0494186542928219\n",
      "177 strategies were explored with an exploration rate of 0.7258794923928659\n",
      "Game number 178 completed in 5510.597777366638 seconds with total loss 1.0324274353682994\n",
      "178 strategies were explored with an exploration rate of 0.7249364150312095\n",
      "Game number 179 completed in 5551.103114366531 seconds with total loss 1.0139678288251162\n",
      "179 strategies were explored with an exploration rate of 0.723994562934793\n",
      "Game number 180 completed in 5600.409380197525 seconds with total loss 0.9765393767505884\n",
      "180 strategies were explored with an exploration rate of 0.7228370400222679\n",
      "Game number 181 completed in 5622.075718164444 seconds with total loss 0.900324833765626\n",
      "181 strategies were explored with an exploration rate of 0.722331205864734\n",
      "Game number 182 completed in 5657.757885456085 seconds with total loss 0.9561833072453737\n",
      "182 strategies were explored with an exploration rate of 0.7215370387012853\n",
      "Game number 183 completed in 5698.121969938278 seconds with total loss 0.8952787932008505\n",
      "183 strategies were explored with an exploration rate of 0.7205996031435559\n",
      "Game number 184 completed in 5729.035929918289 seconds with total loss 0.8741695281118155\n",
      "184 strategies were explored with an exploration rate of 0.719879327723777\n",
      "Game number 185 completed in 5752.259522438049 seconds with total loss 0.7146522123366594\n",
      "185 strategies were explored with an exploration rate of 0.719375563343836\n",
      "Game number 186 completed in 5771.904256105423 seconds with total loss 0.767873116210103\n",
      "186 strategies were explored with an exploration rate of 0.7189440458977778\n",
      "Game number 187 completed in 5804.396865844727 seconds with total loss 0.6918155495077372\n",
      "187 strategies were explored with an exploration rate of 0.7182254252904426\n",
      "Game number 188 completed in 5824.414513349533 seconds with total loss 0.7045312497764826\n",
      "188 strategies were explored with an exploration rate of 0.7177945977547188\n",
      "Game number 189 completed in 5866.201818227768 seconds with total loss 0.7288375183939934\n",
      "189 strategies were explored with an exploration rate of 0.7168620244521859\n",
      "Game number 190 completed in 5894.009873867035 seconds with total loss 0.6865882694721221\n",
      "190 strategies were explored with an exploration rate of 0.7162171066403004\n",
      "Game number 191 completed in 5937.655471801758 seconds with total loss 0.6995240986347199\n",
      "191 strategies were explored with an exploration rate of 0.7152150541879397\n",
      "Game number 192 completed in 5978.241872549057 seconds with total loss 0.6565153434872627\n",
      "192 strategies were explored with an exploration rate of 0.7142858322807374\n",
      "Game number 193 completed in 6015.604617357254 seconds with total loss 0.7761518977582454\n",
      "193 strategies were explored with an exploration rate of 0.7134291605535426\n",
      "Game number 194 completed in 6052.966668605804 seconds with total loss 0.6840991511940956\n",
      "194 strategies were explored with an exploration rate of 0.7125735162672053\n",
      "Game number 195 completed in 6082.228542804718 seconds with total loss 0.677336585521698\n",
      "195 strategies were explored with an exploration rate of 0.7119324565691837\n",
      "Game number 196 completed in 6122.799383401871 seconds with total loss 0.6104091979563236\n",
      "196 strategies were explored with an exploration rate of 0.711007499479398\n",
      "Game number 197 completed in 6157.486720561981 seconds with total loss 0.6391113363206387\n",
      "197 strategies were explored with an exploration rate of 0.7102257821668028\n",
      "Game number 198 completed in 6197.94052863121 seconds with total loss 0.6132746774703264\n",
      "198 strategies were explored with an exploration rate of 0.7093030424230223\n",
      "Game number 199 completed in 6224.393347978592 seconds with total loss 0.630831541493535\n",
      "199 strategies were explored with an exploration rate of 0.7087357985542199\n",
      "Game number 200 completed in 6258.36301445961 seconds with total loss 0.7403041739016771\n",
      "200 strategies were explored with an exploration rate of 0.7079565788635814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 201 completed in 6283.0062375068665 seconds with total loss 0.7742407787591219\n",
      "201 strategies were explored with an exploration rate of 0.7073904117886922\n",
      "Game number 202 completed in 6304.344742774963 seconds with total loss 0.7889400128275156\n",
      "202 strategies were explored with an exploration rate of 0.7068953870276705\n",
      "Game number 203 completed in 6337.114789009094 seconds with total loss 0.6605241641402244\n",
      "203 strategies were explored with an exploration rate of 0.7061888096587545\n",
      "Game number 204 completed in 6357.591466665268 seconds with total loss 0.6591703616082668\n",
      "204 strategies were explored with an exploration rate of 0.705765202287158\n",
      "Game number 205 completed in 6383.754285573959 seconds with total loss 0.7292339041829109\n",
      "205 strategies were explored with an exploration rate of 0.7052007877000672\n",
      "Game number 206 completed in 6437.972739934921 seconds with total loss 0.805569214373827\n",
      "206 strategies were explored with an exploration rate of 0.70400290495468\n",
      "Game number 207 completed in 6470.658089399338 seconds with total loss 0.8296904511749744\n",
      "207 strategies were explored with an exploration rate of 0.7032992187665669\n",
      "Game number 208 completed in 6506.253351211548 seconds with total loss 0.8534163419157267\n",
      "208 strategies were explored with an exploration rate of 0.7025259763244731\n",
      "Game number 209 completed in 6535.982456922531 seconds with total loss 0.8930632147938014\n",
      "209 strategies were explored with an exploration rate of 0.7018939557961292\n",
      "Game number 210 completed in 6565.657974243164 seconds with total loss 0.8434339497238398\n",
      "210 strategies were explored with an exploration rate of 0.7012625038587867\n",
      "Game number 211 completed in 6593.6754240989685 seconds with total loss 0.8115076575428247\n",
      "211 strategies were explored with an exploration rate of 0.7006316200009182\n",
      "Game number 212 completed in 6626.373806238174 seconds with total loss 0.8289937380701303\n",
      "212 strategies were explored with an exploration rate of 0.699931303581085\n",
      "Game number 213 completed in 6666.813828468323 seconds with total loss 0.9703115068376065\n",
      "213 strategies were explored with an exploration rate of 0.6990219386327161\n",
      "Game number 214 completed in 6716.527727127075 seconds with total loss 1.0022010289132595\n",
      "214 strategies were explored with an exploration rate of 0.6979043419659053\n",
      "Game number 215 completed in 6769.292866230011 seconds with total loss 0.93698640614748\n",
      "215 strategies were explored with an exploration rate of 0.6967188532600598\n",
      "Game number 216 completed in 6806.710936546326 seconds with total loss 0.8518146721646189\n",
      "216 strategies were explored with an exploration rate of 0.6958832503173473\n",
      "Game number 217 completed in 6839.268830299377 seconds with total loss 0.8058635918423533\n",
      "217 strategies were explored with an exploration rate of 0.6951876801310012\n",
      "Game number 218 completed in 6865.3470821380615 seconds with total loss 0.8189999198541045\n",
      "218 strategies were explored with an exploration rate of 0.6946317246005211\n",
      "Game number 219 completed in 6921.300920248032 seconds with total loss 0.8358711605891586\n",
      "219 strategies were explored with an exploration rate of 0.6933824497161717\n",
      "Game number 220 completed in 6953.977972269058 seconds with total loss 0.7621040007099509\n",
      "220 strategies were explored with an exploration rate of 0.6926893792053668\n",
      "Game number 221 completed in 6975.233570814133 seconds with total loss 0.7248189015313983\n",
      "221 strategies were explored with an exploration rate of 0.6922046420804511\n",
      "Game number 222 completed in 7002.989557027817 seconds with total loss 0.6707136554643511\n",
      "222 strategies were explored with an exploration rate of 0.6915819070381135\n",
      "Game number 223 completed in 7035.843067169189 seconds with total loss 0.5402495352551341\n",
      "223 strategies were explored with an exploration rate of 0.6908906362599582\n",
      "Game number 224 completed in 7073.435313940048 seconds with total loss 0.47161996755748986\n",
      "224 strategies were explored with an exploration rate of 0.6900620233323045\n",
      "Game number 225 completed in 7110.850382566452 seconds with total loss 0.4660480642691255\n",
      "225 strategies were explored with an exploration rate of 0.6892344041934618\n",
      "Game number 226 completed in 7146.551648616791 seconds with total loss 0.4746071308851242\n",
      "226 strategies were explored with an exploration rate of 0.6884766253140705\n",
      "Game number 227 completed in 7188.551742076874 seconds with total loss 0.44660353362560273\n",
      "227 strategies were explored with an exploration rate of 0.6875821425160749\n",
      "Game number 228 completed in 7208.167042255402 seconds with total loss 0.5062481015920639\n",
      "228 strategies were explored with an exploration rate of 0.687169696354136\n",
      "Game number 229 completed in 7254.609146118164 seconds with total loss 0.4455055624246597\n",
      "229 strategies were explored with an exploration rate of 0.6861396630252178\n",
      "Game number 230 completed in 7287.152023077011 seconds with total loss 0.4508104145526886\n",
      "230 strategies were explored with an exploration rate of 0.6854538320427186\n",
      "Game number 231 completed in 7340.888507843018 seconds with total loss 0.5144659824669361\n",
      "231 strategies were explored with an exploration rate of 0.6842894922795122\n",
      "Game number 232 completed in 7361.388330459595 seconds with total loss 0.5015571944415569\n",
      "232 strategies were explored with an exploration rate of 0.6838790212138836\n",
      "Game number 233 completed in 7399.381705522537 seconds with total loss 0.5213072016835213\n",
      "233 strategies were explored with an exploration rate of 0.6830588175981613\n",
      "Game number 234 completed in 7444.893702030182 seconds with total loss 0.6065454665571451\n",
      "234 strategies were explored with an exploration rate of 0.6821031565884831\n",
      "Game number 235 completed in 7489.883218050003 seconds with total loss 0.6097532760351896\n",
      "235 strategies were explored with an exploration rate of 0.6811488326349142\n",
      "Game number 236 completed in 7527.316751718521 seconds with total loss 0.6120959188789129\n",
      "236 strategies were explored with an exploration rate of 0.6804679902375305\n",
      "Game number 237 completed in 7566.2062776088715 seconds with total loss 0.6017018809914589\n",
      "237 strategies were explored with an exploration rate of 0.6797198495934093\n",
      "Game number 238 completed in 7588.523653507233 seconds with total loss 0.5019279375672341\n",
      "238 strategies were explored with an exploration rate of 0.6792441884160745\n",
      "Game number 239 completed in 7620.355703830719 seconds with total loss 0.4548277497291565\n",
      "239 strategies were explored with an exploration rate of 0.6785652498060483\n",
      "Game number 240 completed in 7648.347779750824 seconds with total loss 0.48774451166391375\n",
      "240 strategies were explored with an exploration rate of 0.6780225875664786\n",
      "Game number 241 completed in 7679.742144346237 seconds with total loss 0.4115672320127487\n",
      "241 strategies were explored with an exploration rate of 0.677344870007728\n",
      "Game number 242 completed in 7729.817626237869 seconds with total loss 0.410541532933712\n",
      "242 strategies were explored with an exploration rate of 0.6762619306503698\n",
      "Game number 243 completed in 7762.158669471741 seconds with total loss 0.4059966839849949\n",
      "243 strategies were explored with an exploration rate of 0.675585972956451\n",
      "Game number 244 completed in 7812.1390812397 seconds with total loss 0.42700100019574166\n",
      "244 strategies were explored with an exploration rate of 0.6745733030549885\n",
      "Game number 245 completed in 7849.258843421936 seconds with total loss 0.49230789467692376\n",
      "245 strategies were explored with an exploration rate of 0.6738316433256626\n",
      "Game number 246 completed in 7881.910105705261 seconds with total loss 0.5087470326572656\n",
      "246 strategies were explored with an exploration rate of 0.6731581148257307\n",
      "Game number 247 completed in 7908.46586728096 seconds with total loss 0.5511550769209862\n",
      "247 strategies were explored with an exploration rate of 0.6726197767804503\n",
      "Game number 248 completed in 7937.657207250595 seconds with total loss 0.5350764043629169\n",
      "248 strategies were explored with an exploration rate of 0.6720146610679759\n",
      "Game number 249 completed in 7980.245299100876 seconds with total loss 0.6325791545212269\n",
      "249 strategies were explored with an exploration rate of 0.671141565987875\n",
      "Game number 250 completed in 8014.268670082092 seconds with total loss 0.6587758578360081\n",
      "250 strategies were explored with an exploration rate of 0.6704707263550691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 251 completed in 8040.565610408783 seconds with total loss 0.6556061409413815\n",
      "251 strategies were explored with an exploration rate of 0.6699345374682468\n",
      "Game number 252 completed in 8059.189292669296 seconds with total loss 0.6953770957887173\n",
      "252 strategies were explored with an exploration rate of 0.6695326772225488\n",
      "Game number 253 completed in 8088.54629945755 seconds with total loss 0.7341913156211376\n",
      "253 strategies were explored with an exploration rate of 0.6689303387885801\n",
      "Game number 254 completed in 8112.685411930084 seconds with total loss 0.6480713292956353\n",
      "254 strategies were explored with an exploration rate of 0.6684622280033892\n",
      "Game number 255 completed in 8144.467058420181 seconds with total loss 0.6017783984541893\n",
      "255 strategies were explored with an exploration rate of 0.6677940665031871\n",
      "Game number 256 completed in 8188.466809272766 seconds with total loss 0.6513367474079133\n",
      "256 strategies were explored with an exploration rate of 0.6668597622596731\n",
      "Game number 257 completed in 8231.70345902443 seconds with total loss 0.6473323911428451\n",
      "257 strategies were explored with an exploration rate of 0.6659933645286759\n",
      "Game number 258 completed in 8266.80618596077 seconds with total loss 0.6695185370743275\n",
      "258 strategies were explored with an exploration rate of 0.6653276707812562\n",
      "Game number 259 completed in 8300.255935907364 seconds with total loss 0.6490633450448513\n",
      "259 strategies were explored with an exploration rate of 0.6646626424281016\n",
      "Game number 260 completed in 8339.509791135788 seconds with total loss 0.6499114654958248\n",
      "260 strategies were explored with an exploration rate of 0.663865485788339\n",
      "Game number 261 completed in 8357.657146215439 seconds with total loss 0.6566841192543507\n",
      "261 strategies were explored with an exploration rate of 0.6635336194253552\n",
      "Game number 262 completed in 8393.7261800766 seconds with total loss 0.6603082723915576\n",
      "262 strategies were explored with an exploration rate of 0.6628703843164486\n",
      "Game number 263 completed in 8434.330738544464 seconds with total loss 0.643029659241438\n",
      "263 strategies were explored with an exploration rate of 0.6620753772039241\n",
      "Game number 264 completed in 8478.78722858429 seconds with total loss 0.6290475342422723\n",
      "264 strategies were explored with an exploration rate of 0.661215195443047\n",
      "Game number 265 completed in 8508.638523817062 seconds with total loss 0.6597597647458315\n",
      "265 strategies were explored with an exploration rate of 0.6606864083899239\n",
      "Game number 266 completed in 8553.94548535347 seconds with total loss 0.6268853593617678\n",
      "266 strategies were explored with an exploration rate of 0.6598280312055066\n",
      "Game number 267 completed in 8591.29467701912 seconds with total loss 0.6591060061007739\n",
      "267 strategies were explored with an exploration rate of 0.6591025831677478\n",
      "Game number 268 completed in 8616.482499837875 seconds with total loss 0.6922042775899172\n",
      "268 strategies were explored with an exploration rate of 0.6586413497480066\n",
      "Game number 269 completed in 8642.355381727219 seconds with total loss 0.6974485117942095\n",
      "269 strategies were explored with an exploration rate of 0.6581804390948164\n",
      "Game number 270 completed in 8690.569873571396 seconds with total loss 0.674690817669034\n",
      "270 strategies were explored with an exploration rate of 0.6573253177165431\n",
      "Game number 271 completed in 8723.311435699463 seconds with total loss 0.65206120274961\n",
      "271 strategies were explored with an exploration rate of 0.6566682881163544\n",
      "Game number 272 completed in 8755.65676498413 seconds with total loss 0.6518929328769445\n",
      "272 strategies were explored with an exploration rate of 0.6561431373162132\n",
      "Game number 273 completed in 8791.457022428513 seconds with total loss 0.6739795919507742\n",
      "273 strategies were explored with an exploration rate of 0.6555528446490504\n",
      "Game number 274 completed in 8839.999763250351 seconds with total loss 0.7213154189288616\n",
      "274 strategies were explored with an exploration rate of 0.6547666137561597\n",
      "Game number 275 completed in 8864.346801757812 seconds with total loss 0.6782693862915039\n",
      "275 strategies were explored with an exploration rate of 0.6543084146046049\n",
      "Game number 276 completed in 8904.66363978386 seconds with total loss 0.6691880889236927\n",
      "276 strategies were explored with an exploration rate of 0.6535890351102286\n",
      "Game number 277 completed in 8961.237791538239 seconds with total loss 0.6837765164673328\n",
      "277 strategies were explored with an exploration rate of 0.6524788221873439\n",
      "Game number 278 completed in 9014.98986530304 seconds with total loss 0.6466856367886067\n",
      "278 strategies were explored with an exploration rate of 0.6515007887600374\n",
      "Game number 279 completed in 9044.004171133041 seconds with total loss 0.6085298843681812\n",
      "279 strategies were explored with an exploration rate of 0.6509797705127709\n",
      "Game number 280 completed in 9087.325791835785 seconds with total loss 0.5827474854886532\n",
      "280 strategies were explored with an exploration rate of 0.650199024291621\n",
      "Game number 281 completed in 9138.137763738632 seconds with total loss 0.6778154343366622\n",
      "281 strategies were explored with an exploration rate of 0.6492244081684073\n",
      "Game number 282 completed in 9180.18983578682 seconds with total loss 0.6432757847011089\n",
      "282 strategies were explored with an exploration rate of 0.6484457672239174\n",
      "Game number 283 completed in 9216.823808431625 seconds with total loss 0.5720269594341516\n",
      "283 strategies were explored with an exploration rate of 0.647732833418171\n",
      "Game number 284 completed in 9245.975903749466 seconds with total loss 0.536363935098052\n",
      "284 strategies were explored with an exploration rate of 0.6471501069975133\n",
      "Game number 285 completed in 9267.12298321724 seconds with total loss 0.519092621281743\n",
      "285 strategies were explored with an exploration rate of 0.6466972378014896\n",
      "Game number 286 completed in 9290.040305376053 seconds with total loss 0.5320385571569204\n",
      "286 strategies were explored with an exploration rate of 0.6462446855188164\n",
      "Game number 287 completed in 9328.648883342743 seconds with total loss 0.4583877455443144\n",
      "287 strategies were explored with an exploration rate of 0.6455987315658703\n",
      "Game number 288 completed in 9349.707618236542 seconds with total loss 0.5300767224282026\n",
      "288 strategies were explored with an exploration rate of 0.6452114691538297\n",
      "Game number 289 completed in 9381.796749830246 seconds with total loss 0.49683113805949686\n",
      "289 strategies were explored with an exploration rate of 0.6446310110535305\n",
      "Game number 290 completed in 9399.497942209244 seconds with total loss 0.49093321748077867\n",
      "290 strategies were explored with an exploration rate of 0.644308760004659\n",
      "Game number 291 completed in 9432.595611333847 seconds with total loss 0.42907362766563895\n",
      "291 strategies were explored with an exploration rate of 0.6437934933670313\n",
      "Game number 292 completed in 9465.864911317825 seconds with total loss 0.40357921570539473\n",
      "292 strategies were explored with an exploration rate of 0.6431499895034946\n",
      "Game number 293 completed in 9505.79802107811 seconds with total loss 0.42871451415121553\n",
      "293 strategies were explored with an exploration rate of 0.642314395990237\n",
      "Game number 294 completed in 9534.901593208313 seconds with total loss 0.4942683231085539\n",
      "294 strategies were explored with an exploration rate of 0.6417365442130818\n",
      "Game number 295 completed in 9572.307787418365 seconds with total loss 0.5072925392538309\n",
      "295 strategies were explored with an exploration rate of 0.6409668837649952\n",
      "Game number 296 completed in 9607.987621068954 seconds with total loss 0.4798500042408705\n",
      "296 strategies were explored with an exploration rate of 0.6402621726189014\n",
      "Game number 297 completed in 9630.70977807045 seconds with total loss 0.48489424102008344\n",
      "297 strategies were explored with an exploration rate of 0.6398141235307175\n",
      "Game number 298 completed in 9672.25734758377 seconds with total loss 0.4199451331049204\n",
      "298 strategies were explored with an exploration rate of 0.6389828640422031\n",
      "Game number 299 completed in 9701.467097997665 seconds with total loss 0.40783580429852007\n",
      "299 strategies were explored with an exploration rate of 0.6384080094447298\n",
      "Game number 300 completed in 9737.398784637451 seconds with total loss 0.4078024197369814\n",
      "300 strategies were explored with an exploration rate of 0.6377061116534296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 301 completed in 9777.153287410736 seconds with total loss 0.43647126145660875\n",
      "301 strategies were explored with an exploration rate of 0.6369412850652153\n",
      "Game number 302 completed in 9814.53553366661 seconds with total loss 0.5665349304676056\n",
      "302 strategies were explored with an exploration rate of 0.636240999864276\n",
      "Game number 303 completed in 9843.591791629791 seconds with total loss 0.5557885952293873\n",
      "303 strategies were explored with an exploration rate of 0.635668611957722\n",
      "Game number 304 completed in 9897.439201831818 seconds with total loss 0.581524670869112\n",
      "304 strategies were explored with an exploration rate of 0.6345888393946029\n",
      "Game number 305 completed in 9931.34316277504 seconds with total loss 0.5921021372079849\n",
      "305 strategies were explored with an exploration rate of 0.6338911405904444\n",
      "Game number 306 completed in 9957.295016288757 seconds with total loss 0.6365025125443935\n",
      "306 strategies were explored with an exploration rate of 0.633384205131998\n",
      "Game number 307 completed in 9992.434034585953 seconds with total loss 0.6472946606576443\n",
      "307 strategies were explored with an exploration rate of 0.6326878307631785\n",
      "Game number 308 completed in 10009.562937736511 seconds with total loss 0.6373197749257088\n",
      "308 strategies were explored with an exploration rate of 0.6323715501102535\n",
      "Game number 309 completed in 10060.82936000824 seconds with total loss 0.7577620446681976\n",
      "309 strategies were explored with an exploration rate of 0.6314868051680899\n",
      "Game number 310 completed in 10089.139703989029 seconds with total loss 0.7334496185183526\n",
      "310 strategies were explored with an exploration rate of 0.6309817925049019\n",
      "Game number 311 completed in 10145.34284543991 seconds with total loss 0.7189549431204796\n",
      "311 strategies were explored with an exploration rate of 0.6299099811639641\n",
      "Game number 312 completed in 10182.455448627472 seconds with total loss 0.5921869799494743\n",
      "312 strategies were explored with an exploration rate of 0.6291545047886059\n",
      "Game number 313 completed in 10227.313823461533 seconds with total loss 0.62426123842597\n",
      "313 strategies were explored with an exploration rate of 0.628274260783552\n",
      "Game number 314 completed in 10275.047939300537 seconds with total loss 0.5953082703053951\n",
      "314 strategies were explored with an exploration rate of 0.6273325087945714\n",
      "Game number 315 completed in 10301.058965921402 seconds with total loss 0.5791666708886624\n",
      "315 strategies were explored with an exploration rate of 0.626830818405512\n",
      "Game number 316 completed in 10333.490706682205 seconds with total loss 0.542954083532095\n",
      "316 strategies were explored with an exploration rate of 0.6262042695857685\n",
      "Game number 317 completed in 10368.910673379898 seconds with total loss 0.513216856122017\n",
      "317 strategies were explored with an exploration rate of 0.6255157891982696\n",
      "Game number 318 completed in 10391.820922374725 seconds with total loss 0.513694629818201\n",
      "318 strategies were explored with an exploration rate of 0.6250780594822557\n",
      "Game number 319 completed in 10414.777168035507 seconds with total loss 0.4197534382343292\n",
      "319 strategies were explored with an exploration rate of 0.6246406360851352\n",
      "Game number 320 completed in 10434.35461473465 seconds with total loss 0.43350875973701475\n",
      "320 strategies were explored with an exploration rate of 0.6242659453870877\n",
      "Game number 321 completed in 10472.855632781982 seconds with total loss 0.44921700954437255\n",
      "321 strategies were explored with an exploration rate of 0.6235172381308395\n",
      "Game number 322 completed in 10514.3337392807 seconds with total loss 0.45641207695007324\n",
      "322 strategies were explored with an exploration rate of 0.6227071518864338\n",
      "Game number 323 completed in 10548.239694356918 seconds with total loss 0.44062470346689225\n",
      "323 strategies were explored with an exploration rate of 0.6220225164055664\n",
      "Game number 324 completed in 10569.30750155449 seconds with total loss 0.43019217550754546\n",
      "324 strategies were explored with an exploration rate of 0.6215872312470423\n",
      "Game number 325 completed in 10598.34874343872 seconds with total loss 0.40907507948577404\n",
      "325 strategies were explored with an exploration rate of 0.6210280264581177\n",
      "Game number 326 completed in 10640.511981964111 seconds with total loss 0.37531048636883496\n",
      "326 strategies were explored with an exploration rate of 0.6202211742480132\n",
      "Game number 327 completed in 10667.987497329712 seconds with total loss 0.46887380834668874\n",
      "327 strategies were explored with an exploration rate of 0.6196631984187219\n",
      "Game number 328 completed in 10692.322953939438 seconds with total loss 0.4929335845634341\n",
      "328 strategies were explored with an exploration rate of 0.6191676413309858\n",
      "Game number 329 completed in 10741.569762468338 seconds with total loss 0.5660631259903312\n",
      "329 strategies were explored with an exploration rate of 0.6181777157594047\n",
      "Game number 330 completed in 10760.961977005005 seconds with total loss 0.6108273727819323\n",
      "330 strategies were explored with an exploration rate of 0.617806901844244\n",
      "Game number 331 completed in 10783.799685955048 seconds with total loss 0.5935568211600184\n",
      "331 strategies were explored with an exploration rate of 0.6173745667307814\n",
      "Game number 332 completed in 10817.564324617386 seconds with total loss 0.6722657648846507\n",
      "332 strategies were explored with an exploration rate of 0.616695794161543\n",
      "Game number 333 completed in 10854.520189285278 seconds with total loss 0.697166551463306\n",
      "333 strategies were explored with an exploration rate of 0.6159561660921309\n",
      "Game number 334 completed in 10886.684019804 seconds with total loss 0.736256149224937\n",
      "334 strategies were explored with an exploration rate of 0.6153404870324116\n",
      "Game number 335 completed in 10907.726020812988 seconds with total loss 0.775681653805077\n",
      "335 strategies were explored with an exploration rate of 0.6149098778914563\n",
      "Game number 336 completed in 10932.227222681046 seconds with total loss 0.8302773833274841\n",
      "336 strategies were explored with an exploration rate of 0.6144181221294783\n",
      "Game number 337 completed in 10959.705635547638 seconds with total loss 0.7685626797378063\n",
      "337 strategies were explored with an exploration rate of 0.6138653669584826\n",
      "Game number 338 completed in 10997.029752731323 seconds with total loss 0.7345433417707682\n",
      "338 strategies were explored with an exploration rate of 0.6131291335342546\n",
      "Game number 339 completed in 11021.387169837952 seconds with total loss 0.7274876806885004\n",
      "339 strategies were explored with an exploration rate of 0.6126388018692538\n",
      "Game number 340 completed in 11045.869223117828 seconds with total loss 0.6900008846074343\n",
      "340 strategies were explored with an exploration rate of 0.6121488623323195\n",
      "Game number 341 completed in 11091.897867679596 seconds with total loss 0.7147520158439875\n",
      "341 strategies were explored with an exploration rate of 0.6112312815166822\n",
      "Game number 342 completed in 11125.636137723923 seconds with total loss 0.661177285388112\n",
      "342 strategies were explored with an exploration rate of 0.6105592631833857\n",
      "Game number 343 completed in 11148.640055179596 seconds with total loss 0.6046817734837532\n",
      "343 strategies were explored with an exploration rate of 0.610131999895235\n",
      "Game number 344 completed in 11177.735635757446 seconds with total loss 0.5604814037680625\n",
      "344 strategies were explored with an exploration rate of 0.6095831006916059\n",
      "Game number 345 completed in 11195.703057050705 seconds with total loss 0.5412840895354748\n",
      "345 strategies were explored with an exploration rate of 0.6092174422564652\n",
      "Game number 346 completed in 11238.998842477798 seconds with total loss 0.5062723666429519\n",
      "346 strategies were explored with an exploration rate of 0.6084259345969443\n",
      "Game number 347 completed in 11261.821516513824 seconds with total loss 0.4872843474149704\n",
      "347 strategies were explored with an exploration rate of 0.60800016419088\n",
      "Game number 348 completed in 11301.85659980774 seconds with total loss 0.48649848662316797\n",
      "348 strategies were explored with an exploration rate of 0.6072102380437154\n",
      "Game number 349 completed in 11326.2229950428 seconds with total loss 0.4202289666980505\n",
      "349 strategies were explored with an exploration rate of 0.6067246398381475\n",
      "Game number 350 completed in 11352.232485294342 seconds with total loss 0.41211867295205595\n",
      "350 strategies were explored with an exploration rate of 0.606239429975204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number 351 completed in 11395.33252120018 seconds with total loss 0.37230931110680104\n",
      "351 strategies were explored with an exploration rate of 0.6053912462305095\n",
      "Game number 352 completed in 11439.881155967712 seconds with total loss 0.48573819138109686\n",
      "352 strategies were explored with an exploration rate of 0.604544249171519\n",
      "Game number 353 completed in 11477.00872707367 seconds with total loss 0.5344441182911396\n",
      "353 strategies were explored with an exploration rate of 0.603819194938748\n",
      "Game number 354 completed in 11515.45513510704 seconds with total loss 0.5161965079605579\n",
      "354 strategies were explored with an exploration rate of 0.6030950102926798\n",
      "Game number 355 completed in 11546.28967833519 seconds with total loss 0.5425953730940819\n",
      "355 strategies were explored with an exploration rate of 0.602492186602783\n",
      "Game number 356 completed in 11586.237943172455 seconds with total loss 0.6224075742065907\n",
      "356 strategies were explored with an exploration rate of 0.6017094165318352\n",
      "Game number 357 completed in 11618.460109472275 seconds with total loss 0.7365718558430672\n",
      "357 strategies were explored with an exploration rate of 0.6011079778123484\n",
      "Game number 358 completed in 11663.079287528992 seconds with total loss 0.7846842654049396\n",
      "358 strategies were explored with an exploration rate of 0.6002669734329278\n",
      "Game number 359 completed in 11697.120261669159 seconds with total loss 0.8306568421423435\n",
      "359 strategies were explored with an exploration rate of 0.5996070098099627\n",
      "Game number 360 completed in 11737.303176403046 seconds with total loss 0.9431688867509365\n",
      "360 strategies were explored with an exploration rate of 0.5988279882192328\n",
      "Game number 361 completed in 11774.346613407135 seconds with total loss 0.9367892257869244\n",
      "361 strategies were explored with an exploration rate of 0.5981097897281294\n",
      "Game number 362 completed in 11806.54665851593 seconds with total loss 0.8063560776412487\n",
      "362 strategies were explored with an exploration rate of 0.5975119490160461\n",
      "Game number 363 completed in 11843.604437112808 seconds with total loss 0.7522359970957041\n",
      "363 strategies were explored with an exploration rate of 0.59679532890369\n",
      "Game number 364 completed in 11894.168604373932 seconds with total loss 0.8093683425337076\n",
      "364 strategies were explored with an exploration rate of 0.5958411721977422\n",
      "Game number 365 completed in 11921.665654182434 seconds with total loss 0.7709593709558249\n",
      "365 strategies were explored with an exploration rate of 0.5953051295955433\n",
      "Game number 366 completed in 11958.582862854004 seconds with total loss 0.6774082861840725\n",
      "366 strategies were explored with an exploration rate of 0.5945911562104764\n",
      "Game number 367 completed in 11987.708678007126 seconds with total loss 0.575472179055214\n",
      "367 strategies were explored with an exploration rate of 0.5940562381727651\n",
      "Game number 368 completed in 12020.000004053116 seconds with total loss 0.5375567026436329\n",
      "368 strategies were explored with an exploration rate of 0.5934624491886252\n",
      "Game number 369 completed in 12052.263475179672 seconds with total loss 0.5332766346633434\n",
      "369 strategies were explored with an exploration rate of 0.5928692537263357\n",
      "Game number 370 completed in 12089.109151363373 seconds with total loss 0.4152710258960724\n",
      "370 strategies were explored with an exploration rate of 0.5921582017851698\n",
      "Game number 371 completed in 12126.263388633728 seconds with total loss 0.422358026355505\n",
      "371 strategies were explored with an exploration rate of 0.5914480026371952\n",
      "Game number 372 completed in 12142.538903713226 seconds with total loss 0.4499740354716778\n",
      "372 strategies were explored with an exploration rate of 0.5911523377747628\n",
      "Game number 373 completed in 12188.64280629158 seconds with total loss 0.47414234541356565\n",
      "373 strategies were explored with an exploration rate of 0.5902662297091621\n",
      "Game number 374 completed in 12209.764843940735 seconds with total loss 0.3974374007433653\n",
      "374 strategies were explored with an exploration rate of 0.5898531672836168\n",
      "Game number 375 completed in 12252.925334453583 seconds with total loss 0.4264693884178996\n",
      "375 strategies were explored with an exploration rate of 0.5890279094011547\n",
      "Game number 376 completed in 12283.677253246307 seconds with total loss 0.4243908340111375\n",
      "376 strategies were explored with an exploration rate of 0.588439146483642\n",
      "Game number 377 completed in 12317.538440465927 seconds with total loss 0.4603058384731412\n",
      "377 strategies were explored with an exploration rate of 0.5877921869669678\n",
      "Game number 378 completed in 12367.99718427658 seconds with total loss 0.6060312429443002\n",
      "378 strategies were explored with an exploration rate of 0.5868524244893883\n",
      "Game number 379 completed in 12406.341452121735 seconds with total loss 0.5622745292261243\n",
      "379 strategies were explored with an exploration rate of 0.5861485887735229\n",
      "Game number 380 completed in 12429.678183555603 seconds with total loss 0.578541591949761\n",
      "380 strategies were explored with an exploration rate of 0.585738407832072\n",
      "Game number 381 completed in 12466.32385802269 seconds with total loss 0.6012583361938596\n",
      "381 strategies were explored with an exploration rate of 0.5850944176429536\n",
      "Game number 382 completed in 12484.405301570892 seconds with total loss 0.6520173417404294\n",
      "382 strategies were explored with an exploration rate of 0.5847434487448293\n",
      "Game number 383 completed in 12507.257711648941 seconds with total loss 0.6616101415827871\n",
      "383 strategies were explored with an exploration rate of 0.5843342511063683\n",
      "Game number 384 completed in 12546.999446630478 seconds with total loss 0.6858925091102719\n",
      "384 strategies were explored with an exploration rate of 0.5835750721935683\n",
      "Game number 385 completed in 12572.980978012085 seconds with total loss 0.7343536920845508\n",
      "385 strategies were explored with an exploration rate of 0.5831083755041576\n",
      "Game number 386 completed in 12591.04015493393 seconds with total loss 0.743788619339466\n",
      "386 strategies were explored with an exploration rate of 0.5827585979334502\n",
      "Game number 387 completed in 12618.431285381317 seconds with total loss 0.7120206207036972\n",
      "387 strategies were explored with an exploration rate of 0.5822343249394611\n",
      "Game number 388 completed in 12636.346881628036 seconds with total loss 0.5817873775959015\n",
      "388 strategies were explored with an exploration rate of 0.5818850716680024\n",
      "Game number 389 completed in 12668.508271217346 seconds with total loss 0.5843798078596592\n",
      "389 strategies were explored with an exploration rate of 0.5813034483748027\n",
      "Game number 390 completed in 12696.079335689545 seconds with total loss 0.566487605124712\n",
      "390 strategies were explored with an exploration rate of 0.5807804844916846\n",
      "Game number 391 completed in 12734.585390090942 seconds with total loss 0.5344685696065425\n",
      "391 strategies were explored with an exploration rate of 0.5800839310976714\n",
      "Game number 392 completed in 12776.061774492264 seconds with total loss 0.5667008630931377\n",
      "392 strategies were explored with an exploration rate of 0.5793302742868484\n",
      "Game number 393 completed in 12803.510469675064 seconds with total loss 0.5985134296119213\n",
      "393 strategies were explored with an exploration rate of 0.5788090855502327\n",
      "Game number 394 completed in 12837.332956552505 seconds with total loss 0.5680568501353264\n",
      "394 strategies were explored with an exploration rate of 0.5781727138056401\n",
      "Game number 395 completed in 12866.844850301743 seconds with total loss 0.5813484266400337\n",
      "395 strategies were explored with an exploration rate of 0.5776525664568328\n",
      "Game number 396 completed in 12904.660058259964 seconds with total loss 0.5925916828215122\n",
      "396 strategies were explored with an exploration rate of 0.5770174662473484\n",
      "Game number 397 completed in 12933.269969463348 seconds with total loss 0.631270008534193\n",
      "397 strategies were explored with an exploration rate of 0.5765560138069321\n",
      "Game number 398 completed in 12961.720797300339 seconds with total loss 0.7130078814923764\n",
      "398 strategies were explored with an exploration rate of 0.5760949303992873\n",
      "Game number 399 completed in 13026.172055482864 seconds with total loss 0.717966178059578\n",
      "399 strategies were explored with an exploration rate of 0.575058840479895\n",
      "Game number 400 completed in 13069.243807792664 seconds with total loss 0.7588163815438748\n",
      "400 strategies were explored with an exploration rate of 0.5743117123687411\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m d: \n\u001b[1;32m---> 17\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     s, r, d, m \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(a)\n\u001b[0;32m     20\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m index\n",
      "Cell \u001b[1;32mIn[167], line 43\u001b[0m, in \u001b[0;36mMinimax.choose_action\u001b[1;34m(self, env, test)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#self.evals = []\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining: \n\u001b[0;32m     46\u001b[0m     r \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[167], line 89\u001b[0m, in \u001b[0;36mMinimax.expand\u001b[1;34m(self, depth)\u001b[0m\n\u001b[0;32m     86\u001b[0m     s, r, d, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mstep(a)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d: info\u001b[38;5;241m.\u001b[39mappend((a, r))  \n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: info\u001b[38;5;241m.\u001b[39mappend((a, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m])) \n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mundo()\n\u001b[0;32m     93\u001b[0m _, reward \u001b[38;5;241m=\u001b[39m Minimax\u001b[38;5;241m.\u001b[39mplayer_to_exp[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mplayer](info, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[167], line 89\u001b[0m, in \u001b[0;36mMinimax.expand\u001b[1;34m(self, depth)\u001b[0m\n\u001b[0;32m     86\u001b[0m     s, r, d, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mstep(a)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d: info\u001b[38;5;241m.\u001b[39mappend((a, r))  \n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: info\u001b[38;5;241m.\u001b[39mappend((a, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m])) \n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mundo()\n\u001b[0;32m     93\u001b[0m _, reward \u001b[38;5;241m=\u001b[39m Minimax\u001b[38;5;241m.\u001b[39mplayer_to_exp[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mplayer](info, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[167], line 81\u001b[0m, in \u001b[0;36mMinimax.expand\u001b[1;34m(self, depth)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_search: \n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m info \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[167], line 64\u001b[0m, in \u001b[0;36mMinimax.evaluate\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):     \n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mvalue_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    555\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:510\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    493\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:667\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 667\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    671\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[0;32m    672\u001b[0m ):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py:241\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    237\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39membedding_lookup_sparse(\n\u001b[0;32m    238\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, ids, weights, combiner\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m         )\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtensordot(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, [[rank \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3714\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3711\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39mbatch_mat_mul_v3(\n\u001b[0;32m   3712\u001b[0m       a, b, adj_x\u001b[38;5;241m=\u001b[39madjoint_a, adj_y\u001b[38;5;241m=\u001b[39madjoint_b, Tout\u001b[38;5;241m=\u001b[39moutput_type, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   3713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3714\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3715\u001b[0m \u001b[43m      \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6012\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6011\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6012\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6013\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMatMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose_a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose_b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6014\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6016\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "agents = [Minimax(max_depth = 2), Minimax(max_depth = 2)]\n",
    "games = 500\n",
    "\n",
    "for g in range(1, games+1):\n",
    "    \n",
    "    env = BG()\n",
    "    s, r, d, m = env.reset()\n",
    "    \n",
    "    index = 0\n",
    "\n",
    "    while not d: \n",
    "        a = agents[index].choose_action(env)\n",
    "        s, r, d, m = env.step(a)\n",
    "\n",
    "        index = 1 - index\n",
    "        \n",
    "    agents[0].reset_metric()\n",
    "    agents[1].reset_metric()\n",
    "    \n",
    "    if g % 1 == 0: \n",
    "        l = (sum(agents[0].loss_h[-10:]) + sum(agents[1].loss_h[-10:]))/20\n",
    "        print(f\"Game number {g} completed in {time.time() - start} seconds with total loss {l}\")\n",
    "        print(f\"There was an exploration rate of {agents[0].epsilon} with a game length of {len(env.actions_taken)}\")\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: 400_game_3,6h_model\\assets\n"
     ]
    }
   ],
   "source": [
    "value_network.save(\"new_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43magents\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mloss_h\n\u001b[0;32m      2\u001b[0m x2 \u001b[38;5;241m=\u001b[39m agents[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mloss_h\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(x)), x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agents' is not defined"
     ]
    }
   ],
   "source": [
    "x = agents[0].loss_h\n",
    "x2 = agents[1].loss_h\n",
    "\n",
    "plt.plot(np.arange(len(x)), x)\n",
    "plt.plot(np.arange(len(x2)), x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "value_network = keras.models.load_model(\"400_game_3,6h_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.276), (17, 0.231), (7, 0.225)] [(37, -0.052), (33, -0.056), (42, -0.074)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gui = GUI() \n",
    "\n",
    "gui.connect_bots([RandomBot(), Minimax(max_depth = 3, max_search = 4000, training = False, debug = True)])\n",
    "gui.enable_competition()\n",
    "gui.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 games passed    \r",
      "2 games passed    \r",
      "3 games passed    \r",
      "4 games passed    \r",
      "5 games passed    \r",
      "6 games passed    \r",
      "7 games passed    \r",
      "8 games passed    \r",
      "9 games passed    \r",
      "10 games passed    \r",
      "11 games passed    \r",
      "12 games passed    \r",
      "13 games passed    \r",
      "14 games passed    \r",
      "15 games passed    \r",
      "16 games passed    \r",
      "17 games passed    \r",
      "18 games passed    \r",
      "19 games passed    \r",
      "20 games passed    \r",
      "21 games passed    \r",
      "22 games passed    \r",
      "23 games passed    \r",
      "24 games passed    \r",
      "25 games passed    \r",
      "26 games passed    \r",
      "27 games passed    \r",
      "28 games passed    \r",
      "29 games passed    \r",
      "30 games passed    \r",
      "31 games passed    \r",
      "32 games passed    \r",
      "33 games passed    \r",
      "34 games passed    \r",
      "35 games passed    \r",
      "36 games passed    \r",
      "37 games passed    \r",
      "38 games passed    \r",
      "39 games passed    \r",
      "40 games passed    \r",
      "41 games passed    \r",
      "42 games passed    \r",
      "43 games passed    \r",
      "44 games passed    \r",
      "45 games passed    \r",
      "46 games passed    \r",
      "47 games passed    \r",
      "48 games passed    \r",
      "49 games passed    \r",
      "50 games passed    \r",
      "51 games passed    \r",
      "52 games passed    \r",
      "53 games passed    \r",
      "54 games passed    \r",
      "55 games passed    \r",
      "56 games passed    \r",
      "57 games passed    \r",
      "58 games passed    \r",
      "59 games passed    \r",
      "60 games passed    \r",
      "61 games passed    \r",
      "62 games passed    \r",
      "63 games passed    \r",
      "64 games passed    \r",
      "65 games passed    \r",
      "66 games passed    \r",
      "67 games passed    \r",
      "68 games passed    \r",
      "69 games passed    \r",
      "70 games passed    \r",
      "71 games passed    \r",
      "72 games passed    \r",
      "73 games passed    \r",
      "74 games passed    \r",
      "75 games passed    \r",
      "76 games passed    \r",
      "77 games passed    \r",
      "78 games passed    \r",
      "79 games passed    \r",
      "80 games passed    \r",
      "81 games passed    \r",
      "82 games passed    \r",
      "83 games passed    \r",
      "84 games passed    \r",
      "85 games passed    \r",
      "86 games passed    \r",
      "87 games passed    \r",
      "88 games passed    \r",
      "89 games passed    \r",
      "90 games passed    \r",
      "91 games passed    \r",
      "92 games passed    \r",
      "93 games passed    \r",
      "94 games passed    \r",
      "95 games passed    \r",
      "96 games passed    \r",
      "97 games passed    \r",
      "98 games passed    \r",
      "99 games passed    \r",
      "100 games passed    \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[44, 0, 56]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate(n = 100):\n",
    "    env = BG()\n",
    "    \n",
    "    records = [0, 0, 0]\n",
    "    for _ in range(n):\n",
    "        s, r, d, m = env.reset()\n",
    "        \n",
    "        agents = [RandomBot(), RandomBot()]\n",
    "        #agents = [Minimax(max_depth = 1, debug = False, training = False, explore = False), RandomBot()] \n",
    "        #agents = [RandomBot(), Minimax(max_depth = 1, debug = False, training = False, explore = False)]\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        while not d: \n",
    "            a = agents[index].choose_action(env)\n",
    "            s, r, d, m = env.step(a)\n",
    "\n",
    "            index = 1 - index\n",
    "\n",
    "        records[int(2 * r)] += 1\n",
    "        print(f\"{_+1} games passed    \", end = '\\r')\n",
    "    return records\n",
    "    \n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BG()\n",
    "    \n",
    "agents = [RandomBot(), RandomBot()]\n",
    "index = 0\n",
    "\n",
    "s, r, d, m = env.reset()\n",
    "while not d: \n",
    "    a = agents[index].choose_action(env)\n",
    "    s, r, d, m = env.step(a)\n",
    "\n",
    "    index = 1 - index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.0), (6, 0.0), (16, 0.0)] [(9, 1.0), (14, 1.0), (57, 1.0)] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot = Minimax(max_depth = 2, debug = True, training = False, explore = False)\n",
    "bot.choose_action(env, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.undo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O|O|O| \n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X| |X|X\n",
      "-------\n",
      "X|X| |X\n",
      "\n",
      "=======\n",
      "\n",
      " | |X|X\n",
      "-------\n",
      " |O| | \n",
      "-------\n",
      " |O|O| \n",
      "-------\n",
      "X|O|O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X| |O\n",
      "-------\n",
      " |O| | \n",
      "-------\n",
      "O|X|X|O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| | \n",
      "-------\n",
      "O| |X| \n",
      "-------\n",
      "X| |X|X\n",
      "-------\n",
      "O|O|O| \n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot = Minimax(max_depth = 1, debug = False, training = False, explore = False)\n",
    "\n",
    "bot.choose_action(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui = GUI()\n",
    "gui.game = env\n",
    "gui.illustrator.bg = env\n",
    "\n",
    "gui.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env.undo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X| \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X| \n",
      "\n",
      "=======\n",
      "\n",
      " |O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X| \n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X| \n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | |X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      "X| | |X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| | |X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O| \n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      " |X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X| \n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X|X\n",
      "-------\n",
      " | |O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| | |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X|X\n",
      "-------\n",
      " |O|O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O|X| |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X|X\n",
      "-------\n",
      " |O|O|O\n",
      "-------\n",
      "X| | |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O|X| |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X|X\n",
      "-------\n",
      " |O|O|O\n",
      "-------\n",
      "X|O| |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " |X|X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O|X| |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X|X\n",
      "-------\n",
      " |O|O|O\n",
      "-------\n",
      "X|O| |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      " |X|X|O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O|X| |X\n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " |X|X|X\n",
      "-------\n",
      " |O|O|O\n",
      "-------\n",
      "X|O| |O\n",
      "-------\n",
      "X|O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "O|X| |X\n",
      "-------\n",
      "X| |O|X\n",
      "-------\n",
      " |O| |O\n",
      "-------\n",
      " | |X|X\n",
      "\n",
      "=======\n",
      "\n",
      "X|O| | \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | |O\n",
      "\n",
      "\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "env = BG()\n",
    "\n",
    "s, r, d, m = env.reset()\n",
    "\n",
    "agents = [RandomBot(), RandomBot()]\n",
    "index = 0 \n",
    "\n",
    "while not d: \n",
    "    a = agents[index].choose_action(env, test = True)\n",
    "    s, r, d, m = env.step(a)\n",
    "\n",
    "    env.render()\n",
    "    print()\n",
    "    index = 1 - index\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X|O| |X\n",
      "-------\n",
      " |O|O|X\n",
      "-------\n",
      " |X|X|O\n",
      "-------\n",
      " |O|X|O\n",
      "\n",
      "=======\n",
      "\n",
      "X|O|O|X\n",
      "-------\n",
      " |X|X|O\n",
      "-------\n",
      "O|O| | \n",
      "-------\n",
      "X|O| | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |O| |X\n",
      "-------\n",
      " |X| |X\n",
      "-------\n",
      "O| | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN\n",
      "[61, 63]\n",
      "[(2, 1.0), (4, -0.36423319578170776), (8, 1.0), (12, -0.32946106791496277), (20, 1.0), (26, 1.0), (27, 1.0), (30, -0.3352173864841461), (31, 1.0), (32, 1.0), (33, 1.0), (34, -0.3320755958557129), (35, 1.0), (36, -0.334259957075119), (38, 1.0), (40, 1.0), (42, 1.0), (45, -0.334259957075119), (46, 1.0), (47, -0.3338382840156555), (48, 1.0), (49, -0.334259957075119), (50, 1.0), (51, -0.32777732610702515), (52, 1.0), (53, -0.3293707072734833), (54, 1.0), (55, -0.3150988221168518), (56, 1.0), (57, -0.33156096935272217), (59, 1.0), (60, 1.0), (61, -0.3919256031513214), (62, 1.0), (63, -0.3919256031513214)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot = Minimax(-1, max_depth = 2, debug = True)\n",
    "bot.choose_action(env, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58,\n",
       " 1,\n",
       " 0,\n",
       " 44,\n",
       " 7,\n",
       " 29,\n",
       " 3,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 14,\n",
       " 23,\n",
       " 19,\n",
       " 24,\n",
       " 28,\n",
       " 25,\n",
       " 16,\n",
       " 11,\n",
       " 9,\n",
       " 37,\n",
       " 41,\n",
       " 13,\n",
       " 43,\n",
       " 15,\n",
       " 39,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 22]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.actions_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.18240757]], dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_network(env.game_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.undo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58,\n",
       " 5,\n",
       " 18,\n",
       " 17,\n",
       " 63,\n",
       " 38,\n",
       " 33,\n",
       " 41,\n",
       " 62,\n",
       " 30,\n",
       " 6,\n",
       " 61,\n",
       " 45,\n",
       " 39,\n",
       " 7,\n",
       " 51,\n",
       " 12,\n",
       " 47,\n",
       " 20,\n",
       " 15,\n",
       " 35,\n",
       " 25,\n",
       " 0,\n",
       " 48,\n",
       " 16,\n",
       " 19,\n",
       " 29,\n",
       " 40,\n",
       " 55,\n",
       " 1,\n",
       " 4,\n",
       " 10,\n",
       " 60,\n",
       " 2,\n",
       " 36,\n",
       " 44,\n",
       " 43,\n",
       " 27]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.actions_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[47331, 1, 52668]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate(n=1000):\n",
    "\n",
    "    env = BG()\n",
    "    tallies = [0, 0, 0]\n",
    "    \n",
    "    for x in range(n):\n",
    "    \n",
    "        s, r, d, m = env.reset()\n",
    "\n",
    "        agents = [RandomBot(), RandomBot()]\n",
    "        index = 0 \n",
    "\n",
    "        while not d: \n",
    "            a = agents[index].choose_action(env)\n",
    "            s, r, d, m = env.step(a)\n",
    "\n",
    "            #env.render()\n",
    "            #print()\n",
    "            index = 1 - index\n",
    "\n",
    "        #print(_)\n",
    "        \n",
    "        tallies[int(r) + 1] += 1\n",
    "    \n",
    "    return tallies\n",
    "        \n",
    "simulate(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 5, 10, 15], [3, 6, 9, 12], [0, 17, 34, 51], [3, 18, 33, 48], [0, 20, 40, 60], [48, 36, 24, 12], [48, 53, 58, 63], [51, 54, 57, 60], [12, 29, 46, 63], [15, 30, 45, 60], [3, 23, 43, 63], [51, 39, 27, 15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 21, 42, 63], [48, 37, 26, 15], [3, 22, 41, 60], [12, 25, 38, 51]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert(p):\n",
    "    return p // 16, (p % 16) // 4, p % 4\n",
    "\n",
    "def unconvert(i, j, k):\n",
    "    return 16 * i + 4 * j + k\n",
    "\n",
    "\n",
    "diags = {}\n",
    "\n",
    "for i in range(4):\n",
    "    diags[i] = [[unconvert(i, j, j) for j in range(4)], [unconvert(i, j, 3-j) for j in range(4)]]\n",
    "       \n",
    "for i in range(4):\n",
    "    diags[4+i] = [[unconvert(j, i, j) for j in range(4)], [unconvert(j, i, 3-j) for j in range(4)]]\n",
    "    \n",
    "for i in range(4):\n",
    "    diags[8+i] = [[unconvert(j, j, i) for j in range(4)], [unconvert(j, 3-j, i) for j in range(4)]]\n",
    "\n",
    "    \n",
    "space_diags = []\n",
    "space_diags.append([unconvert(i, i, i) for i in range(4)])\n",
    "space_diags.append([unconvert(3-i, i, i) for i in range(4)])\n",
    "space_diags.append([unconvert(i, i, 3-i) for i in range(4)])\n",
    "space_diags.append([unconvert(i, 3-i, i) for i in range(4)])\n",
    "space_diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game speed Test\n",
    "\n",
    "The percentage of time spent in evaluation must be over 90% to indicate that our game is fast enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2429416179656982\n",
      "560\n",
      "1.1324031352996826\n",
      "560\n",
      "0.9110670355966259\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "env = BG()\n",
    "bot = Minimax(max_depth = 2, debug = False) #Make sure the bot.eval lines are commented back in inside the Minimax class\n",
    "bot.choose_action(env, test = True)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "bot.choose_action(env, test = True)\n",
    "\n",
    "tot_time = time.time() - start\n",
    "\n",
    "print(tot_time)\n",
    "print(bot.checked)\n",
    "print(sum(bot.evals))\n",
    "print(len(bot.evals))\n",
    "print(sum(bot.evals) / tot_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002989530563354492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.evals[0] #2ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([10,20,30])\n",
    "b = np.array([2, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52655377, 0.37232974, 0.30400596])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * np.sqrt(np.log(2) / a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def default_policy(env):\n",
    "    log_probs = tf.expand_dims(tf.math.log(env.mask), axis = 0)\n",
    "    return tf.random.categorical(log_probs, 1)[0, 0].numpy()\n",
    "\n",
    "e = BG()\n",
    "\n",
    "a = default_policy(e)\n",
    "s, r, d, m = e.step(a)   \n",
    "while not d: \n",
    "    a = default_policy(e)\n",
    "    s, r, d, m = e.step(a)\n",
    "    \n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O|X| |O\n",
      "-------\n",
      "O| |O|O\n",
      "-------\n",
      "O| | |O\n",
      "-------\n",
      " |O|X| \n",
      "\n",
      "=======\n",
      "\n",
      "X| |O|O\n",
      "-------\n",
      " |O| |X\n",
      "-------\n",
      "X|X|X|X\n",
      "-------\n",
      "X|X|O| \n",
      "\n",
      "=======\n",
      "\n",
      "X|X| |X\n",
      "-------\n",
      "X|X|O| \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      "X|O| |X\n",
      "\n",
      "=======\n",
      "\n",
      "O|O|O| \n",
      "-------\n",
      "O|O| |X\n",
      "-------\n",
      "X| |X| \n",
      "-------\n",
      "O|O|X| \n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = env.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([0,0,0,0,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.where(mask == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problems with current design: \n",
    "\n",
    "1) Mask double maintained in Node and game - large storage cost for Nodes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Selection -> Need UCB of ALL child nodes, need actual nodes as well\n",
    "# Expansion -> Need to randomly pick unexplored nodes + create node \n",
    "# Simulation -> Just need environment, simulation simple\n",
    "# Backup -> Recurse backwards to update the values of nodes selected\n",
    "\n",
    "\"\"\"\n",
    "State \n",
    "-> Keep track of UCB + node object of child nodes (split mean and UCB because for max add but min subtract)\n",
    "-> Unexplored mask \n",
    "-> Parent responsible for updating child's UCB\n",
    "-> Note whether is a min or max node \n",
    "\n",
    "Fast - Could create a list of tuples of Nodes and information in MCTS and then go thru list to backup\n",
    "Overhead - Use Publisher - Subscriber Pattern to update all nodes once game result is reached \n",
    "\"\"\"\n",
    "\n",
    "class UCBState:\n",
    "        \n",
    "    def __init__(self, mask):\n",
    "        self.unexplored = mask.copy()\n",
    "        self.action_to_node = [None] * ACTION_SPACE # Indicies represent possible actions\n",
    "\n",
    "        self.N = 0\n",
    "        self.n = np.zeros(64)\n",
    "        self.wins = np.zeros(64)\n",
    "      \n",
    "    @property\n",
    "    def is_unexplored(self):\n",
    "        return self.unexplored.sum() > 0\n",
    "    \n",
    "    def update_explore(self, action, node):\n",
    "        #print(\"CALLED\")\n",
    "        self.unexplored[action] = 0\n",
    "        self.action_to_node[action] = node\n",
    "    \n",
    "    def update_values(self, action, result):\n",
    "        self.N += 1\n",
    "        self.n[action] += 1 \n",
    "        self.wins[action] += result        \n",
    "\n",
    "class MCTS:\n",
    "        \n",
    "    def __init__(self, num_rollouts = 20, c = 0.2):\n",
    "        self.e = BG()\n",
    "        self.reset_search()\n",
    "        \n",
    "        self.num_rollouts = num_rollouts\n",
    "        self.c = c\n",
    "        \n",
    "        self.def_time = 0\n",
    "        self.tree_time = 0\n",
    "        self.expand_time = 0\n",
    "        self.select_time = 0\n",
    "        self.simulate_time = 0\n",
    "        \n",
    "    def times(self):\n",
    "        return [self.def_time, self.tree_time, self.expand_time, self.select_time, self.simulate_time]\n",
    "\n",
    "    def default_policy(self, mask = None): # Used during expansion and simulation\n",
    "        \n",
    "        s = time.time()\n",
    "        \n",
    "        if mask is None: \n",
    "            mask = self.e.mask\n",
    "            \n",
    "            \n",
    "        #log_probs = tf.expand_dims(tf.math.log(mask), axis = 0)\n",
    "        #ans = tf.random.categorical(log_probs, 1)[0, 0].numpy()\n",
    "        ans = np.random.choice(np.where(mask == 1)[0])\n",
    "        \n",
    "        self.def_time += time.time() - s\n",
    "        return ans\n",
    "    \n",
    "    def tree_policy(self, node, test = False, debug = False): \n",
    "        # Certain counts will just be 0 (illegal actions and unexplored actions); so only use counts > 0\n",
    "        s = time.time()\n",
    "        \n",
    "        usable = node.n.nonzero()[0]\n",
    "\n",
    "        wins, n = node.wins[usable], node.n[usable]\n",
    "\n",
    "        ucb = wins / n\n",
    "        if not test: ucb += self.c * np.sqrt(2) * np.sqrt(np.log(node.N) / n) * self.e.player # Subtract if argmin \n",
    "\n",
    "        ucb *= self.e.player\n",
    "        \n",
    "        chosen_ucb_idx = np.random.choice(np.where(ucb == ucb.max())[0])\n",
    "        ans = usable[chosen_ucb_idx] \n",
    "        \n",
    "        if debug:\n",
    "            print(ucb)\n",
    "            print(self.e.player)\n",
    "            print(sum(node.n))\n",
    "        \n",
    "        self.tree_time += time.time() - s\n",
    "        return ans\n",
    "    \n",
    "    def choose_action(self, env, test = False):\n",
    "        \n",
    "        root = self.next_node \n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for action in env.actions_taken:\n",
    "            if root.action_to_node[action] is not None: \n",
    "                root = root.action_to_node[action]\n",
    "            else: \n",
    "                #print(\"CREaTING NEW ACTION\")\n",
    "                node = UCBState(env.get_internal()['mask'])\n",
    "                root.update_explore(action, node)\n",
    "                root = node        \n",
    "\n",
    "        for _ in range(self.num_rollouts):\n",
    "            \n",
    "            self.e.set_internal(env.get_internal())\n",
    "            backup = []\n",
    "            cur = root\n",
    "                \n",
    "            cur, r, d = self.select(cur, backup) \n",
    "            \n",
    "            if not d: \n",
    "                r, d = self.expand(cur, backup)\n",
    "                r = self.simulate(r, d)\n",
    "                \n",
    "            self.backup_tree(backup, r)\n",
    "            \n",
    "        self.e.set_internal(env.get_internal())\n",
    "            \n",
    "        a = self.tree_policy(root, test)\n",
    "        return a\n",
    "                \n",
    "    def select(self, cur, backup):\n",
    "        \n",
    "        sta = time.time()\n",
    "        \n",
    "        r, d = -1, False\n",
    "        \n",
    "        while cur is not None and not cur.is_unexplored:\n",
    "            a = self.tree_policy(cur)\n",
    "            backup.append((cur, a))\n",
    "            cur = cur.action_to_node[a]     # Will be None if action leads to terminal state\n",
    "            s, r, d, m = self.e.step(a)     # If d is true, cur should be None (simulate should have not created a node)\n",
    "                \n",
    "        ans = cur, r, d\n",
    "        self.select_time += time.time() - sta\n",
    "        \n",
    "        return ans\n",
    "    \n",
    "    def expand(self, cur, backup):\n",
    "        \n",
    "        sta = time.time()\n",
    "\n",
    "        a = self.default_policy(cur.unexplored) \n",
    "        s, r, d, m = self.e.step(a) \n",
    "        \n",
    "        backup.append((cur, a))\n",
    "        \n",
    "        if d: cur.unexplored[a] = 0\n",
    "        else: cur.update_explore(a, UCBState(self.e.mask))\n",
    "            \n",
    "        ans = r, d\n",
    "        \n",
    "        self.expand_time += time.time() - sta\n",
    "        return ans\n",
    "            \n",
    "    def simulate(self, r, d):\n",
    "        \n",
    "        sta = time.time()\n",
    "        \n",
    "        while not d: \n",
    "            a = self.default_policy()\n",
    "            s, r, d, m = self.e.step(a)\n",
    "              \n",
    "        self.simulate_time += time.time() - sta\n",
    "                \n",
    "        return r\n",
    "    \n",
    "    def backup_tree(self, backup, r):\n",
    "        for node, action in backup: \n",
    "            node.update_values(action, r)\n",
    "            \n",
    "    def reset_search(self):\n",
    "        mask = self.e.get_internal()['mask'].copy()\n",
    "        self.next_node = UCBState(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_node(node, counter = 0): \n",
    "    counter += 1\n",
    "    \n",
    "    for t in node.action_to_node:\n",
    "        if t is not None: \n",
    "            counter = get_depth_node(t, counter)\n",
    "            \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_depth_node(agents[1].next_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_depth_node(agents[1].next_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 games passed with a reward of 1.0   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 0, 8]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate(n = 10):\n",
    "    env = BG()\n",
    "    \n",
    "    records = [0, 0, 0]\n",
    "    for _ in range(n):\n",
    "        s, r, d, m = env.reset()\n",
    "        \n",
    "        agents = [MCTS(5000, 0), MCTS(5000, 0.15)]\n",
    "        #agents = [Minimax(max_depth = 1, debug = False, training = False, explore = False), RandomBot()] \n",
    "        #agents = [RandomBot(), Minimax(max_depth = 1, debug = False, training = False, explore = False)]\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        while not d: \n",
    "            a = agents[index].choose_action(env)\n",
    "            s, r, d, m = env.step(a)\n",
    "\n",
    "            index = 1 - index\n",
    "        \n",
    "        reward_to_index = {0 : 2, 0.5: 1, 1: 0} # Player 1 is index 0 \n",
    "        records[reward_to_index[r]] += 1\n",
    "        print(f\"{_+1} games passed with a reward of {r}   \", end = '\\r')\n",
    "    return records\n",
    "    \n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREaTING NEW ACTION\n",
      "[-0.62745098 -0.50617284 -0.5        -0.53424658 -0.64       -0.5625\n",
      " -0.5862069  -0.51282051 -0.58333333 -0.47311828 -0.64       -0.5625\n",
      " -0.5        -0.49411765 -0.48351648 -0.45631068 -0.52702703 -0.51282051\n",
      " -0.48314607 -0.4375     -0.50617284 -0.57142857 -0.49411765 -0.46464646\n",
      " -0.51282051 -0.60714286 -0.49425287 -0.7        -0.5625     -0.48863636\n",
      " -0.49411765 -0.65217391 -0.50617284 -0.61111111 -0.48863636 -0.44761905\n",
      " -0.61111111 -0.46       -0.57142857 -0.43478261 -0.52702703 -0.46391753\n",
      " -0.59649123 -0.55223881 -0.64       -0.57894737 -0.5625     -0.41085271\n",
      " -0.57377049 -0.44144144 -0.43362832 -0.47311828 -0.44761905 -0.42735043\n",
      " -0.51282051 -0.64       -0.5        -0.4375     -0.48863636 -0.5\n",
      " -0.5        -0.45544554 -0.52702703]\n",
      "-1.0\n",
      "5000.0\n"
     ]
    }
   ],
   "source": [
    "env = BG()\n",
    "\n",
    "s, r, d, m = env.reset()\n",
    "\n",
    "agents = [RandomBot(), MCTS(5000)]\n",
    "index = 0 \n",
    "\n",
    "a = agents[0].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)\n",
    "\n",
    "a = agents[1].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50574713 -0.55714286 -0.65957447 -0.51807229 -0.65306122 -0.53947368\n",
      " -0.45454545 -0.6        -0.42857143 -0.54929577 -0.59016393 -0.54054054\n",
      " -0.4893617  -0.54054054 -0.47916667 -0.47916667 -0.51807229 -0.525\n",
      " -0.51807229 -0.53246753 -0.50588235 -0.65957447 -0.4587156  -0.421875\n",
      " -0.44444444 -0.6        -0.65957447 -0.48913043 -0.53246753 -0.49450549\n",
      " -0.578125   -0.55882353 -0.53947368 -0.54929577 -0.525      -0.51190476\n",
      " -0.50588235 -0.58730159 -0.65306122 -0.50574713 -0.54794521 -0.63461538\n",
      " -0.56923077 -0.54929577 -0.4893617  -0.50588235 -0.48421053 -0.45794393\n",
      " -0.50588235 -0.51190476 -0.48351648 -0.44444444 -0.54929577 -0.65306122\n",
      " -0.47916667 -0.48913043 -0.53246753 -0.42857143 -0.54794521 -0.45454545\n",
      " -0.45045045]\n",
      "-1.0\n",
      "5001.0\n"
     ]
    }
   ],
   "source": [
    "a = agents[1].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 48, 24, 25]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.actions_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.798228979110718,\n",
       " 0.5081002712249756,\n",
       " 0.665541410446167,\n",
       " 1.222064733505249,\n",
       " 16.888139247894287]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[1].times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREaTING NEW ACTION\n",
      "[0.69230769 0.64285714 0.38461538 0.5625     0.81818182 0.75\n",
      " 0.37037037 0.69230769 0.6        0.47619048 0.47619048 0.64285714\n",
      " 0.45454545 0.4        0.45454545 0.5        0.45454545 0.5625\n",
      " 0.5        0.41666667 0.69230769 0.47619048 0.5        0.47619048\n",
      " 0.5        0.5        0.55555556 0.64285714 0.69230769 0.5\n",
      " 0.45454545 0.81818182 0.75       0.27777778 0.5625     0.47619048\n",
      " 0.41666667 0.47619048 0.45454545 0.45454545 0.45454545 0.52631579\n",
      " 0.75       0.52941176 0.47619048 0.47619048 0.5625     0.45454545\n",
      " 0.52631579 0.69230769 0.45454545 0.52631579 0.5625    ]\n",
      "1.0\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "a = agents[0].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)\n",
    "\n",
    "a = agents[1].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2647345337.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[343], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.tree_time = 0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "self.def_time = 0\n",
    "        self.tree_time = 0\n",
    "        self.expand_time = 0\n",
    "        self.select_time = 0\n",
    "        self.simulate_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5300107002258301,\n",
       " 0.03822779655456543,\n",
       " 0.08184623718261719,\n",
       " 0.0726308822631836,\n",
       " 1.621001958847046]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[1].times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.n[[usable]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable = node.n.nonzero()[0]\n",
    "\n",
    "wins, n = node.wins[[usable]], node.n[[usable]]\n",
    "\n",
    "ucb = wins / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 2., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucb = ucb * - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4, 10, 11, 13, 20, 23, 24, 31, 34, 42, 43, 47, 49, 50, 59, 60,\n",
       "       61], dtype=int64)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCTS 3.0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(ucb == ucb.max())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.where(ucb == ucb.max())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[0.  1.  0.  1.  0.5 1.  0.  1.  0.5 0.5 1.  1.  1.  0.  1.  0.5 0.5 1.\n",
      " 0.  1.  1.  0.5 1.  0.5 0.5 1.  1.  1.  0.5 0.5 0.5 0.  1.  0.  1.  1.\n",
      " 0.  1.  1.  1.  0.5 1.  0.5 0.5 0.5 1.  1.  0.  0.  1.  1.  0.5 1.  0.5\n",
      " 0.5 0.5 1.  1.  1.  0.5 0.  1.  0.5]\n",
      "1.0\n",
      "100.0\n",
      "58\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      "37\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " | | | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[1.         1.         0.5        1.         0.5        1.\n",
      " 1.         1.         0.5        0.5        0.5        1.\n",
      " 0.         1.         1.         0.5        0.5        1.\n",
      " 0.5        1.         0.33333333 0.5        1.         0.5\n",
      " 0.5        1.         0.         1.         0.5        0.\n",
      " 1.         1.         0.5        0.         1.         1.\n",
      " 1.         1.         0.5        1.         0.33333333 1.\n",
      " 0.         1.         0.5        0.5        1.         0.\n",
      " 1.         0.33333333 0.33333333 0.         0.5        1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n",
      "1.0\n",
      "100.0\n",
      "61\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "2\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[0.         0.5        0.5        0.33333333 0.5        1.\n",
      " 1.         0.5        0.5        0.33333333 0.5        0.5\n",
      " 1.         0.33333333 1.         1.         0.5        0.5\n",
      " 0.5        1.         1.         1.         1.         0.5\n",
      " 0.5        0.5        0.         0.5        0.5        0.\n",
      " 0.5        0.5        1.         1.         0.33333333 0.33333333\n",
      " 1.         1.         1.         1.         1.         0.5\n",
      " 1.         1.         1.         1.         1.         0.5\n",
      " 1.         1.         1.         1.         0.         0.5\n",
      " 1.         0.33333333 1.         0.5        1.        ]\n",
      "1.0\n",
      "100.0\n",
      "46\n",
      " | |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | |O| \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "0\n",
      "X| |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | |O| \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[-1.         -1.         -1.         -0.5        -1.         -1.\n",
      " -0.5        -1.         -0.5        -0.5        -1.         -0.5\n",
      " -0.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -0.5        -1.         -1.         -0.5        -1.\n",
      " -1.         -1.         -0.         -0.5        -1.         -0.33333333\n",
      " -1.         -1.         -0.33333333 -1.         -0.         -0.33333333\n",
      " -1.         -1.         -0.         -1.         -0.33333333 -0.\n",
      " -1.         -0.33333333 -0.5        -0.5        -1.         -0.33333333\n",
      " -1.         -1.         -0.5        -0.33333333 -0.33333333 -1.\n",
      " -1.         -0.33333333 -1.        ]\n",
      "-1.0\n",
      "100.0\n",
      "44\n",
      "X| |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| |O| \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "47\n",
      "X| |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[0.33333333 0.5        1.         1.         0.33333333 0.33333333\n",
      " 0.5        1.         0.5        1.         1.         0.5\n",
      " 1.         1.         1.         0.5        0.         1.\n",
      " 0.33333333 1.         0.5        1.         1.         1.\n",
      " 1.         0.5        0.5        0.5        0.5        1.\n",
      " 0.33333333 1.         0.5        1.         0.33333333 1.\n",
      " 1.         1.         1.         1.         0.5        0.5\n",
      " 0.33333333 0.5        1.         1.         0.5        0.5\n",
      " 0.         1.         0.5        1.         1.         0.33333333\n",
      " 0.5       ]\n",
      "1.0\n",
      "100.0\n",
      "51\n",
      "X| |X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "1\n",
      "X|X|X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X| | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[-1.         -0.5        -1.         -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      " -0.5        -0.5        -1.         -1.         -0.5        -0.5\n",
      " -0.5        -0.5        -0.5        -0.5        -1.         -0.5\n",
      " -0.5        -0.5        -0.33333333 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -0.5        -0.         -1.\n",
      " -1.         -1.         -1.         -0.5        -1.         -1.\n",
      " -0.5        -1.         -0.5        -1.         -1.         -1.\n",
      " -0.5        -1.         -0.5        -0.5        -0.33333333]\n",
      "-1.0\n",
      "100.0\n",
      "38\n",
      "X|X|X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "40\n",
      "X|X|X| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "[0.5        0.5        0.5        1.         1.         1.\n",
      " 0.5        0.5        1.         0.5        0.5        0.5\n",
      " 0.5        1.         0.5        0.5        0.5        0.5\n",
      " 0.         1.         1.         1.         0.5        0.5\n",
      " 0.5        0.5        0.5        0.33333333 0.5        1.\n",
      " 1.         1.         1.         0.5        1.         0.5\n",
      " 1.         0.5        0.5        1.         0.5        0.5\n",
      " 0.5        0.5        1.         0.5        0.5        0.\n",
      " 1.         1.         0.5       ]\n",
      "1.0\n",
      "100.0\n",
      "6\n",
      "X|X|X| \n",
      "-------\n",
      " | |O| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "33\n",
      "X|X|X| \n",
      "-------\n",
      " | |O| \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n",
      "[-1.         -0.5        -1.         -0.5        -1.         -0.5\n",
      " -0.5        -0.         -1.         -0.33333333 -0.         -1.\n",
      " -0.5        -0.5        -0.         -1.         -0.5        -1.\n",
      " -0.5        -0.5        -0.5        -0.5        -1.         -1.\n",
      " -1.         -1.         -1.         -0.5        -1.         -0.33333333\n",
      " -0.33333333 -0.33333333 -0.         -0.5        -0.33333333 -0.5\n",
      " -1.         -1.         -1.         -0.5        -1.         -1.\n",
      " -1.         -0.33333333 -1.         -0.5        -1.         -0.5\n",
      " -0.        ]\n",
      "-1.0\n",
      "100.0\n",
      "11\n",
      "X|X|X| \n",
      "-------\n",
      " | |O| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "23\n",
      "X|X|X| \n",
      "-------\n",
      " | |O| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "CREaTING NEW ACTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -1.         -0.         -1.         -0.5        -0.33333333\n",
      " -0.5        -1.         -0.5        -1.         -0.5        -0.5\n",
      " -0.5        -1.         -1.         -0.5        -1.         -1.\n",
      " -0.5        -0.33333333 -0.5        -0.5        -0.5        -0.5\n",
      " -1.         -0.5        -1.         -0.5        -0.5        -1.\n",
      " -1.         -1.         -0.33333333 -0.33333333 -0.5        -0.\n",
      " -0.5        -0.5        -0.5        -0.5        -0.5        -1.\n",
      " -1.         -0.5        -1.         -1.         -0.        ]\n",
      "-1.0\n",
      "100.0\n",
      "5\n",
      "X|X|X| \n",
      "-------\n",
      " |O|O| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "3\n",
      "X|X|X|X\n",
      "-------\n",
      " |O|O| \n",
      "-------\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " | | | \n",
      "-------\n",
      " | | |X\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " | | | \n",
      "\n",
      "=======\n",
      "\n",
      " |X| | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      "X| | | \n",
      "-------\n",
      "O| |O|X\n",
      "\n",
      "=======\n",
      "\n",
      " | | |O\n",
      "-------\n",
      " | | | \n",
      "-------\n",
      " |X|O| \n",
      "-------\n",
      " |O| | \n",
      "\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "env = BG()\n",
    "\n",
    "s, r, d, m = env.reset()\n",
    "\n",
    "agents = [RandomBot(), MCTS(num_rollouts = 100)]\n",
    "index = 0 \n",
    "\n",
    "while not d: \n",
    "    a = agents[index].choose_action(env, test = True)\n",
    "    s, r, d, m = env.step(a)\n",
    "\n",
    "    print(a)\n",
    "    env.render()\n",
    "    print()\n",
    "    index = 1 - index\n",
    "    \n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREaTING NEW ACTION\n",
      "[0.64285714 0.64285714 0.42857143 0.52941176 0.5625     0.52941176\n",
      " 0.5625     0.75       0.47368421 0.75       0.6        0.45\n",
      " 0.47368421 0.8        0.6        0.45       0.75       0.8\n",
      " 0.69230769 0.52941176 0.5        0.47368421 0.52941176 0.41666667\n",
      " 0.5625     0.39130435 0.52941176 0.5625     0.47368421 0.8\n",
      " 0.5625     0.8        0.47368421 0.45       0.5625     0.6\n",
      " 0.47368421 0.42857143 0.8        0.42857143 0.75       0.64285714\n",
      " 0.69230769 0.47368421 0.64285714 1.         0.8        0.64285714\n",
      " 0.5        0.45       0.69230769 0.5        0.88888889 0.4\n",
      " 0.64285714 0.8        0.6        0.5625     0.8        0.4\n",
      " 0.64285714 0.52941176 0.52941176]\n",
      "1.0\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "env = BG()\n",
    "\n",
    "s, r, d, m = env.reset()\n",
    "\n",
    "agents = [RandomBot(), MCTS(1000)]\n",
    "index = 0 \n",
    "\n",
    "a = agents[0].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)\n",
    "\n",
    "a = agents[1].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable = node.n.nonzero()[0]\n",
    "\n",
    "wins, n = node.wins[[usable]], node.n[[usable]]\n",
    "\n",
    "ucb = wins / n\n",
    "#if not test: ucb += node.c * np.sqrt(2) * np.sqrt(np.log(node.N) / n) * self.e.player # Subtract if argmin \n",
    "\n",
    "ucb *= -1\n",
    "ucb\n",
    "\n",
    "usable[np.argmax(ucb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  4, 10, 11, 13, 20, 23, 24, 31, 34, 42, 43, 47, 49, 50, 59, 60,\n",
       "        61], dtype=int64),)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 2., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 2., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating for action,  40\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  17 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  38 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  61 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  24 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  42 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  15 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  32 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  31 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  56 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  54 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  21 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  46 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  9 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  16 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  44 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  51 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  57 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  5 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  0 WITH NODE  MCTS 4.0\n",
      "CALLED\n",
      "NEWW EXPAND ==================================== MCTS 3.0\n",
      "ADDING TO MCTS 3.0 FOR ACTION  26 WITH NODE  MCTS 4.0\n",
      "CALLED\n"
     ]
    }
   ],
   "source": [
    "a = agents[0].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)\n",
    "\n",
    "a = agents[1].choose_action(env, test = True)\n",
    "s, r, d, m = env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 8, 40, 1]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.actions_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " MCTS 4.0,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " MCTS 4.0,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[1].next_node.action_to_node[18].action_to_node[8].action_to_node[40].action_to_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[1].tree_policy(agents[1].next_node.action_to_node[18].action_to_node[8].action_to_node[40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCTS 3.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = agents[1].next_node.action_to_node[15].action_to_node[56].action_to_node[17]\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(array([ 2,  4, 10, 11, 13, 23, 24, 42, 43, 49, 60], dtype=int64),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = agents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 0, 35]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.actions_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.UCBState at 0x1d9a1584970>,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " <__main__.UCBState at 0x1d9a1584ee0>,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.next_node.action_to_node[31].action_to_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[87], line 93\u001b[0m, in \u001b[0;36mMCTS.choose_action\u001b[1;34m(self, env, test)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m d: \n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(d)\n\u001b[0;32m     95\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate(cur, backup)       \n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackup_tree(backup, r)\n",
      "\u001b[1;31mValueError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "agents[1].choose_action(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MCTS()\n",
    "m.default_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui = GUI() \n",
    "\n",
    "gui.connect_bots([RandomBot(), MCTS(5000, 0.15)])\n",
    "gui.main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.951217889785767,\n",
       " 3.8535499572753906,\n",
       " 4.175041913986206,\n",
       " 8.74736213684082,\n",
       " 61.05209231376648]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui.bots[-1].times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
