{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed t=95800 iterations   \r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "eps = 1e-12\n",
    "\n",
    "#Use State instead of Game class to simplify tree operations below (also undo is expensive :/)\n",
    "class TicTacToeState:\n",
    "    def __init__(self, board=None, to_move=1):\n",
    "        self.board = np.zeros((3,3), dtype=int) if board is None else board.copy()\n",
    "        self.to_move = to_move  # 1 for X, -1 for O\n",
    "\n",
    "    def legal_actions(self):\n",
    "        return [(i,j) for i in range(3) for j in range(3) if self.board[i,j] == 0]\n",
    "\n",
    "    def is_terminal(self):\n",
    "        # Win conditions\n",
    "        for player in (1, -1):\n",
    "            # rows and columns\n",
    "            if any(np.all(self.board[i,:] == player) for i in range(3)) or \\\n",
    "               any(np.all(self.board[:,j] == player) for j in range(3)):\n",
    "                return True, player\n",
    "            # diagonals\n",
    "            if (self.board[0,0] == player and self.board[1,1] == player and self.board[2,2] == player) or \\\n",
    "               (self.board[0,2] == player and self.board[1,1] == player and self.board[2,0] == player):\n",
    "                return True, player\n",
    "        if not self.legal_actions():\n",
    "            return True, 0  # draw\n",
    "        return False, None\n",
    "\n",
    "    def next_state(self, action):\n",
    "        new_state = TicTacToeState(self.board, -self.to_move)\n",
    "        new_state.board[action] = self.to_move\n",
    "        return new_state\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.board.tobytes()) ^ hash(self.to_move)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, TicTacToeState) and self.to_move == other.to_move and np.array_equal(self.board, other.board)\n",
    "\n",
    "    def draw(self):\n",
    "        def convert(n):\n",
    "            return \"X\"*(n==1) + \" \"*(n==0) + \"O\"*(n==-1)\n",
    "        \n",
    "        temp = [[convert(int(self.board[j][i])) for i in range(3)] for j in range(3)]\n",
    "        print(f\"{temp[0][0]}|{temp[0][1]}|{temp[0][2]}\")\n",
    "        print(\"-----\")\n",
    "        print(f\"{temp[1][0]}|{temp[1][1]}|{temp[1][2]}\")\n",
    "        print(\"-----\")\n",
    "        print(f\"{temp[2][0]}|{temp[2][1]}|{temp[2][2]}\")  \n",
    "        print()\n",
    "    \n",
    "class SequenceForm:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.state_to_id = {}\n",
    "        self.indices = {}  # (state_id, action) -> seq_idx\n",
    "        self.num_sequences = 0\n",
    "\n",
    "    def build(self, root_state):\n",
    "        # BFS to collect all states\n",
    "        queue = deque([root_state])\n",
    "        while queue:\n",
    "            st = queue.popleft()\n",
    "            if st in self.state_to_id:\n",
    "                continue\n",
    "            sid = len(self.states)\n",
    "            self.state_to_id[st] = sid\n",
    "            self.states.append(st)\n",
    "            terminal, _ = st.is_terminal()\n",
    "            if not terminal:\n",
    "                for a in st.legal_actions():\n",
    "                    queue.append(st.next_state(a))\n",
    "        # Assign sequence indices\n",
    "        seq_idx = 0\n",
    "        for sid, st in enumerate(self.states):\n",
    "            terminal, _ = st.is_terminal()\n",
    "            if terminal:\n",
    "                continue\n",
    "            for a in st.legal_actions():\n",
    "                self.indices[(sid, a)] = seq_idx\n",
    "                seq_idx += 1\n",
    "        self.num_sequences = seq_idx\n",
    "\n",
    "def GRADIENT(x):\n",
    "    return 1.0 + np.log(np.clip(x, EPS, None))\n",
    "\n",
    "def ARGCONJUGATE(g):\n",
    "    exp_g = np.exp(g - np.max(g))\n",
    "    return exp_g / exp_g.sum() # Just a point estimate\n",
    "\n",
    "# --- Bandit regret solver ---\n",
    "class BanditRegretSolver:\n",
    "    def __init__(self, sf: SequenceForm, eta: float):\n",
    "        self.sf = sf\n",
    "        self.eta = eta\n",
    "        self.x = np.ones(sf.num_sequences) / sf.num_sequences\n",
    "\n",
    "    def next_strategy(self):\n",
    "        return self.x.copy()\n",
    "\n",
    "    def observe_loss(self, loss_estimate):\n",
    "        g = self.eta * loss_estimate - GRADIENT(self.x)\n",
    "        self.x = ARGCONJUGATE(-g)\n",
    "\n",
    "    def build_loss_estimate(self, path, payoff, x):\n",
    "        est = np.zeros_like(x)\n",
    "        for i in path:\n",
    "            if x[i] > 0:\n",
    "                est[i] = payoff / x[i]\n",
    "        return est\n",
    "\n",
    "def sample_self_play(sf: SequenceForm, x, o):\n",
    "    path_X, path_O = [], []\n",
    "    st = sf.states[0]  # root state\n",
    "    while True:\n",
    "        terminal, payoff = st.is_terminal()\n",
    "        if terminal:\n",
    "            return path_X, path_O, payoff\n",
    "        sid = sf.state_to_id[st]\n",
    "        legal = st.legal_actions()\n",
    "        seqs = [sf.indices[(sid, a)] for a in legal]\n",
    "        probs = (x if st.to_move == 1 else o)[seqs]\n",
    "        total = probs.sum()\n",
    "        if total <= 0 or np.isnan(total):\n",
    "            probs = np.ones(len(legal)) / len(legal) # Handle edges cases \n",
    "        else:\n",
    "            probs = probs / total\n",
    "        choice = np.random.choice(len(legal), p=probs)\n",
    "        idx = seqs[choice]\n",
    "        if st.to_move == 1:\n",
    "            path_X.append(idx)\n",
    "        else:\n",
    "            path_O.append(idx)\n",
    "        st = st.next_state(legal[choice])\n",
    "\n",
    "\n",
    "def train_self_play(T=10000, eta=0.1):\n",
    "    root = TicTacToeState()\n",
    "    sf = SequenceForm()\n",
    "    sf.build(root)\n",
    "    X_solver = BanditRegretSolver(sf, eta)\n",
    "    O_solver = BanditRegretSolver(sf, eta)\n",
    "    avg_x = np.zeros(sf.num_sequences)\n",
    "    avg_o = np.zeros(sf.num_sequences)\n",
    "\n",
    "    for t in range(1, T+1):\n",
    "        x_t = X_solver.next_strategy()\n",
    "        o_t = O_solver.next_strategy()\n",
    "        path_X, path_O, payoff = sample_self_play(sf, x_t, o_t)\n",
    "        lx = X_solver.build_loss_estimate(path_X, payoff, x_t)\n",
    "        lo = O_solver.build_loss_estimate(path_O, -payoff, o_t)\n",
    "        X_solver.observe_loss(lx)\n",
    "        O_solver.observe_loss(lo)\n",
    "        avg_x += x_t\n",
    "        avg_o += o_t\n",
    "        \n",
    "        if t %100 == 0:\n",
    "            print(f\"Completed {t=} iterations   \", end=\"\\r\")\n",
    "    return avg_x / T, avg_o / T\n",
    "\n",
    "\n",
    "\n",
    "def play_against_agent(pi, sf, human_player= -1, deterministic = True):\n",
    "    \"\"\"\n",
    "    Play a human vs. agent game. \n",
    "    human_player: 1 for X (goes first), -1 for O.\n",
    "    \"\"\"\n",
    "    state = TicTacToeState()\n",
    "    while True:\n",
    "        terminal, payoff = state.is_terminal()\n",
    "        if terminal:\n",
    "            if payoff == 0:\n",
    "                print(\"Draw!\")\n",
    "            else:\n",
    "                winner = 'X' if payoff == 1 else 'O'\n",
    "                print(f\"Winner: {winner}\")\n",
    "            break\n",
    "        state.draw()\n",
    "        if state.to_move == human_player:\n",
    "            # human turn\n",
    "            while True:\n",
    "                move = input(f\"Your move {('X' if human_player==1 else 'O')}, enter row,col: \")\n",
    "                try:\n",
    "                    i,j = map(int, move.split(','))\n",
    "                    if (i,j) in state.legal_actions():\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Illegal move\")\n",
    "                except:\n",
    "                    print(\"Invalid input, format: row,col\")\n",
    "            state = state.next_state((i,j))\n",
    "        else:\n",
    "            # agent turn\n",
    "            sid = sf.state_to_id[state]\n",
    "            legal = state.legal_actions()\n",
    "            seqs = [sf.indices[(sid,a)] for a in legal]\n",
    "            probs = pi[seqs]\n",
    "            probs = probs / probs.sum()\n",
    "            print(f\"Probabilities {probs=}\")\n",
    "            if deterministic: \n",
    "                choice = int(np.argmax(probs))\n",
    "            else:\n",
    "                choice = np.random.choice(len(legal), p=probs)\n",
    "            print(f\"Agent plays {legal[choice]}\")\n",
    "            state = state.next_state(legal[choice])\n",
    "\n",
    "np.random.seed(420)\n",
    "pi_X, pi_O = train_self_play(T=100000, eta=0.05)\n",
    "sf = SequenceForm()\n",
    "sf.build(TicTacToeState())\n",
    "\n",
    "np.save('pi_X.npy', pi_X)\n",
    "np.save('pi_O.npy', pi_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51edef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_X = np.load('pi_X.npy')\n",
    "pi_O = np.load('pi_O.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "07b96107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | | \n",
      "-----\n",
      " | | \n",
      "-----\n",
      " | | \n",
      "\n",
      "Probabilities probs=array([0.10002728, 0.12805571, 0.09729799, 0.12908966, 0.08385077,\n",
      "       0.13132796, 0.10456902, 0.1193195 , 0.10646212])\n",
      "Agent plays (1, 2)\n",
      " | | \n",
      "-----\n",
      " | |X\n",
      "-----\n",
      " | | \n",
      "\n",
      "Your move O, enter row,col: 1, 1\n",
      " | | \n",
      "-----\n",
      " |O|X\n",
      "-----\n",
      " | | \n",
      "\n",
      "Probabilities probs=array([0.1452948 , 0.13557789, 0.10604309, 0.23036927, 0.1180822 ,\n",
      "       0.14521477, 0.11941798])\n",
      "Agent plays (1, 0)\n",
      " | | \n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      " | | \n",
      "\n",
      "Your move O, enter row,col: 0,0\n",
      "O| | \n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      " | | \n",
      "\n",
      "Probabilities probs=array([0.11997939, 0.14253484, 0.30026015, 0.36249353, 0.07473208])\n",
      "Agent plays (2, 1)\n",
      "O| | \n",
      "-----\n",
      "X|O|X\n",
      "-----\n",
      " |X| \n",
      "\n",
      "Your move O, enter row,col: 2,2\n",
      "Winner: O\n"
     ]
    }
   ],
   "source": [
    "play_against_agent(pi_X, sf, human_player=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4692b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_against_agent(pi_O, sf, human_player=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a78b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9ea78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866b4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ddbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5579ce7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16167"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the game and sequence form utils\n",
    "import numpy as np\n",
    "\n",
    "class Game: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.board = np.zeros(10, dtype = int)\n",
    "        self.player = 1 # Alternates between -1 and 1\n",
    "        self.board[9] = self.player\n",
    "        self.hist = []\n",
    "     \n",
    "    def get_actions(self, board = None):\n",
    "        if board == None: board = self.board\n",
    "        return [i for i in range(9) if board[i] == 0]\n",
    "    \n",
    "    def winner(self): #Return tuple (done, outcome)\n",
    "        b = self.board[:9].reshape(3, 3)\n",
    "\n",
    "        # Check rows and columns\n",
    "        rows, cols = b.sum(axis = 1), b.sum(axis = 0)\n",
    "        if 3 in rows or 3 in cols: return True, 1\n",
    "        elif -3 in rows or -3 in cols: return True, -1\n",
    "        \n",
    "        # Check diagonals\n",
    "        if abs(b[0, 0] + b[1, 1] + b[2, 2]) == 3: return True, np.sign(b[0, 0])\n",
    "        if abs(b[0, 2] + b[1, 1] + b[2, 0]) == 3: return True, np.sign(b[0, 2])\n",
    "\n",
    "        # Check for draw\n",
    "        if np.all(self.board[:9] != 0):\n",
    "            return True, 0\n",
    "\n",
    "        return False, None  # Game still ongoing\n",
    "\n",
    "    \n",
    "    def update(self, a: int):\n",
    "        self.board[a] = self.player\n",
    "        self.player *= -1\n",
    "        self.hist.append(a)\n",
    "        self.board[9] = self.player\n",
    "        \n",
    "    def undo(self):\n",
    "        a = self.hist.pop()\n",
    "        self.player *= -1\n",
    "        self.board[a] = 0\n",
    "        self.board[9] = self.player\n",
    "            \n",
    "    def get_state(self):\n",
    "        return self.board\n",
    "    \n",
    "    def get_state_id(self):\n",
    "        return hash(self.board.tobytes())\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return np.array_equal(self.board, other.board)\n",
    "    \n",
    "    \n",
    "    def draw(self):\n",
    "        def convert(n):\n",
    "            return \"X\"*(n==1) + \" \"*(n==0) + \"O\"*(n==-1)\n",
    "        \n",
    "        temp = [[convert(int(self.board[3*j+i])) for i in range(3)] for j in range(3)]\n",
    "        print(f\"{temp[0][0]}|{temp[0][1]}|{temp[0][2]}\")\n",
    "        print(\"-----\")\n",
    "        print(f\"{temp[1][0]}|{temp[1][1]}|{temp[1][2]}\")\n",
    "        print(\"-----\")\n",
    "        print(f\"{temp[2][0]}|{temp[2][1]}|{temp[2][2]}\")  \n",
    "        print()\n",
    "    \n",
    "class SequenceForm: \n",
    "    \n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "        \n",
    "        self.state_to_id = {} # board -> id\n",
    "        self.indices = {}  # (state_id, action) -> seq_idx\n",
    "        self.num_sequences = 0\n",
    "        \n",
    "        self.build()\n",
    "        \n",
    "    def build(self):\n",
    "        def dfs():\n",
    "            state_hash = self.game.get_state_id()\n",
    "            if state_hash in self.state_to_id:\n",
    "                return\n",
    "\n",
    "            sid = len(self.state_to_id)\n",
    "            self.state_to_id[state_hash] = sid\n",
    "\n",
    "            done, _ = self.game.winner()\n",
    "            if done: return\n",
    "\n",
    "            for a in self.game.get_actions():\n",
    "                self.indices[(sid, a)] = self.num_sequences\n",
    "                self.num_sequences += 1\n",
    "                self.game.update(a)\n",
    "                dfs()\n",
    "                self.game.undo()\n",
    "        \n",
    "        dfs()\n",
    "        \n",
    "def GRADIENT(x):\n",
    "    pass\n",
    "\n",
    "def ARGCONJUGATE(g):\n",
    "    pass\n",
    "\n",
    "# --- Bandit regret solver ---\n",
    "class BanditRegretSolver:\n",
    "    def __init__(self, sf: SequenceForm, eta: float):\n",
    "        pass\n",
    "\n",
    "    def next_strategy(self):\n",
    "        pass\n",
    "\n",
    "    def observe_loss(self, loss_estimate):\n",
    "        pass\n",
    "\n",
    "    def build_loss_estimate(self, path, payoff, x):\n",
    "        pass\n",
    "\n",
    "# --- Self-play sampling and training ---\n",
    "def sample_self_play(sf: SequenceForm, x, o):\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_self_play(T=10000, eta=0.1):\n",
    "    pass\n",
    "\n",
    "sf = SequenceForm(Game())\n",
    "sf.num_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b98ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
