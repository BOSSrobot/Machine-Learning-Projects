{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello! Here I test RL on a gridworld. In a gridworld an agent needs to get to a goal while obstacles lie in it's way. Here I use walls as the obstacle. The agent uses Table Lookup SARSA(lambda). To start run the cells until the next message comes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import numpy as np\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "import matplotlib.pyplot as plt\n",
    "from Common_functions import file_io, pygame_visuals as pv\n",
    "from sys import exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL algorithm\n",
    "# If you are going to adjust the agents parameters view the documentation in __init__() to understand what each does.\n",
    "\n",
    "class sarsa():\n",
    "    \"\"\"\n",
    "    Uses table lookup backward view SARSA(lambda) to learn. States are represented with with natural numbers. Same for actions.\n",
    "    \n",
    "    Game Loop should look like:\n",
    "    Get first action (baction, bstate)\n",
    "    Repeat until terminal state\n",
    "      take the action   (reward)\n",
    "      update env (nstate)\n",
    "      get action    (naction)\n",
    "      update agent (bstate, baction <-- nstate, naction)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma, alpha, epsilon, min_epsilon, lamda, num_states, num_actions):\n",
    "        \"\"\"\n",
    "        Initalizes agent. \n",
    "        \n",
    "        Params: \n",
    "        gamma:       disount factor. How much it cares about the future. [0,1]\n",
    "        alpha:       step size rate. How much it updates current prediction towards new one. [0,1]\n",
    "        epsilon:     exploration rate. How often it makes random moves. [0,1]\n",
    "        min_epsilon: lower bound on epsilon. [0,1]\n",
    "        lamda:       weight of n-step return. [0,1]\n",
    "        ...\n",
    "        \"\"\"\n",
    "        #Learning parameters\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.lamda = lamda\n",
    "        \n",
    "        #Field variables\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.q_table = np.random.randn(num_states, num_actions)\n",
    "        self.not_min_epsilon = True\n",
    "        \n",
    "        #Resetables \n",
    "        self.eligibility = np.zeros((num_states, num_actions))\n",
    "        self.bstate = None\n",
    "        self.baction = None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.bstate = None\n",
    "        self.baction = None\n",
    "        self.eligibility = np.zeros((self.num_states, self.num_actions))\n",
    "\n",
    "    def set_init_values(self, state, action):\n",
    "        self.bstate = state\n",
    "        self.baction = action\n",
    "        \n",
    "    def q_value(self, state, action):\n",
    "        return self.q_table[state][action]\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        \"\"\"\n",
    "        Returns action given state. Both are represented as whole numbers\n",
    "        \n",
    "        Params:\n",
    "        state:   whole number corresponding to state\n",
    "        \"\"\"\n",
    "        \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0,self.num_actions)\n",
    "        else:\n",
    "            actions = [self.q_value(state, ac) for ac in range(self.num_actions)]\n",
    "            return actions.index(max(actions))\n",
    "            \n",
    "    def update(self, state, action, reward, debug = False):\n",
    "        \n",
    "        if debug: #\n",
    "            print(\"new update\")\n",
    "            \n",
    "        sarsa_error = self.q_table[state][action] + reward - self.q_table[self.bstate][self.baction]\n",
    "    \n",
    "        if debug: #\n",
    "            print('bstate', self.bstate, 'baction', self.baction, 'reward', reward, 'state', state, 'action', action)\n",
    "            print('error', sarsa_error)\n",
    "            \n",
    "        \n",
    "        self.eligibility *= self.lamda*self.gamma\n",
    "        self.eligibility[self.bstate][self.baction] += 1\n",
    "            \n",
    "        if debug: #\n",
    "            print(self.q_table[:3])\n",
    "                \n",
    "        #self.q_table[self.bstate][self.baction] +=  self.alpha*sarsa_error* self.eligibility[self.bstate][self.baction]\n",
    "        self.q_table +=  self.alpha*sarsa_error* self.eligibility\n",
    "        \n",
    "        if debug: #\n",
    "            print(self.q_table[:3])\n",
    "                \n",
    "        if self.not_min_epsilon: \n",
    "            self.epsilon *= 0.99999\n",
    "            if self.epsilon <= 0.1:\n",
    "                self.not_min_epsilon = False\n",
    "                    \n",
    "        self.bstate, self.baction = state, action\n",
    "                   \n",
    "    def save(self, filename = 'agent.txt'):\n",
    "        \n",
    "        with open(filename, mode = 'w') as file:\n",
    "            file.write(str(self.gamma) + \" \" + str(self.alpha) + \" \" + str(self.epsilon) + \" \" + str(self.min_epsilon) + \" \")\n",
    "            file.write(str(self.lamda) + \" \" + str(self.num_states) + \" \" + str(self.num_actions) + \" \"+ str(self.not_min_epsilon))\n",
    "            file.write(\"\\n\\n\" + str(self.q_table))\n",
    "            \n",
    "    def load(self, filename = 'agent.txt'):\n",
    "        \n",
    "        with open(filename, mode = 'r') as file:\n",
    "            sarsa_string = file.read()\n",
    "            params, q_table = sarsa_string.split(\"\\n\\n\")\n",
    "            params_list = params.split(\" \")\n",
    "            \n",
    "            self.gamma, self.alpha, self.epsilon, self.min_epsilon, self.lamda = [float(val) for val in params_list[:5]]\n",
    "            self.num_states, self.num_actions = [int(val) for val in params_list[5:7]]\n",
    "            self.not_min_epsilon = bool(params_list[7])\n",
    "            \n",
    "            self.q_table = np.array(file_io.from_twodim_nparr(q_table))\n",
    "            self.reset()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "\n",
    "class gridworld:\n",
    "    def __init__(self, cs, blocks, playerx, playery, goalx, goaly, wall_coords = [], vision = 5):\n",
    "        self.init_player = pygame.Rect(playerx,playery,cs,cs)\n",
    "        self.player = self.init_player\n",
    "        self.goal = pygame.Rect(goalx, goaly, cs,cs)\n",
    "        self.wall = []\n",
    "        for coord in wall_coords:\n",
    "            self.wall.append(pygame.Rect(coord[0], coord[1], cs, cs))\n",
    "        \n",
    "        self.cs = cs\n",
    "        self.blocks = blocks\n",
    "        self.end = (1+blocks)*cs\n",
    "        self.move = []\n",
    "        \n",
    "        self.vision = vision\n",
    "        self.feature_size = vision**2+2\n",
    "        self.shift = int(vision/2)\n",
    "        self.vision_player_index = 2+(1+self.vision)*self.shift\n",
    "        \n",
    "        self.terminal = False\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.score = 0\n",
    "    \n",
    "    def rect_to_list(rect):\n",
    "        return [rect.topleft[0], rect.topleft[1], rect.size[0], rect.size[1]]\n",
    "        \n",
    "    def save(self, filename = 'map.txt'):\n",
    "        \n",
    "        with open(filename, mode = 'w') as file:\n",
    "            file.write(str(self.cs) + \" \" + str(self.blocks) + \" \" + str(self.vision) + \"\\n\")\n",
    "            file.write(str(gridworld.rect_to_list(self.init_player)) + \"\\n\")\n",
    "            file.write(str(gridworld.rect_to_list(self.goal)) + \"\\n\")\n",
    "            file.write(str([gridworld.rect_to_list(w) for w in self.wall]))\n",
    "\n",
    "\n",
    "    \n",
    "    def load(self, filename = 'map.txt'):\n",
    "        \n",
    "        with open(filename, mode = 'r') as file:\n",
    "            gw_string = file.read()\n",
    "            params, player, goal, walls = gw_string.split(\"\\n\")\n",
    "            self.cs, self.blocks, self.vision = [int(val) for val in params.split(\" \")]\n",
    "            self.init_player = pygame.Rect(file_io.from_onedim_list(player, dtype = int))\n",
    "            self.goal = pygame.Rect(file_io.from_onedim_list(goal, dtype = int))\n",
    "            \n",
    "            for rect in file_io.from_twodim_list(walls, dtype = int):\n",
    "                self.wall.append(pygame.Rect(rect))\n",
    "        \n",
    "        self.player = self.init_player\n",
    "        \n",
    "        self.end = (1+self.blocks)*self.cs\n",
    "\n",
    "        self.feature_size = self.vision**2+2\n",
    "        self.shift = int(self.vision/2)\n",
    "        self.vision_player_index = 2+6*self.shift\n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = self.init_player\n",
    "        self.terminal = False\n",
    "        self.reward = 0\n",
    "        self.score = 0    \n",
    "    \n",
    "    def make_gridworld(self):\n",
    "        \n",
    "        pygame.init()\n",
    "        self.reset()\n",
    "        pygame.display.set_caption('Gridworld Creator')\n",
    "        gameDisplay = pygame.display.set_mode((800,600))\n",
    "        mode = 'wall'\n",
    "        color = (0,0,255)\n",
    "        mousecoor = (1000,1000)\n",
    "        directions = pv(gameDisplay, text_color = (255,255,255))\n",
    "        directions.add_message(topleft = (self.end+10, self.cs))\n",
    "        directions.add_message(topleft = (self.end+10, 2*self.cs))\n",
    "        directions.add_message(topleft = (self.end+10, 3*self.cs))\n",
    "        directions.add_message(topleft = (self.end+10, 4*self.cs))\n",
    "        \n",
    "        run = True\n",
    "        while run: \n",
    "            for event in pygame.event.get():\n",
    "                if event.type == QUIT:\n",
    "                    pygame.quit()\n",
    "                    exit()\n",
    "                elif event.type == KEYDOWN:\n",
    "                    if event.key == pygame.K_SPACE:\n",
    "                        run = False\n",
    "                    elif event.key == pygame.K_w:\n",
    "                        mode = 'wall'\n",
    "                        color = (0,0,255)\n",
    "                    elif event.key == pygame.K_p:\n",
    "                        mode = 'player'\n",
    "                        color = (255,0,0)\n",
    "                    elif event.key == pygame.K_g:\n",
    "                        mode = 'goal'\n",
    "                        color = (0,255,0)\n",
    "                        \n",
    "                elif event.type == MOUSEBUTTONDOWN:\n",
    "                    xmouse, ymouse = event.pos\n",
    "                    \n",
    "                    if xmouse < self.end or xmouse >= self.cs:\n",
    "                        if ymouse < self.end or ymouse >= self.cs:\n",
    "                            x = int(xmouse/self.cs)*self.cs\n",
    "                            y = int(ymouse/self.cs)*self.cs\n",
    "                            test_rect = pygame.Rect(x, y, self.cs, self.cs)\n",
    "                            if mode == 'wall':\n",
    "                                if test_rect in self.wall:\n",
    "                                    self.wall.remove(test_rect)\n",
    "                                else:\n",
    "                                    self.wall.append(test_rect)\n",
    "                            elif mode == 'player':\n",
    "                                self.init_player = test_rect\n",
    "                                self.player = test_rect\n",
    "                            elif mode == 'goal':\n",
    "                                self.goal = test_rect\n",
    "                            \n",
    "                elif event.type == MOUSEMOTION:\n",
    "                    mousecoor = event.pos \n",
    "                \n",
    "            gameDisplay.fill((0,0,0))\n",
    "            pygame.draw.circle(gameDisplay, color, mousecoor, 5)\n",
    "            self.draw(gameDisplay, False)\n",
    "            pv.show_text(gameDisplay, 'Mode is ' + str(mode), topleft = (self.cs, self.end), fontsize = 20, priority = 0)\n",
    "            directions.show_all_messages(\"Click any square to edit it\", \"Press w to go to wall edit mode\", \n",
    "                                         \"Press p to go to player edit mode\", \"Press g to go to goal edit mode\")\n",
    "            pygame.display.update()\n",
    "    \n",
    "            pygame.time.wait(50)\n",
    "        pygame.quit()\n",
    "        \n",
    "    \n",
    "    def set_movement(self, choice):\n",
    "        if choice == 0:\n",
    "            self.move = [self.cs,0]\n",
    "        elif choice == 1:\n",
    "            self.move = [0,self.cs]\n",
    "        elif choice == 2:\n",
    "            self.move = [-self.cs,0]\n",
    "        elif choice == 3:\n",
    "            self.move = [0,-self.cs]\n",
    "            \n",
    "    def return_feature(self, action):       \n",
    "        # If you are reading this part you have discovered a method that isn't used but sheds light into the parameters \n",
    "        # of the linear function approximator!\n",
    "        \n",
    "        feature = np.zeros(self.feature_size) # Vision = self.vision by self.vision + the xdist and ydist to goal\n",
    "        \n",
    "        original_move = self.move.copy()\n",
    "        self.set_movement(action)\n",
    "        \n",
    "        topleft_xpos = self.player.left + self.move[0]\n",
    "        topleft_ypos = self.player.top + self.move[1]\n",
    "        \n",
    "        test_rect = pygame.Rect(topleft_xpos, topleft_ypos, self.cs, self.cs)\n",
    "        \n",
    "        if self.check_boundary(test_rect):\n",
    "            topleft_xpos -= self.move[0]\n",
    "            topleft_ypos -= self.move[1]\n",
    "        else:    \n",
    "            for rect in self.wall:\n",
    "                if test_rect.colliderect(rect):\n",
    "                    topleft_xpos -= self.move[0]\n",
    "                    topleft_ypos -= self.move[1]\n",
    "                    break\n",
    "                    \n",
    "        feature[0], feature[1] = (topleft_xpos - self.goal.left)//self.cs, (topleft_ypos - self.goal.top)//self.cs\n",
    "        topleft_xpos -= self.shift*self.cs\n",
    "        topleft_ypos -= self.shift*self.cs\n",
    "        \n",
    "        #Deal with player themself\n",
    "        if self.vision != 0:\n",
    "            feature[self.vision_player_index] = 1\n",
    "        \n",
    "        #Deal with all other vision \n",
    "        for i in range(self.vision):\n",
    "            for j in range(self.vision):\n",
    "                rect = pygame.Rect(topleft_xpos+i*self.cs, topleft_ypos+j*self.cs, self.cs, self.cs)\n",
    "                \n",
    "                if self.check_boundary(rect):\n",
    "                    feature[2+i+self.vision*j] = 1\n",
    "                elif rect.colliderect(self.goal):\n",
    "                    feature[2+i+self.vision*j] = 1\n",
    "                else:\n",
    "                    for wall_rect in self.wall:\n",
    "                        if rect.colliderect(wall_rect):\n",
    "                            feature[2+i+self.vision*j] = 1\n",
    "                            break\n",
    "                \n",
    "            \n",
    "        \n",
    "        self.move = original_move\n",
    "        return feature\n",
    "    \n",
    "    def return_all_features(self):\n",
    "        return [self.return_feature(action) for action in range(4)]\n",
    "    \n",
    "    def return_state(self):\n",
    "        return (self.player.left//self.cs-1) + (self.player.top//self.cs-1)*self.blocks\n",
    "    \n",
    "    def update(self):\n",
    "        test_rect = pygame.Rect(self.player.left + self.move[0], self.player.top + self.move[1], self.cs, self.cs)\n",
    "        if test_rect.colliderect(self.goal):\n",
    "            self.terminal = True\n",
    "            self.reward = 0\n",
    "            self.player = test_rect\n",
    "            \n",
    "        elif self.check_boundary(test_rect):\n",
    "            self.reward = -2\n",
    "        else:    \n",
    "            for rect in self.wall:\n",
    "                if test_rect.colliderect(rect):\n",
    "                    self.reward = -3\n",
    "                    break\n",
    "            else:\n",
    "                self.reward = -1\n",
    "                self.player = test_rect\n",
    "            \n",
    "        self.score += self.reward\n",
    "    \n",
    "    def check_boundary(self, rect):\n",
    "        return rect.left >= self.end or rect.left < self.cs or rect.top >= self.end or rect.top < self.cs\n",
    "        \n",
    "    def draw(self, gameDisplay, show_score = True):\n",
    "        pygame.draw.rect(gameDisplay, (255,0,0), self.player)\n",
    "        pygame.draw.rect(gameDisplay, (0,255,0), self.goal)\n",
    "        for rect in self.wall:\n",
    "            pygame.draw.rect(gameDisplay, (0,0,255), rect)\n",
    "        for i in range(self.cs, self.end+1, self.cs):\n",
    "            pygame.draw.line(gameDisplay, (255,255,255), (i, self.cs), (i, self.end))\n",
    "            pygame.draw.line(gameDisplay, (255,255,255), (self.cs, i), (self.end, i))\n",
    "            \n",
    "        if show_score:\n",
    "            pv.show_text(gameDisplay, 'Score: '+ str(self.score), topleft = (self.end+10, self.cs), text_color = (0,255,0), priority = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have made it here, you have a couple of choices. You can create your own gridworld from scratch or load one you have already created. To create a new one use the cell right below. To use one that has been saved, use the 2nd cell. In each one when you run it a window will pop up. Go to that window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can adjust blocks and cs to your liking!\n",
    "\n",
    "# Here blocks represents the size of the environment. With blocks = 10 you will get a 10 by 10 world to play with!\n",
    "blocks = 10\n",
    "\n",
    "# cs represents the amount of pixels each square in the grid will take up. \n",
    "cs = 30\n",
    "\n",
    "gw = gridworld(cs,blocks, cs, cs, blocks*cs, blocks*cs)\n",
    "gw.make_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# You can specify the name of the file you are loading by using filename = 'nameoffile.txt'\n",
    "\n",
    "gw = gridworld(1,1,1,1,1,1)\n",
    "gw.load(filename = 'map.txt')\n",
    "gw.make_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.save(filename = 'map.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below if you want to save your gridworld!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the agent! The next cell initializes lists that will hold some information about the all agents ever trained. If you ever want to wipe out this information just rerun this cell. The cell below it is what actually trains the agent. Every time you run that cell a new agent is created and it's training data is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_data = []\n",
    "score_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsiodes done:  1000\n",
      "Epsiodes done:  2000\n",
      "Epsiodes done:  3000\n",
      "Epsiodes done:  4000\n",
      "Epsiodes done:  5000\n",
      "Epsiodes done:  6000\n",
      "Epsiodes done:  7000\n",
      "Epsiodes done:  8000\n",
      "Epsiodes done:  9000\n",
      "Epsiodes done:  10000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'step_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     gw\u001b[38;5;241m.\u001b[39mreset()    \n\u001b[0;32m     49\u001b[0m     agent\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 51\u001b[0m \u001b[43mstep_data\u001b[49m\u001b[38;5;241m.\u001b[39mappend([episodes_vs_steps, label])\n\u001b[0;32m     52\u001b[0m score_data\u001b[38;5;241m.\u001b[39mappend([episodes_vs_score, label])\n\u001b[0;32m     54\u001b[0m agent\u001b[38;5;241m.\u001b[39msave(filename \u001b[38;5;241m=\u001b[39m agent_save)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'step_data' is not defined"
     ]
    }
   ],
   "source": [
    "# You can adjust the agent's parameters (gamma, alpha, epsilon, min_epsilon, lamda). All must be between 0 and 1 \n",
    "# The parameters below are the parameters I found work best\n",
    "# Go back to the top of the cell containing the SARSA class to get learn more about what each really represents\n",
    "\n",
    "agent = sarsa(gamma=0.7, alpha=0.01, epsilon=1, min_epsilon=0.12, lamda=0.8, num_states = gw.blocks**2, num_actions = 4)\n",
    "\n",
    "# Adjust label to give the data for this agent a different name. \n",
    "# For example, if you are looking at how gamma effects learning you can try using gamma = whatever you set it to\n",
    "label = 'top agent'\n",
    "\n",
    "# Adjust agent_save to save the agent to a different text file\n",
    "agent_save = 'agent.txt'\n",
    "\n",
    "# Adjust num_training_episodes to train the agent for a different number of episodes. \n",
    "num_training_episodes = 10000\n",
    "\n",
    "episodes_vs_steps = []\n",
    "episodes_vs_score = []\n",
    " \n",
    "agent.reset()\n",
    "gw.reset()\n",
    "\n",
    "for i in range(1, num_training_episodes+1):\n",
    "    \n",
    "    if (i*10%num_training_episodes) == 0:\n",
    "        print(\"Epsiodes done: \", i)\n",
    "    \n",
    "    #Actual Training Logic\n",
    "    state  = gw.return_state()\n",
    "    action = agent.choose_action(state)\n",
    "    agent.set_init_values(state, action)\n",
    " \n",
    "    steps = 0\n",
    "    while not gw.terminal:\n",
    "        gw.set_movement(action)\n",
    "        gw.update()\n",
    "        reward = gw.reward\n",
    "        \n",
    "        state = gw.return_state()\n",
    "        action = agent.choose_action(state)\n",
    "        agent.update(state, action, reward)\n",
    "\n",
    "        steps+=1\n",
    "\n",
    "    episodes_vs_steps.append((i+1, steps))\n",
    "    episodes_vs_score.append((i+1, gw.score))\n",
    "\n",
    "    gw.reset()    \n",
    "    agent.reset()\n",
    "    \n",
    "step_data.append([episodes_vs_steps, label])\n",
    "score_data.append([episodes_vs_score, label])\n",
    "    \n",
    "agent.save(filename = agent_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the agent(s) have been trained you can view their progress and compare them if you have multiple by running the two cells below. You can also save them by setting option equal to 1 in their respective cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change option to 1 to save the figure. To change the file it saves to go to savefig() and adjust the first parameter. \n",
    "option = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.0,0.4,0.9,0.4])\n",
    "\n",
    "\n",
    "for info_steps_package in step_data:\n",
    "    episodes, steps = zip(*info_steps_package[0])\n",
    "    axes.plot(episodes, steps, label = info_steps_package[1])\n",
    "    \n",
    "axes.set_xlabel('Episodes')\n",
    "axes.set_ylabel('Steps')\n",
    "axes.set_title(\"Agent steps over episodes\")\n",
    "axes.legend(loc=0)\n",
    "\n",
    "if option:\n",
    "    fig.savefig('Steps.jpeg', figsize = (6,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same stuff applies here\n",
    "option = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.0,0.4,0.9,0.4])\n",
    "\n",
    "\n",
    "for info_score_package in score_data:\n",
    "    episodes, score = zip(*info_score_package[0])\n",
    "    axes.plot(episodes, score, label = info_score_package[1])\n",
    "    \n",
    "axes.set_xlabel('Episodes')\n",
    "axes.set_ylabel('Score')\n",
    "axes.set_title(\"Agent score over episodes\")\n",
    "axes.legend(loc=0)\n",
    "\n",
    "if option:\n",
    "    fig.savefig('Score.jpeg', figsize = (6,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have made it here you can finally view the agent in its gridworld by running the cell below. Press p to pause and unpause the replay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust filename to load a specific agent that has been saved\n",
    "agent.load(filename = 'agent.txt')\n",
    "\n",
    "agent.epsilon = 0\n",
    "agent.reset()\n",
    "gw.reset()\n",
    "\n",
    "pygame.init()\n",
    "pygame.display.set_caption('Gridworld Viewer')\n",
    "gameDisplay = pygame.display.set_mode((800,600))\n",
    "\n",
    "state  = gw.return_state()\n",
    "action = agent.choose_action(state)\n",
    "agent.set_init_values(state, action)\n",
    "\n",
    "run = True\n",
    "paused = False\n",
    "while run:\n",
    "\n",
    "    # Human interaction\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == QUIT:\n",
    "            run = False\n",
    "        elif event.type == KEYDOWN:\n",
    "            if event.key == pygame.K_SPACE:\n",
    "                run = False\n",
    "            elif event.key == pygame.K_p:\n",
    "                if paused:\n",
    "                    paused = False\n",
    "                else: \n",
    "                    paused = True\n",
    "    if paused:\n",
    "        #Do something\n",
    "        pygame.time.wait(250)\n",
    "        continue\n",
    "\n",
    "    #Game Logic\n",
    "    gw.set_movement(action)\n",
    "    gw.update()\n",
    "    reward = gw.reward\n",
    "        \n",
    "    state = gw.return_state()\n",
    "    action = agent.choose_action(state)\n",
    "    #agent.update(state, action, reward, debug = True)\n",
    "    \n",
    "    if gw.terminal:\n",
    "        gw.reset()\n",
    "        agent.reset()\n",
    "        \n",
    "        state  = gw.return_state()\n",
    "        action = agent.choose_action(state)\n",
    "        agent.set_init_values(state, action)\n",
    "        \n",
    "        gameDisplay.fill((0,0,0))\n",
    "        pv.show_text(gameDisplay, \"Done\", topleft = (200,200))\n",
    "        pygame.display.update()\n",
    "        pygame.time.wait(200)\n",
    "\n",
    "    #Visuals\n",
    "    gameDisplay.fill((0,0,0))\n",
    "    gw.draw(gameDisplay)\n",
    "    pygame.display.update()\n",
    "\n",
    "    pygame.time.wait(200)\n",
    "\n",
    "pygame.quit()\n",
    "\n",
    "agent.epsilon = agent.min_epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for taking the time to look at my project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = agent.q_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = q.max(axis=1).reshape(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        v[i][j] = round(v[i][j],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17., -17., -16., -15.,   1., -10.,  -8.,  -7.,   1.,   0.],\n",
       "       [-18., -17.,   2., -14., -12., -11.,   1.,  -5.,   1.,   0.],\n",
       "       [-19., -17., -16., -15.,   1., -10.,   1.,  -4.,  -2.,  -1.],\n",
       "       [-20.,   0.,   2.,   2.,  -9.,  -9.,  -8.,  -7.,   1.,  -2.],\n",
       "       [-21., -18., -19.,   2.,   1.,   0.,   0.,   1.,  -5.,  -3.],\n",
       "       [  2., -17.,   2., -12., -11.,  -9.,  -8.,  -7.,  -6.,  -5.],\n",
       "       [-18., -16., -14., -13.,   1.,   1.,   1.,  -0.,   1.,  -6.],\n",
       "       [-19.,   0., -17., -15., -14., -13., -11., -10.,  -9.,  -7.],\n",
       "       [-18., -18., -17.,   1., -15.,  -0., -13., -12.,   2., -10.],\n",
       "       [-18., -17., -17., -16., -15., -14., -13., -13., -12., -11.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.make_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
